

@inproceedings{Gois2016,
	Author = {Gois, N. and Porfirio, P. and Coelho, A. and Barbosa, T.},
	Booktitle = {Proceedings of the 2016 Latin American Computing Conference (CLEI)},
	Isbn = {978-1-5090-1632-7},
	Title = {{Improving Stress Search Based Testing using a Hybrid Metaheuristic Approach}},
	Pages = {718--728},
	Year = {2016}}	

@inproceedings{Piel2010,
author = {Piel, {\'{E}}ric and Gonz{\'{a}}lez-Sanchez, Alberto and Gro{\ss}, Hans-Gerhard},
doi = {10.1007/978-3-642-16573-3},
file = {:Users/naubergois/Downloads/rbtcg{\_}preprint.pdf:pdf},
isbn = {978-3-642-16572-6},
journal = {Ictss},
number = {October},
pages = {79--94},
title = {{Testing Software and Systems}},
url = {http://dblp.uni-trier.de/db/conf/pts/ictss2010.html{\#}PielGG10},
volume = {6435},
year = {2010}
}


@article{Rakshit2017,
abstract = {Noisy optimization is currently receiving increasing popularity for its widespread applications in engineering optimization problems, where the objective functions are often found to be contaminated with noisy sensory measurements. In absence of knowledge of the noise-statistics, discriminating better trial solutions from the rest becomes difficult in the “selection” step of an evolutionary optimization algorithm with noisy objective/s. This paper provides a thorough survey of the present state-of-the-art research on noisy evolutionary algorithms for both single and multi-objective optimization problems. This is undertaken by incorporating one or more of the five strategies in traditional evolutionary algorithms. The strategies include (i) fitness sampling of individual trial solution, (ii) fitness estimation of noisy samples, (iii) dynamic population sizing over the generations, (iv) adaptation of the evolutionary search strategy, and (v) modification in the selection strategy.},
author = {Rakshit, Pratyusha and Konar, Amit and Das, Swagatam},
doi = {10.1016/j.swevo.2016.09.002},
file = {:Users/naubergois/Downloads/rakshit2016.pdf:pdf},
issn = {22106502},
journal = {Swarm and Evolutionary Computation},
keywords = {Evolutionary optimization,Fitness estimation,Noise,Population sizing,Sampling,Selection,Uncertainty},
mendeley-groups = {Search-Based Tests/Noise Reduction},
pages = {18--45},
publisher = {Elsevier},
title = {{Noisy evolutionary optimization algorithms – A comprehensive survey}},
url = {http://dx.doi.org/10.1016/j.swevo.2016.09.002},
volume = {33},
year = {2017}
}

@article{Siegmund2013,
abstract = {In Evolutionary Multi-objective Optimization many solutions have to be evaluated to provide the decision maker with a diverse choice of solutions along the Pareto-front, in particular for high-dimensional optimization problems. In Simulation-based Optimization the modeled systems are complex and require long simulation times. In addition the evaluated systems are often stochastic and reliable quality assessment of system configurations by resampling requires many simulation runs. As a countermeasure for the required high number of simulation runs caused by multiple optimization objectives the optimization can be focused on interesting parts of the Pareto-front, as it is done by the Reference point-guided NSGA-II algorithm (R-NSGA-II) [9]. The number of evaluations needed for the resampling of solutions can be reduced by intelligent resampling algorithms that allocate just as much sampling budget needed in different situations during the optimization run. In this paper we propose and compare resampling algorithms that support the R-NSGA-II algorithm on optimization problems with stochastic evaluation functions. {\textcopyright} 2013 IEEE.},
author = {Siegmund, Florian and Ng, Amos H C and Deb, Kalyanmoy},
doi = {10.1109/CEC.2013.6557782},
file = {:Users/naubergois/Downloads/k2013008.pdf:pdf},
isbn = {9781479904549},
journal = {2013 IEEE Congress on Evolutionary Computation, CEC 2013},
keywords = {Evolutionary multi-objective optimization,decision support,dynamic,guided search,reference point,resampling,simulation-based optimization,stochastic systems},
mendeley-groups = {Noise Reduction},
number = {2013008},
pages = {1826--1835},
title = {{A comparative study of dynamic resampling strategies for guided Evolutionary Multi-objective Optimization}},
year = {2013}
}


@article{DiPietro2004,
abstract = {For many "real world" applications of evolutionary computation, the fitness function is obscured by random noise. This interferes with the evaluation and selection process and adversely affects the performance of the algorithm. We present a study of noise compensation techniques designed to better counteract the negative effects of noise. We introduce algorithms that vary the number of samples used per candidate based on the amount of noise present at that point in the search space. Results show that these algorithms are significantly better than the traditional technique used by the optimisation community and that noise compensation is indeed a difficult task that warrants further investigation.},
author = {{Di Pietro}, A. and While, L. and Barone, L.},
doi = {10.1109/CEC.2004.1331041},
file = {:Users/naubergois/Downloads/10.1109@cec.2004.1331041.pdf:pdf},
isbn = {0-7803-8515-2},
journal = {Proceedings of the 2004 Congress on Evolutionary Computation},
pages = {1254--1261},
title = {{Applying evolutionary algorithms to problems with noisy, time-consuming fitness functions}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=1331041},
year = {2004}
}


@article{Deb2005,
author = {Deb, Kalyanmoy and Mohan, M. and Mishra, S.},
doi = {10.1162/106365605774666895},
file = {:Users/naubergois/Downloads/deb2005.pdf:pdf},
journal = {Evolutionary Computation Journal},
keywords = {-dominance,computational effort,convergence measure,evolutionary algorithms,genetic algorithms,hyper-volume metric,measure,multi-objective optimization,optimal solutions,pareto-,sparsity},
mendeley-groups = {Metaheuristics/MultiObjective},
number = {4},
pages = {501--525},
title = {{Evaluating the epislon-domination based multiobjective evolutionary algorithm for a quick computation of Pareto-optimal solutions}},
volume = {13},
year = {2005}
}


@article{Ye2007,
author = {Ye, Li},
file = {:home/74397176353/Downloads/gradu01951.pdf:pdf},
mendeley-groups = {Model Based Test},
number = {June},
title = {{Model-Based Testing Approach for Web Applications}},
year = {2007}
}


@article{Illes2005,
author = {Illes, T and Herrmann, A and Paech, B and R{\"{u}}ckert, J},
file = {:Users/naubergois/Downloads/2005{\_}Criteria{\_}for{\_}Software{\_}Testing{\_}TIMEA.pdf:pdf},
mendeley-groups = {Load Test Tools},
pages = {213--222},
title = {{Criteria for Software Testing Tool Evaluation – A Task Oriented View}},
volume = {2},
year = {2005}
}

@article{Jeong2016,
author = {Jeong, So-young and Yoo, Cheol-jung and Noh, Hye-min and Author, Corresponding},
keywords = {embedded system,state modeling,state transition diagram,test case},
mendeley-groups = {Model Based Test/State Machine Model},
number = {11},
pages = {233--254},
title = {{State Transition Based Test Model and Test Case Generation Technique for Embedded System: An Empirical Approach}},
volume = {10},
year = {2016}
}

@article{Arslan2015,
abstract = {Recently many application are migrated towards cloud computing. It becomes an emerging field of research in software testing; moreover it is non-trivial to evaluate the performance of cloud services. Performance and load testing are one of the dominant means to evaluate the web-application performance. At the end of load testing performance analyst have to analyze thousands of performance counters in both scenarios traditional as well as in cloud based load testing. These performance counters consist of run time system and web application properties such as resource consumption, response time, Memory utilization, throughput, Disk input output, latency, network traffic, delay. Performance analyst analyzes these performance measures manually, find out if the application meets service level agreement or not. It is very time consuming and error prone method, so to resolve this issue in this paper we proposed an approach to detect the performance deviation in cloud based load testing compare with the traditional load testing. It also helps performance analyst to compare load test more efficiently in order to detect performance deviation moreover it provides manageable set of important program counter to analyst for further and efficient root cause analysis. This approach is verified on the data obtain by performing load testing of web-application using J-meter in case of traditional and blaze meter in cloud based load testing. Our proposed approach provide up to 90{\%} of reduction in the set of performance counter and 96{\%} precision while detecting performance deviation with few false positives.},
author = {Arslan, Muhammad and Qamar, Usman and Hassan, Shoaib and Ayub, Sara},
doi = {10.1109/ICSESS.2015.7339023},
file = {:Users/naubergois/Downloads/07339023.pdf:pdf},
isbn = {978-1-4799-8352-0},
issn = {23270594},
journal = {2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS)},
keywords = {icle},
mendeley-groups = {Load Test Tools/Blaze Meter},
number = {September},
pages = {140--144},
title = {{Automatic performance analysis of cloud based load testing of web-application {\&} its comparison with traditional load testing}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84958250651{\&}partnerID=tZOtx3y1},
volume = {2015-Novem},
year = {2015}
}

@inproceedings{Bai2011a,
abstract = {Cloud platform provides an infrastructure for resource sharing, software hosting and service delivering in a pay-per-use approach. To test the cloud-based software systems, techniques and tools are necessary to address unique quality concerns of the cloud infrastructure such as massive scalability and dynamic configuration. The tools can also be built on the cloud platform to benefit from virtualized platform and services, massive resources, and parallelized execution. The paper makes a survey of representative approaches and typical tools for cloud testing. It identifies the needs for cloud testing tools including multi-layer testing, SLA-based testing, large scale simulation, and on-demand test environment. To address the needs, it investigates the new architecture and techniques for designing testing tools for the cloud and in the cloud. Tool implementations are surveyed considering different approaches including migrated conventional tools, research tools, commercial tools and facilities like benchmark and testbed. Based on the analysis of state-of-the-art practices, the paper further investigates future trend of testing tool research and development from both capability and usability perspectives.},
author = {Bai, Xiaoying and Li, Muyang and Chen, Bin and Tsai, Wei Tek and Gao, Jerry},
booktitle = {Proceedings - 6th IEEE International Symposium on Service-Oriented System Engineering, SOSE 2011},
doi = {10.1109/SOSE.2011.6139087},
file = {:Users/naubergois/Downloads/Cloud Testing Tools.pdf:pdf},
isbn = {9781467304108},
keywords = {Cloud Computing,Cloud Testing,Testing Tool},
mendeley-groups = {Load Test Tools,Load Test Tools/D-Cloud,Load Test Tools/Cloud},
pages = {1--12},
title = {{Cloud testing tools}},
year = {2011}
}

@article{Bianchi2017,
author = {Bianchi, Francesco and Margara, Alessandro and Pezze, Mauro},
doi = {10.1109/TSE.2017.2707089},
file = {:Users/naubergois/Downloads/bianchi2017.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
mendeley-groups = {Software Testing},
number = {c},
pages = {1--1},
title = {{A Survey of Recent Trends in Testing Concurrent Software Systems}},
url = {http://ieeexplore.ieee.org/document/7932530/},
volume = {5589},
year = {2017}
}

@article{Vetoio2011,
author = {Trubiani, Catia},
file = {:Users/naubergois/Downloads/PhDThesis-CatiaTrubiani.pdf:pdf},
journal = {Language},
mendeley-groups = {Anti-Patterns,Anti-Patterns/More is less,Anti-Patterns/The Ramp,Anti-Patterns/Traffic Jam,Anti-Patterns/Excessive Dynamic Aloccation,Anti-Patterns/One Lane Bridge,Anti-Patterns/Tower of Babel,Anti-Patterns/Empty Semi Trucks (EST),Anti-Patterns/Circuitous Treasure Hunt,Anti-Patterns/Extensive Process,Anti-Patterns/Piper and Filter,Anti-Patterns/Concurrent Processing System,Anti-Patterns/Blob (aka. God Class)},
title = {{PhD Thesis in Computer Science Automated generation of architectural feedback from software performance analysis results Catia Trubiani}},
year = {2011}
}

@article{Trubiani2011,
author = {Trubiani, Catia},
file = {:Users/naubergois/Downloads/PhDThesis-CatiaTrubiani.pdf:pdf},
journal = {Language},
mendeley-groups = {Anti-Patterns,Anti-Patterns/More is less,Anti-Patterns/The Ramp,Anti-Patterns/Traffic Jam,Anti-Patterns/Excessive Dynamic Aloccation,Anti-Patterns/One Lane Bridge,Anti-Patterns/Tower of Babel,Anti-Patterns/Empty Semi Trucks (EST),Anti-Patterns/Circuitous Treasure Hunt,Anti-Patterns/Extensive Process,Anti-Patterns/Piper and Filter,Anti-Patterns/Concurrent Processing System,Anti-Patterns/Blob (aka. God Class)},
title = {{Automated generation of architectural feedback from software performance analysis results Catia Trubiani}},
year = {2011}
}

@article{Marinho2014,
abstract = {It is no secret that many projects fail, regardless of the business sector, software projects are notoriously disaster victims, not necessarily because of technological failure, but more often due to their uncertainties. The threats identified by uncertainty in day-to-day of a project are real and immediate and the stakes in a project are often high. This paper presents a systematic review about software project management uncertainties. It helps to identify the difficulties and the actions that can minimize the uncertainties effects in the projects and how managers and teams can prepare themselves for the challenges of their projects scenario, with the aim of contributing to the improvement of project management in organizations as well as contributing to project success.},
archivePrefix = {arXiv},
arxivId = {1412.3690},
author = {Marinho, Marcelo and Sampaio, Suzana and Lima, Telma and de Moura, Hermano},
doi = {10.5121/ijsea.2014.5601},
eprint = {1412.3690},
file = {:Users/naubergois/Downloads/1412.3690.pdf:pdf},
issn = {09762221},
journal = {International Journal of Software Engineering {\&} Applications},
number = {6},
pages = {1--21},
title = {{A Systematic Review of Uncertainties in Software Project Management}},
url = {http://arxiv.org/abs/1412.3690},
volume = {5},
year = {2014}
}



@article{MatneiFilho2016,
abstract = {Mutation approaches have been recently applied for feature testing of Software Product Lines (SPLs). The idea is to select products, associated to mutation operators that describe possible faults in the Feature Model (FM). In this way, the operators and mutation score can be used to evaluate and generate a test set, that is a set of SPL products to be tested. However, the generation of test sets to kill all the mutants with a reduced, possible minimum, number of products is a complex task.},
author = {{Matnei Filho}, Rui A. and Vergilio, Silvia R.},
doi = {10.1186/s40411-016-0030-9},
file = {:Users/naubergois/Downloads/10.1186@s40411-016-0030-9.pdf:pdf},
issn = {2195-1721},
journal = {Journal of Software Engineering Research and Development},
keywords = {multi-objective optimization,mutation testing,software product line},
mendeley-groups = {Search-Based Tests/Multi objective tests/Multo-objective tests,Search-Based Tests/Multi objective tests/Multo-objective tests/Test Data,Metaheuristics/MultiObjective/spea2},
number = {1},
pages = {4},
publisher = {Journal of Software Engineering Research and Development},
title = {{A multi-objective test data generation approach for mutation testing of feature models}},
url = {http://jserd.springeropen.com/articles/10.1186/s40411-016-0030-9},
volume = {4},
year = {2016}
}

@article{Harman2015,
abstract = {Search Based Software Testing (SBST) formulates testing as an optimisation problem, which can be attacked using computational search techniques from the field of Search Based Software Engineering (SBSE). We present an analysis of the SBST research agenda1, focusing on the open problems and chal- lenges of testing non-functional properties, in particular a topic we call ‘Search Based Energy Testing' (SBET), Multi-objective SBST and SBST for Test Strategy Identification. We conclude with a vision of FIFIVERIFY tools, which would automatically find faults, fix them and verify the fixes. We explain why we think such FIFIVERIFY tools constitute an exciting challenge for the SBSE community that already could be within its reach.},
author = {Harman, Mark and Jia, Yue and Zhang, Yuanyuan},
isbn = {9781479971251},
journal = {8th IEEE International Conference on Software Testing, Verification and Validation (ICST)},
number = {Icst},
title = {{Achievements , open problems and challenges for search based software testing}},
url = {http://www0.cs.ucl.ac.uk/staff/mharman/icst15.pdf},
year = {2015}
}

@article{Illes2005,
author = {Illes, T and Herrmann, A and Paech, B and R{\"{u}}ckert, J},
file = {:Users/naubergois/Downloads/2005{\_}Criteria{\_}for{\_}Software{\_}Testing{\_}TIMEA.pdf:pdf},
mendeley-groups = {Load Test Tools},
pages = {213--222},
title = {{Criteria for Software Testing Tool Evaluation – A Task Oriented View}},
volume = {2},
year = {2005}
}


@article{Kitchenham2007,
abstract = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research. The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis.},
author = {Kitchenham, Barbara and Charters, S},
doi = {10.1145/1134285.1134500},
isbn = {1595933751},
issn = {00010782},
journal = {Engineering},
pages = {1051},
title = {{Guidelines for performing Systematic Literature Reviews in Software Engineering}},
volume = {2},
year = {2007}
}


@article{Lacour2015,
abstract = {We propose a new approach to the computation of the hypervolume indicator, based on partitioning the dominated region into a set of axis-parallel hyperrectangles or boxes. We present a nonincremental algorithm and an incremental algorithm, which allows insertions of points, whose time complexities are . O(n???p-12???+1) and . O(n???p2???+1), respectively, where . n is the number of points and . p is the dimension of the objective space. While the theoretical complexity of such a method is lower bounded by the complexity of the partition, which is, in the worst-case, larger than the best upper bound on the complexity of the hypervolume computation, we show that it is practically efficient. In particular, the nonincremental algorithm competes with the currently most practically efficient algorithms. Finally, we prove an enhanced upper bound of . O(np-1) and a lower bound of . ??(n???p2???logn) for . p???4 on the worst-case complexity of the WFG algorithm.},
archivePrefix = {arXiv},
arxivId = {1510.01963},
author = {Lacour, Renaud and Klamroth, Kathrin and Fonseca, Carlos M.},
doi = {10.1016/j.cor.2016.06.021},
eprint = {1510.01963},
file = {:Users/naubergois/Downloads/c352a4ba8594a381dbd91dcd588bd65bccfc.pdf:pdf},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Hypervolume indicator,Klee's measure problem,Multi-objective optimization},
mendeley-groups = {Metaheuristics/MultiObjective},
pages = {1--21},
title = {{A box decomposition algorithm to compute the hypervolume indicator}},
year = {2015}
}


@article{Zitzler1999,
abstract = {Evolutionary algorithms (EAs) are often well-suited for$\backslash$noptimization problems involving several, often conflicting objectives.$\backslash$nSince 1985, various evolutionary approaches to multiobjective$\backslash$noptimization have been developed that are capable of searching for$\backslash$nmultiple solutions concurrently in a single run. However, the few$\backslash$ncomparative studies of different methods presented up to now remain$\backslash$nmostly qualitative and are often restricted to a few approaches. In this$\backslash$npaper, four multiobjective EAs are compared quantitatively where an$\backslash$nextended 0/1 knapsack problem is taken as a basis. Furthermore, we$\backslash$nintroduce a new evolutionary approach to multicriteria optimization, the$\backslash$nstrength Pareto EA (SPEA), that combines several features of previous$\backslash$nmultiobjective EAs in a unique manner. It is characterized by (a)$\backslash$nstoring nondominated solutions externally in a second, continuously$\backslash$nupdated population, (b) evaluating an individual's fitness dependent on$\backslash$nthe number of external nondominated points that dominate it, (c)$\backslash$npreserving population diversity using the Pareto dominance relationship,$\backslash$nand (d) incorporating a clustering procedure in order to reduce the$\backslash$nnondominated set without destroying its characteristics. The$\backslash$nproof-of-principle results obtained on two artificial problems as well$\backslash$nas a larger problem, the synthesis of a digital hardware-software$\backslash$nmultiprocessor system, suggest that SPEA can be very effective in$\backslash$nsampling from along the entire Pareto-optimal front and distributing the$\backslash$ngenerated solutions over the tradeoff surface. Moreover, SPEA clearly$\backslash$noutperforms the other four multiobjective EAs on the 0/1 knapsack$\backslash$nproblem},
author = {Zitzler, E. and Thiele, L.},
doi = {10.1109/4235.797969},
file = {:Users/naubergois/Downloads/adafb5b55140fc03b95806b6d4ae195ea9b3.pdf:pdf},
isbn = {1089-778X},
issn = {1089-778X},
journal = {IEEE Transactions on Evolutionary Computation},
mendeley-groups = {Metaheuristics/MultiObjective},
number = {4},
pages = {257--271},
title = {{Multiobjective evolutionary algorithms: a comparative case study$\backslash$nand the strength Pareto approach}},
volume = {3},
year = {1999}
}

@article{Nachiyappan2015,
author = {Nachiyappan, S and Justus, S},
doi = {10.1016/j.procs.2015.04.018},
file = {:Users/naubergois/Downloads/nachiyappan2015.pdf:pdf},
issn = {1877-0509},
journal = {Procedia - Procedia Computer Science},
mendeley-groups = {Load Test Tools/Cloud,Load Test Tools/Blaze Meter,Load Test Tools/SOASTA,Load Test Tools/ITKO LISA,Load Test Tools/LoadRunner,Load Test Tools/Blitz},
pages = {482--489},
publisher = {Elsevier Masson SAS},
title = {{Cloud Testing Tools and Its Challenges : A Comparative Study}},
url = {http://dx.doi.org/10.1016/j.procs.2015.04.018},
volume = {50},
year = {2015}
}

@article{Giese1999,
abstract = {To ease the development of distributed systems, the visual notions for the structural aspects of object-oriented analysis and design should be combined with techniques for handling concurrency and distribution. A novel approach and language for the visual design of distributed software systems is introduced and illustrated by means of an example. The language of OCoNs (Object Coordination Nets) is integrated into the structuring mechanisms of the UML (Unified Modeling Language) standard for object-oriented analysis and design. Such an object-oriented notation is crucial for handling complex software systems and can be extended with the graphical expressive power of Petri nets to also describe concurrency and coordination. The same visual language is used to specify the interfaces and contracts of software components, the resource handling within a component as well as the control flow of services},
author = {Giese, H and Graf, J and Wirtz, G},
doi = {10.1109/VL.1999.795887},
file = {:Users/naubergois/Downloads/47266cad98d12a0ee18c41003b48f283f84d.pdf:pdf},
isbn = {1049-2615 VO -},
journal = {Visual Languages, 1999. Proceedings. 1999 IEEE Symposium on},
keywords = {Concurrent computing,Contracts,Electrical capacitance tomography,Handicapped aids,Microwave integrated circuits,OCoNs,Object Coordination Nets,Object oriented modeling,Petri nets,Software systems,UML standard,Unified Modeling Language,Unified modeling language,Workstations,complex software systems,concurrency,contract specification,contracts,coordination,distributed programming,distributed software systems development,graphical expressive power,interface specification,object-oriented analysis,object-oriented design,object-oriented languages,object-oriented methods,resource handling,seamless visual object-oriented behavior modeling,service control flow,software components,specification languages,structural aspects,structuring mechanisms,subroutines,visual design,visual language,visual languages},
mendeley-groups = {Model Based Test},
pages = {156--199},
title = {{Seamless visual object-oriented behavior modeling for distributed software systems}},
year = {1999}
}


@book{Marinescu2015,
abstract = {Software testing aims at gaining confidence in software products through fault detection, by observing the differences between the behavior of the implementation and the expected behavior described in the specification. Nowadays, testing is the main verification technique used in industry, being a time and resource consuming activity. This has boosted the development of potentially more efficient testing techniques, like model-based testing, where test creation and execution can be automated, using an abstract system model as input. In this chapter, we provide an overview of the state-of-the-art in tool-supported model-based testing that starts from requirements-based models, by presenting and classifying some of the most mature tools available at this moment. Our goal is to get a deeper insight into the state-of-the-art in this area, as well as to form a position with respect to possible needs and gaps in the current tools used by industry and academia, which need to be addressed in order to enhance the applicability of model-based testing techniques. To achieve this, we extend an existing taxonomy with: (i) the test artifact, representing the type of information encoded in the model for the purpose of testing (i.e., functional behavior, extra-functional behavior, or the architectural description), and (ii) the mapping of test cases, which describes ways of using the generated test cases on the actual system under test. To provide further evidence of the inner-workings of different model-based testing tools, we select four representative tools (i.e, ProTest, UPPAAL Cover, MaTeLo, and CompleteTest) that we apply on a simple yet illustrative Coffee/Tea Vending Machine example, to show the differences in modeling notations, test case generation methods, and the produced test-cases. {\textcopyright} 2015 Elsevier Inc.},
author = {Marinescu, Raluca and Seceleanu, Cristina and {Le Guen}, H{\`{e}}l{\'{e}}ne and Pettersson, Paul},
booktitle = {Advances in Computers},
doi = {10.1016/bs.adcom.2015.03.003},
file = {:Users/naubergois/Downloads/Advances in Computers-Elsevier-chapter -MSLeGP2015.pdf:pdf},
isbn = {9780128021323},
issn = {00652458},
keywords = {Classification,Formal modeling,Literature review,Model-based testing,Model-checking,Requirements-based design,Survey,Taxonomy,Tool support,Tools for model-based testing},
mendeley-groups = {Model Based Test},
number = {December},
pages = {89--140},
title = {{A Research Overview of Tool-Supported Model-based Testing of Requirements-based Designs}},
volume = {98},
year = {2015}
}



@book{utting2010practical,
  title={Practical model-based testing: a tools approach},
  author={Utting, Mark and Legeard, Bruno},
  year={2010},
  publisher={Morgan Kaufmann}
}

@article{janssens2010multiple,
  title={Multiple criteria performance analysis of non-dominated sets obtained by multi-objective evolutionary algorithms for optimisation},
  author={Janssens, Gerrit and Pangilinan, Jos{\'e}},
  journal={Artificial Intelligence Applications and Innovations},
  pages={94--103},
  year={2010},
  publisher={Springer}
}

@book{deb2001multi,
  title={Multi-objective optimization using evolutionary algorithms},
  author={Deb, Kalyanmoy},
  volume={16},
  year={2001},
  publisher={John Wiley \& Sons}
}

@article{Tervonen2017,
author = {Tervonen, Tommi and Kingdom, United},
doi = {10.1016/j.omega.2016.07.003},
file = {:Users/naubergois/Downloads/article.pdf:pdf},
mendeley-groups = {Metaheuristics/MultiObjective},
number = {April},
title = {{Evaluation of multi-objective optimization approaches for solving green supply chain design problems : Evaluation of multi-objective optimization approaches for solving green supply chain design problems}},
year = {2017}
}

@article{Zitzler2001,
abstract = {The Strength Pareto Evolutionary Algorithm(SPEA) (Zitzler and Thiele 1999) is a relatively recent technique for finding or approximating the Pareto-optimal set for multiobjective optimization problems. In different studies (Zitzler and Thiele 1999; Zitzler, Deb, and Thiele 2000) SPEA has shown very good performance in comparison to other multiobjective evolutionary algorithms, and therefore it has been a point of reference in various recent investigations, e.g., (Corne, Knowles, and Oates 2000). Furthermore, it has been used in different applications, e.g., (Lahanas, Milickovic, Baltas, and Zamboglou 2001). In this paper, an improved ver- sion, namely SPEA2, is proposed, which incorporates in contrast to its predecessor a fine-grained fitness assignment strategy, a density estimation technique, and an enhanced archive truncation method. The comparison of SPEA2 with SPEA and two other modern elitist methods, PESA and NSGA-II, on different test problems yields promising results. 1},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Zitzler, Eckart and Laumanns, Marco and Thiele, Lothar},
doi = {10.1.1.28.7571},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/P8.pdf:pdf},
isbn = {TIK-Report No. 103},
issn = {03772217},
journal = {Evolutionary Methods for Design Optimization and Control with Applications to Industrial Problems},
mendeley-groups = {Metaheuristics/MultiObjective},
pages = {95--100},
pmid = {15003161},
title = {{SPEA2: Improving the Strength Pareto Evolutionary Algorithm}},
year = {2001}
}


@book{Havelund2006,
author = {Havelund, Klaus and N{\'{u}}{\~{n}}ez, Manuel and Roşu, Grigore and Wolff, Burkhart},
booktitle = {Serious Games Development and Applications},
file = {:Users/naubergois/Downloads/Deterministic{\_}dynamic{\_}monitors{\_}for{\_}linea.pdf:pdf},
isbn = {9783642238338},
pages = {155},
title = {{Formal Approaches to Software Testing and Runtime Verification}},
url = {http://www.ulb.tu-darmstadt.de/tocs/79304567.pdf},
year = {2006}
}


@article{Blum2003,
abstract = {The emergence of metaheuristics for solving difficult combinatorial optimization problems is one of the most notable achievements of the last two decades in operations research. This paper provides an account of the most recent developments in the field and identifies some common issues and trends. Examples of applications are also reported for vehicle routing and scheduling problems.},
author = {Blum, C. and Roli, A.},
doi = {10.1007/s10479-005-3971-7},
file = {:Users/naubergois/Downloads/blum{\_}roli{\_}metaheuristics-preprint.pdf:pdf},
isbn = {0254-5330},
issn = {02545330},
journal = {ACM Computing Surveys},
keywords = {Combinatorial optimization,Metaheuristics,Unifying framework,Vehicle routing},
number = {3},
pages = {189--213},
title = {{Metaheuristics in combinatorial optimization: overview and conceptual comparison}},
volume = {35},
year = {2003}
}

@article{Aleti2016,
author = {Aleti, Aldeida and Moser, I. and Grunske, Lars},
doi = {10.1007/s10515-016-0197-7},
file = {:Users/naubergois/Downloads/JASE2016.pdf:pdf},
isbn = {1051501601},
issn = {15737535},
journal = {Automated Software Engineering},
keywords = {Fitness landscape characterisation,Genetic algorithms,Test data generation},
pages = {1--19},
title = {{Analysing the fitness landscape of search-based software testing problems}},
year = {2016}
}

@book{Hasan,
author = {Hasan, Tahsin},
file = {:Users/naubergois/Documents/Tahsin Hasan OpenCart 1.4 Template Design Cookbook.pdf:pdf},
isbn = {9781849514309},
title = {{OpenCart Template Design Cookbook}}
}
    


@article{ManuelLopez-IbanezJeremieDubois-LacosteLesliePerezCaceresMauroBirattari2016,
author = {{Manuel López-Ibãnez, Jérémie Dubois-Lacoste, Leslie Pérez Cáceres, Mauro Birattari}, Thomas Stutzle},
doi = {10.1016/j.orp.2016.09.002},
file = {:Users/naubergois/Documents/1-s2.0-S2214716015300270-main.pdf:pdf},
issn = {22147160},
journal = {Operations Research Perspectives},
keywords = {Automatic algorithm configuration,Parameter tuning,Racing},
pages = {43--58},
title = {{The irace package: Iterated racing for automatic algorithm configuration}},
volume = {3},
year = {2016}
}


@inproceedings{Meinke2010,
abstract = {We present an application of learning-based testing to the problem of automated test case generation (ATCG) for numerical software. Our approach uses n-dimensional polynomial models as an algorithmically learned abstraction of the SUT which supports n-wise testing. Test cases are iteratively generated by applying a satisfiability algorithm to first-order program specifications over real closed fields and iteratively refined piecewise polynomial models. We benchmark the performance of our iterative ATCG algorithm against iterative random testing, and empirically analyse its performance in finding injected errors in numerical codes. Our results show that for software with small errors, or long mean time to failure, learning-based testing is increasingly more efficient than iterative random testing. {\textcopyright} 2010 IFIP International Federation for Information Processing.},
author = {Meinke, Karl and Niu, Fei},
doi = {10.1007/978-3-642-16573-3_16},
file = {:Users/naubergois/Downloads/64350220.pdf:pdf},
isbn = {3642165729},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {221--235},
title = {{A learning-based approach to unit testing of numerical software}},
volume = {6435 LNCS},
year = {2010}
}


@inproceedings{Kamali2007,
abstract = {In traditional optimal control and design problems, the control gains and design parameters are usually derived to minimize a cost function reflecting the system performance and control effort. One major challenge of such approaches is the selection of weighting matrices in the cost function, which are usually determined via trial-and-error and human intuition. While various techniques have been proposed to automate the weight selection process, they either can not address complex design problems or suffer from slow convergence rate and high computational costs. We propose a layered approach based on Q-learning, a reinforcement learning technique, on top of genetic algorithms (GA) to determine the best weightings for optimal control and design problems. The layered approach allows for reuse of knowledge. Knowledge obtained via Q-learning in a design problem can be used to speed up the convergence rate of a similar design problem. Moreover, the layered approach allows for solving optimizations that cannot be solved by GA alone. To test the proposed method, we perform numerical experiments on a sample active-passive hybrid vibration control problem, namely adaptive structures with active-passive hybrid piezoelectric networks. These numerical experiments show that the proposed Q-learning scheme is a promising approach for automation of weight selection for complex design problems. (27 References).},
author = {Kamali, Kaivan and Jiang, L. J. and Yen, John and Wang, K. W.},
doi = {10.1115/1.2739502},
file = {:Users/naubergois/Downloads/kamali2007.pdf:pdf},
isbn = {0-7918-4739-X},
issn = {15309827},
journal = {Journal of Computing and Information Science in Engineering},
keywords = {genetic algorithms,optimal control,q-learning},
number = {December 2007},
pages = {302},
title = {{Using Q-Learning and Genetic Algorithms to Improve the Efficiency of Weight Adjustments for Optimal Control and Design Problems}},
volume = {7},
year = {2007}
}

	
@inproceedings{sato2015automatic,
  title={Automatic Generation of Specification-Based Test Cases by Applying Genetic Algorithms in Reinforcement Learning},
  author={Sato, Yuji and Sugihara, Taku},
  booktitle={International Workshop on Structured Object-Oriented Formal Language and Method},
  pages={59--71},
  year={2015},
  organization={Springer}
}	
	
@inproceedings{Boyan2000,
abstract = {This paper describes algorithms that learn to improve search performance on large-scale optimization tasks. The main algorithm, STAGE, works by learning an evaluation function that predicts the outcome of a local search algorithm, such as hillclimbing or Walksat, from features of states visited during search. The learned evaluation function is then used to bias future search trajectories toward better optima on the same problem. Another algorithm, X-STAGE, transfers previously learned evaluation functions to new, similar optimization problems. Empirical results are provided on seven large-scale optimization domains: bin-packing, channel routing, Bayesian network structure-finding, radiotherapy treatment planning, cartogram design, Boolean satisfiability, and Boggle board setup.},
author = {Boyan, Justin A. and Moore, Andrew W.},
file = {:Users/naubergois/Downloads/boyan00a.pdf:pdf},
issn = {1533-7928},
journal = {Journal of Machine Learning Research},
pages = {77--112},
title = {{Learning Evaluation Functions to Improve Local Search}},
url = {http://citeseer.nj.nec.com/boyan00learning.html},
volume = {1},
year = {2000}
}


@book{talbi2009metaheuristics,
  title={Metaheuristics: from design to implementation},
  author={Talbi, El-Ghazali},
  volume={74},
  year={2009},
  publisher={John Wiley \& Sons}
}

@book{Battiti2009,
abstract = {This book is about learning for problem solving. [...] Human problem solving is strongly connected to learning. Learning takes places when the problem at hand is not well known at the beginning, and its structure becomes more and more clear when more experience with the problem is available. [...] What is critical for men is critical also in many human-developed problem solving strategies. It is not surprising that many methods for solving problems in Artificial Intelligence, Operations Research and related areas, follow the search scheme [...] We aim at giving the main principles and at developing some fresh intuition for the approaches. We like mathematics but we also think that hiding the underlying motivations and sources of inspiration takes some color out of the scientific work [...]. On the other hand, pictures and hand-waving can be very dangerous in isolation and we try to avoid these pitfalls by giving also the basic equations when possible, or by at least directing the reader to the bibliographic references for deepening a topic. The point of view of the book is to look at the zoo of different optimization beasts to underline opportunities for learning and self-tuning strategies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Battiti, Roberto and Brunato, Mauro and Mascia, Franco},
booktitle = {Operations Research/ Computer Science Interfaces Series},
doi = {10.1007/978-0-387-09624-7},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/book{\_}reactive{\_}search{\_}and{\_}iIntelligent{\_} optimization.pdf:pdf},
isbn = {9780387096230},
issn = {1387666X},
pmid = {25246403},
title = {{Reactive search and intelligent optimization}},
volume = {45},
year = {2009}
}


@inproceedings{Smith2002,
author = {Smith, C.U. and Williams, L.G.},
file = {:Users/naubergois/Downloads/24fe255149e4fc0d7e1e8924c243a85dd676.pdf:pdf},
journal = {Cmg-Conference-},
pages = {797--806},
title = {{Software Performance AntiPatterns; Common Performance Problems and their Solutions}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.6968{\&}rep=rep1{\&}type=pdf},
volume = {2},
year = {2002}
}

@inproceedings{Bennett2006,
abstract = {The fields of machine learning and mathematical programming are increasingly intertwined. Optimization problems lie at the heart of most machine learning approaches. The Special Topic on Machine Learning and Large Scale Optimization examines this interplay. Machine learning researchers have embraced the advances in mathematical programming allowing new types of models to be pursued. The special topic includes models using quadratic, linear, second-order cone, semi-definite, and semi-infinite programs. We observe that the qualities of good optimization algorithms from the machine learning and optimization perspectives can be quite different. Mathematical programming puts a premium on accuracy, speed, and robustness. Since generalization is the bottom line in machine learning and training is normally done off-line, accuracy and small speed improvements are of little concern in machine learning. Machine learning prefers simpler algorithms that work in reasonable computational time for specific classes of problems. Reducing machine learning problems to well-explored mathematical programming classes with robust general purpose optimization codes allows machine learning researchers to rapidly develop new techniques. In turn, machine learning presents new challenges to mathematical programming. The special issue include papers from two primary themes: novel machine learning models and novel optimization approaches for existing models. Many papers blend both themes, making small changes in the underlying core mathematical program that enable the develop of effective new algorithms.},
archivePrefix = {arXiv},
arxivId = {math/0601771},
author = {Bennett, Kristin P},
doi = {10.1051/ps},
eprint = {0601771},
file = {:Users/naubergois/Downloads/MLOPT-intro06a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {convex optimization,machine learning,mathematical programming},
number = {November},
pages = {1265--1281},
primaryClass = {math},
title = {{The Interplay of Optimization and Machine Learning Research}},
url = {http://portal.acm.org/citation.cfm?id=1248593},
volume = {7},
year = {2006}
}


@inproceedings{Gambardella1995,
author = {Gambardella, Luca M and Dorigo, Marco},
file = {:Users/naubergois/Downloads/gambardella95-icml (1).pdf:pdf},
pages = {252--260},
title = {{Ant-Q : A Reinforcement Learning approach to the traveling salesman problem}},
volume = {5625},
year = {1995}
}

@inproceedings{Matsuura2015,
author = {Matsuura, Jackson and Bianchi, Reinaldo A C},
file = {:Users/naubergois/Downloads/sbia2815.pdf:pdf},
number = {March},
title = {{Heuristically Accelerated Q – Learning : a new approach to speed up Reinforcement Learning}},
year = {2015}
}




@inproceedings{Wang2013,
author = {Wang, Xingen and Zhou, Bo and Li, Wei},
doi = {10.1080/02533839.2012.726028},
file = {:Users/naubergois/Downloads/wang2013.pdf:pdf},
issn = {0253-3839},
journal = {Journal of the Chinese Institute of Engineers},
keywords = {Model Based Test,Stress testing,load testing,markov chains,usage model},
number = {1},
pages = {74--86},
title = {{Model-based load testing of web applications}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02533839.2012.726028},
volume = {36},
year = {2013}
}


@inproceedings{Baars2011,
abstract = {The Future Internet will be a complex interconnection$\backslash$nof services, applications, content and media, on which$\backslash$nour society will become increasingly dependent. Time to$\backslash$nmarket is crucial in Internet applications and hence$\backslash$nrelease cycles grow ever shorter. This, coupled with$\backslash$nthe highly dynamic nature of the Future Internet will$\backslash$nplace new demands on software testing. Search-Based$\backslash$nTesting is ideally placed to address these emerging$\backslash$nchallenges. Its techniques are highly flexible and$\backslash$nrobust to only partially observable systems. This paper$\backslash$npresents an overview of Search-Based Testing and$\backslash$ndiscusses some of the open challenges remaining to make$\backslash$nsearch-based techniques applicable to the Future$\backslash$nInternet.},
author = {Baars, Arthur I and Lakhotia, Kiran and Vos, Tanja E J and Wegener, Joachim},
file = {:Users/naubergois/Downloads/fedcsis11.pdf:pdf},
isbn = {9788360810392},
journal = {Federated Conference on Computer Science and Information Systems (FedCSIS 2011)},
keywords = {Evolutionary computation,Internet,Optimisation,SBSE,Search Based Test,Search problems,Software,Testing,evolutionary testing,future Internet testing,genetic algorithms,genetic programming,search-based testing,software testing,time to market},
pages = {917--923},
title = {{Search-based testing, the underlying engine of Future Internet testing}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=6078178},
year = {2011}
}


@inproceedings{Brown2003,
author = {Brown, Matthew a and Tapolcsanyi, Eli},
file = {:Users/naubergois/Downloads/Brown-mock-objects.pdf:pdf},
journal = {Matrix},
pages = {1--17},
title = {{Mock Object Patterns}},
year = {2003}
}


@inproceedings{Hunt2002,
author = {Hunt, Editors Andy and Thomas, Dave and Pragmatic, I The and Hunt, Andy and Mackinnon, Tim and Freeman, Steve},
doi = {10.1109/MS.2004.1259177},
file = {:Users/naubergois/Downloads/may{\_}02{\_}mock.pdf:pdf},
issn = {0740-7459},
journal = {Ieee Software},
number = {June},
pages = {22--24},
title = {{Software Construction}},
year = {2002}
}

@inproceedings{Bertolino2008,
isbn = {978-3-540-68514-2, 978-3-540-68524-1},
issn = {978-3-540-68514-2},
journal = {Testing of Software and},
pages = {266--282},
title = {Model-based generation of testbeds for web services},
year = {2008}
}

@book{GendreauMichelandPotvin2010,
author = {{Gendreau, Michel and Potvin}, Jean-Yves},
doi = {10.1007/978-1-4614-1900-6},
file = {:Users/naubergois/Downloads/Artificial{\_}Immune{\_}Systems.pdf:pdf},
isbn = {9781441979605},
title = {{Handbook of Metaheuristics}},
volume = {157},
year = {2010}
}




@inproceedings{Mackinnon2001,
abstract = {Unit testing is a fundamental practice in Extreme Programming, but most non-trivial code is difficult to test in isolation. It is hard to avoid writing test suites that are complex, incomplete, and difficult to maintain and interpret. Using Mock Objects for unit testing improves both domain code and test suites. They allow unit tests to be written for everything, simplify test structure, and avoid polluting domain code with testing infrastructure.},
author = {Mackinnon, Tim and Freeman, Steve and Craig, Philip},
file = {:Users/naubergois/Downloads/mockobjects.pdf:pdf},
isbn = {0201710404},
journal = {Extreme programming examined},
keywords = {extreme programming,mock objects,stubs,unit testing},
pages = {287--301},
title = {{Endo-Testing : Unit Testing with Mock Objects}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.3214{\&}rep=rep1{\&}type=pdf},
year = {2001}
}



@inproceedings{Wert2013a,
abstract = {Performance problems pose a significant risk to software vendors. If left undetected, they can lead to lost customers, increased operational costs, and damaged reputation. Despite all efforts, software engineers cannot fully prevent performance problems being introduced into an application. Detecting and resolving such problems as early as possible with minimal effort is still an open challenge in software performance engineering. In this paper, we present a novel approach for Performance Problem Diagnostics (PPD) that systematically searches for well-known performance problems (also called performance antipatterns) within an application. PPD automatically isolates the problem's root cause, hence facilitating problem solving. We applied PPD to a well established transactional web e-Commerce benchmark (TPC-W) in two deployment scenarios. PPD automatically identified four performance problems in the benchmark implementation and its deployment environment. By fixing the problems, we increased the maximum throughput of the benchmark from 1800 requests per second to more than 3500.},
author = {Wert, Alexander and Happe, Jens and Happe, Lucia},
doi = {10.1109/ICSE.2013.6606601},
file = {:Users/naubergois/Downloads/ICSE-2013-PerformanceProblemDiagnostics.pdf:pdf},
isbn = {9781467330763},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {measurement,performance,problem detection},
number = {May},
pages = {552--561},
title = {{Supporting swift reaction: Automatically uncovering performance problems by systematic experiments}},
year = {2013}
}

@inproceedings{Smith2003,
abstract = {Performance antipatterns document common software performance problems as well as their solutions. These problems are often introduced during the architectural or design phases of software development, but not detected until later in testing or deployment. Solutions usually require software changes as opposed to system tuning changes. This paper presents three new performance antipatterns and gives examples to illustrate them. These antipatterns will help developers and performance engineers avoid common perfor- mance problems. 1.0},
author = {Smith, Connie U and Williams, Lloyd G},
file = {:Users/naubergois/Downloads/moreanti.pdf:pdf},
journal = {Computer Measurement Group Conference},
pages = {717--725},
title = {{More New Software Performance AntiPatterns: EvenMore Ways to Shoot Yourself in the Foot}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.4517{\&}rep=rep1{\&}type=pdf},
year = {2003}
}



@inproceedings{Glover1986,
abstract = {Tabu Search is a meta-heuristic that guides a local heuristic search procedure to explore the solution space beyond local optimality. One of the main components of Tabu Search of Tabu Search is its use of adaptive memory, which creates a more flexible search behavior.},
author = {Glover, Fred and Mart{\'{i}}, Rafael},
file = {:Users/naubergois/Downloads/ts2.pdf:pdf},
journal = {Tabu Search},
pages = {1--16},
title = {{Tabu Search}},
year = {1986}
}

@inproceedings{Gay,
author = {Gay, Gregory},
file = {:Users/naubergois/Downloads/16mockito.pdf:pdf},
keywords = {automated unit test generation,real faults,search-based testing},
pages = {1--6},
title = {{Challenges in Using Search-Based Test Generation to Identify Real Faults in Mockito}}
}


@inproceedings{Wert2014,
abstract = {Performance problems such as high response times in software applications have a significant effect on the customer's satisfaction. In enterprise applications, performance problems are frequently manifested in inefficient or unnecessary communication patterns between software components originating from poor architectural design or implementation. Due to high manual effort, thorough performance analysis is often neglected, in practice. In order to overcome this problem, automated engineering approaches are required for the detection of performance problems. In this paper, we introduce several heuristics for measurement-based detection of well-known performance anti-patterns in inter-component communications. The detection heuristics comprise load and instrumentation descriptions for performance tests as well as corresponding detection rules. We integrate these heuristics with Dynamic Spotter, a framework for automatic detection of performance problems. We evaluate our heuristics on four evaluation scenarios based on an e-commerce benchmark (TPC-W) where the heuristics detect the expected communication performance anti-patterns and pinpoint their root causes. Copyright {\&}copy; 2014 ACM 978-1-4503-2577-6/14/06 ...{\$}15.00.},
author = {Wert, Alexander and Oehler, Marius and Heger, Christoph and Farahbod, Roozbeh},
doi = {10.1145/2602576.2602579},
file = {:Users/naubergois/Downloads/2014-qosa-messaging.pdf:pdf},
isbn = {9781450325776},
journal = {QoSA 2014 - Proceedings of the 10th International ACM SIGSOFT Conference on Quality of Software Architectures (Part of CompArch 2014)},
keywords = {Application programs;Customer satisfaction;},
pages = {3--12},
title = {{Automatic detection of performance anti-patterns in inter-component communications}},
url = {http://dx.doi.org/10.1145/2602576.2602579},
year = {2014}
}

@inproceedings{Arcelli2012,
abstract = {Identifying and removing the causes of poor performance in software systems are complex problems due to a variety of factors to take into account. Nowadays these problems are usually tackled after the software deployment only with human-based means, which frequently boil down to developer skills and previous experiences. Performance antipatterns can be used to cope with these problems since they capture typical design patterns that are known leading to performance problems, as well as refactoring actions that can be taken to remove them. The goal of this paper is to introduce an approach that allows the refactoring of architectural models, based on antipatterns, that aims at providing performance improvement. To this end, we use a Role-Based Modeling Language to represent: (i) antipattern problems as Source Role Models (SRMs), and (ii) antipattern solutions as Target Role Models (TRMs). Hence, SRM-TRM pairs represent new instruments in the hands of developers to achieve architectural model refactorings aimed at removing sources of performance problems. Model refactoring for antipattern removal can be in fact obtained by replacing an SRM with the corresponding TRM. This approach has been applied to a case study in the e-commerce domain, whose experimental results demonstrate its effectiveness. Copyright {\textcopyright} 2012 ACM.},
author = {Arcelli, Davide and Cortellessa, Vittorio and Trubiani, Catia},
doi = {10.1145/2304696.2304704},
file = {:Users/naubergois/Downloads/antipatterns-QoSA-2012.pdf:pdf},
isbn = {9781450313469},
journal = {Proceedings of the 8th international ACM SIGSOFT conference on Quality of Software Architectures (QoSA '12)},
keywords = {model refactoring,performance an-,software performance},
pages = {33--42},
title = {{Antipattern-Based Model Refactoring for Software Performance Improvement}},
url = {http://doi.acm.org/10.1145/2304696.2304704},
year = {2012}
}

@inproceedings{Cortellessa2007,
author = {Cortellessa, Vittorio and Frittella, Laurento},
file = {:Users/naubergois/Downloads/10.1007@978-3-540-75211-013.pdf:pdf},
keywords = {architectural,feedback,layered queueing networks,performance indices,software performance},
pages = {171--185},
title = {{A Framework for Automated Generation of Architectural Feedback from Software Performance Analysis}},
year = {2007}
}

@inproceedings{Smith2000,
author = {Smith, Connie U. and Williams, Lloyd G.},
doi = {10.1145/350391.350420},
file = {:Users/naubergois/Downloads/antipat.pdf:pdf},
isbn = {158113195X},
journal = {Proceedings of the second international workshop on Software and performance  - WOSP '00},
pages = {127--136},
title = {{Software performance antipatterns}},
url = {http://portal.acm.org/citation.cfm?doid=350391.350420},
year = {2000}
}



@book{Halili2008,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Halili, Emily H.},
booktitle = {PACKT Publishing},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {jmeter},
pmid = {25246403},
title = {{Apache JMeter: A practical beginner's guide to automated testing and performance measurement for your websites.}},
year = {2008}
}

@inproceedings{Aleti2016,
author = {Aleti, Aldeida and Moser, I. and Grunske, Lars},
doi = {10.1007/s10515-016-0197-7},
isbn = {1051501601},
issn = {15737535},
journal = {Automated Software Engineering},
keywords = {Fitness landscape characterisation,Genetic algorithms,Test data generation},
pages = {1--19},
title = {{Analysing the fitness landscape of search-based software testing problems}},
year = {2016}
}


@book{Jaziri2008,
author = {Jaziri, Wassim},
isbn = {9783902613349},
pages = {294},
title = {{Local Search Techniques: Focus on Tabu Search}},
year = {2008}
}


@inproceedings{Blum2003,
abstract = {The emergence of metaheuristics for solving difficult combinatorial optimization problems is one of the most notable achievements of the last two decades in operations research. This paper provides an account of the most recent developments in the field and identifies some common issues and trends. Examples of applications are also reported for vehicle routing and scheduling problems.},
author = {Blum, C. and Roli, A.},
doi = {10.1007/s10479-005-3971-7},
isbn = {0254-5330},
issn = {02545330},
journal = {ACM Computing Surveys},
keywords = {Combinatorial optimization,Metaheuristics,Unifying framework,Vehicle routing},
number = {3},
pages = {189--213},
title = {{Metaheuristics in combinatorial optimization: overview and conceptual comparison}},
volume = {35},
year = {2003}
}


@incollection{raidl2010metaheuristic,
  title={Metaheuristic hybrids},
  author={Raidl, G{\"u}nther R and Puchinger, Jakob and Blum, Christian},
  booktitle={Handbook of metaheuristics},
  pages={469--496},
  year={2010},
  publisher={Springer}
}

@inproceedings{DiAlesio2014,
		author = {Di Alesio, Stefano and Nejati, Shiva and Briand, Lionel and Gotlieb, Arnaud},
	journal = {Principles and Practice of Constraint Programming},
	pages = {813--830},
	  year={2014},
	Title = {{Worst-Case Scheduling of Software Tasks -- A Constraint Optimization Model to Support Performance Testing}}
	}

@inproceedings{DiAlesio2013,
	Abstract = {Safety-critical Real Time Embedded Systems (RT-ESs) are usually subject to strict timing and performance requirements that must be satisfied for the system to be deemed safe. In this paper, we use effective search strategies whose goal is finding worst case scenarios with respect to deadline misses. Such scenarios can in turn be used to test the target RTES and ensure that it satisfies its timing requirements even under worst case conditions. Specifically, we develop an approach based on Constraint Programming (CP) to automate the generation of test cases that reveal, or are likely to, task deadline misses. We evaluate it through a comparison with a state-of-the-art approach based on Genetic Algorithms (GA). In particular, we compare CP and GA in five case studies for efficiency, effectiveness, and scalability. Our experimental results show that, on the largest and more complex case studies, CP performs significantly better than GA. Furthermore, CP offers some advantages over GA, such as it guarantees a complete search when there is sufficient time, and, being deterministic, it doesn't rely on parameters that potentially have a significant effect on the search and therefore need to be tuned. Hence, we conclude that our results are encouraging and suggest this is an advantageous approach for stress testing of RTESs with respect to timing constraints.},
	Author = {{Di Alesio}, S and Nejati, S and Briand, L and Gotlieb, A},
	Doi = {10.1109/ISSRE.2013.6698915},
	File = {:Users/naubergois/Documents/10.0000@www.computer.org@generic-DD33B05EC8B4.pdf:pdf},
	Isbn = {9781479923663},
	Journal = {IEEE Xplore},
	Keywords = {constraint pro-,real-time systems,stress testing},
	Pages = {158--167},
	Title = {{Stress testing of task deadlines: A constraint programming approach}},
	Year = {2013}}

@inproceedings{Alesio2015,
	Author = {Alesio, Stefano D I and Briand, Lionel C and Nejati, Shiva and Gotlieb, Arnaud},
	File = {:Users/naubergois/Documents/a4-dialesio.pdf:pdf},
	Journal = {ACM Transactions on Software Engineering and Methodology},
	Number = {1},
	Title = {{Combining Genetic Algorithms and Constraint Programming}},
	Volume = {25},
	Year = {2015}}

@inproceedings{Raidl2006,
	Author = {Raidl, R},
	Isbn = {9783540463849},
	Issn = {03029743},
	Journal = {Hybrid Metaheuristics (LNCS 4030)},
	Pages = {1--12},
	Title = {{A Unified View on Hybrid Metaheuristics}},
	Year = {2006}}

@inproceedings{Pohlheim2005,
	Abstract = {Whereas the verification of non-safety-related embedded software typically focuses on demonstrating that the implementation fulfills its functional requirements, this is not sufficient for safety-relevant systems. In this case, the control software must also meet application- specific safety requirements.Safety requirements typically arise from the application of hazard and/or safety analysis techniques, e.g., FMEA, FTA or SHARD. During the downstream development process it must be shown that these requirements cannot be violated. This can be achieved utilizing different techniques. One way of providing evidence that violations of the safety properties identified cannot occur is to thoroughly test each of the safety requirements.This paper introduces Evolutionary Safety Testing (EST), a fully automated procedure for the safety testing of embedded control software. EST employs extended evolutionary algorithms in an optimization process which aggressively tries to find test data sequences that cause the test object to violate a given safety requirement.A compact description formalism for input sequences for safety testing is presented, which is compatible with description techniques used during other test process stages. This compact description allows 1) an efficient application of evolutionary algorithms (and other optimization techniques) and 2) the description of long test sequences necessary for the adequate stimulation of real-world systems. The objective function is designed in such a way that optimal values represent test data sequences which violate a given safety requirement. By means of repeated input sequence generation, software execution and the subsequent evaluation of the objective function each safety requirement is extensively tested.The use of EST for the safety testing of automotive control software is demonstrated using safety requirements of an adaptive cruise control (ACC) system.The EST approach can easily be integrated into an overall software test strategy which combines different test design techniques with specific test objectives.},
	Author = {Pohlheim, Hartmut and Conrad, Mirko and Griep, Arne},
	Doi = {10.4271/2005-01-0750},
	Journal = {Analysis},
	Number = {724},
	Pages = {804----814},
	Title = {{Evolutionary Safety Testing of Embedded Control Software by Automatically Generating Compact Test Data Sequences}},
	Year = {2005}}

@inproceedings{Gross2000,
	Abstract = {Software architecture design approaches typically treat architecture as an abstraction of the implemented system. However, doing so means that the concepts, languages, notations, and tools for architecture are much more closely related to those of detailed design and implementation than to those of software requirements. Thus the gap between requirements and architecture represents a paradigm shift, while that between architecture and detailed design does not. Global Analysis, which is part of the Siemens Four Views architecture design approach, is a set of activities that serves to reduce the magnitude of this gap by guiding the architecture design process, capturing design rationale, and supporting traceability between requirements and architecture. In this paper Global Analysis is re-examined in light of five years of teaching it, reflecting on it, comparing it to other approaches, and examining how it was applied in four new systems. This experience confirms the value of the Global Analysis activities and the importance of capturing its results. In some cases the benefit went beyond that envisioned, and in other cases Global Analysis was not applied as expected. Because the templates that are provided for Global Analysis results have such a strong influence on how the activities were performed, this will be the focus of future changes},
	Author = {Gross, Hg and Jones, Bryan F and Eyres, David E},
	Doi = {10.1049/ip-sen},
	File = {:Users/naubergois/Documents/gross2000.pdf:pdf},
	Isbn = {0818669101},
	Issn = {14625970},
	Journal = {Software, IEE Proceedings-},
	Number = {2},
	Pages = {25--30},
	Pmid = {18015135},
	Title = {{Structural performance measure of evolutionary testing applied to worst-case timing of real-time systems}},
	Volume = {147},
	Year = {2000}}

@inproceedings{Smeral2014,
	Author = {\v{S}meral, Ron},
	File = {:Users/naubergois/Dropbox/dp.pdf:pdf},
	Title = {{Modern Performance Tools Applied}},
	Year = {2014}}

@inproceedings{Puchinger2005,
	Abstract = {In this survey we discuss different state-of-the-art approaches of combining exact algorithms and metaheuristics to solve combinatorial optimization problems. Some of these hybrids mainly aim at providing optimal solutions in shorter time, while others primarily focus on getting better heuristic solutions. The two main categories in which we divide the approaches are collaborative versus integrative combinations.We further classify the different techniques in a hierarchical way. Altogether, the surveyed work on combinations of exact algorithms and metaheuristics documents the usefulness and strong potential of this research direction.},
	Author = {Puchinger, Jakob and Raidl, R},
	Doi = {10.1007/11499305\_5},
	File = {:Users/naubergois/Documents/puchinger-05.pdf:pdf},
	Isbn = {9783540263197},
	Issn = {03029743},
	Journal = {Artificial Intelligence and Knowledge Engineering Applications a Bioinspired Approach},
	Pages = {41--53},
	Title = {{Combining Metaheuristics and Exact Algorithms in Combinatorial Optimization : A Survey and Classification}},
	Volume = {3562},
	Year = {2005}}

@inproceedings{Blum2012,
	Abstract = {Research in metaheuristics for combinatorial optimization problems has lately experienced a noteworthy shift towards the hybridization of metaheuristics with other techniques for optimization. At the same time, the focus of research has changed from being rather algorithm-oriented to being more problem-oriented. Nowadays the focus is on solving the problem at hand in the best way possible, rather than promoting a certain metaheuristic. This has led to an enormously fruitful cross-fertilization of different areas of optimization. This cross-fertilization is documented by a multitude of powerful hybrid algorithms that were obtained by combining components from several different optimization techniques. Hereby, hybridization is not restricted to the combination of different metaheuristics but includes, for example, the combination of exact algorithms and metaheuristics. In this work we provide a survey of some of the most important lines of hybridization. The literature review is accompanied by the presentation of illustrative examples. {\copyright} 2010 Elsevier B.V. All rights reserved.},
	Author = {Blum, Christian},
	Doi = {10.1007/978-3-642-33860-1\_1},
	File = {:Users/naubergois/Documents/blum-11.pdf:pdf},
	Isbn = {9783642338595},
	Issn = {03029743},
	Journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	Keywords = {combinatorial optimization,hybrid metaheuristics},
	Number = {6},
	Pages = {1--10},
	Publisher = {Elsevier B.V.},
	Title = {{Hybrid metaheuristics in combinatorial optimization: A tutorial}},
	Volume = {7505 LNCS},
	Year = {2012}}

@inproceedings{Wang2010,
	Author = {Wang, Xingen and Zhou, Bo and Li, Wei},
	Doi = {10.1109/ISPA.2010.24},
	File = {:Users/naubergois/Dropbox/WangXingen-ISPA2010.pdf:pdf},
	Isbn = {978-1-4244-8095-1},
	Journal = {International Symposium on Parallel and Distributed Processing with Applications},
	Keywords = {load model,load testing,markov chains,model,performance engineering,usage},
	Pages = {483--490},
	Title = {{Model Based Load Testing of Web Applications}},
	Year = {2010}}

@book{Smith:2012qr,
	Author = {Smith, J.~M. and Jones, A.~B.},
	Edition = {7th},
	Publisher = {Publisher},
	Title = {{B}ook {T}itle},
	Year = {2012}}

@inproceedings{Smith:2013jd,
	Author = {Jones, A.~B. and Smith, J.~M.},
	Journal = {{J}ournal {T}itle},
	Month = {March},
	Number = {52},
	Pages = {123-456},
	Publisher = {Publisher},
	Title = {{A}rticle {T}itle},
	Volume = {13},
	Year = {2013}}

@inproceedings{Tlili1917,
	Author = {Tlili, Marouane and Wappler, Stefan and Sthamer, Harmen},
	Isbn = {1595931864},
	Journal = {Technology},
	Keywords = {daimler-,harmen,sthamer},
	Pages = {1917--1924},
	Title = {{Improving Evolutionary Real-Time Testing}},
	Year = {1917}}

@phdthesis{Jiang2010,
	Author = {Jiang, ZM},
	Booktitle = {\ldots symposium on Software testing and analysis},
	Title = {{Automated analysis of load testing results}},
	Url = {http://dl.acm.org/citation.cfm?id=1831726},
	Year = {2010}}

@inproceedings{Jiang2009,
	Abstract = {The goal of a load test is to uncover functional and per- formance problems of a system under load. Performance problems refer to the situations where a system suffers from unexpectedly high response time or low throughput. It is difficult to detect performance problems in a load test due to the absence of formally-defined performance objectives and the large amount of data that must be examined. In this paper, we present an approach which automati- cally analyzes the execution logs of a load test for perfor- mance problems. We first derive the system's performance baseline from previous runs. Then we perform an in-depth performance comparison against the derived performance baseline. Case studies show that our approach produces few false alarms (with a precision of 77\%) and scales well to large industrial systems.},
	Author = {Jiang, ZM and Hassan, AE},
	Journal = {\ldots , 2009. ICSM 2009. IEEE \ldots},
	Title = {{Automated performance analysis of load tests}},
	Year = {2009}}

@inproceedings{Afzal2009a,
	Abstract = {Search-based software testing is the application of metaheuristic search techniques to generate software tests. The test adequacy criterion is transformed into a fitness function and a set of solutions in the search space are evaluated with respect to the fitness function using a metaheuristic search technique. The application of metaheuristic search techniques for testing is promising due to the fact that exhaustive testing is infeasible considering the size and complexity of software under test. Search-based software testing has been applied across the spectrum of test case design methods; this includes white-box (structural), black-box (functional) and grey-box (combination of structural and functional) testing. In addition, metaheuristic search techniques have also been applied to test non-functional properties. The overall objective of undertaking this systematic review is to examine existing work into non-functional search-based software testing (NFSBST). We are interested in types of non-functional testing targeted using metaheuristic search techniques, different fitness functions used in different types of search-based non-functional testing and challenges in the application of these techniques. The systematic review is based on a comprehensive set of 35 articles obtained after a multi-stage selection process and have been published in the time span 1996-2007. The results of the review show that metaheuristic search techniques have been applied for non-functional testing of execution time, quality of service, security, usability and safety. A variety of metaheuristic search techniques are found to be applicable for non-functional testing including simulated annealing, tabu search, genetic algorithms, ant colony methods, grammatical evolution, genetic programming (and its variants including linear genetic programming) and swarm intelligence methods. The review reports on different fitness functions used to guide the search for each of the categories of execution time, safety, usability, quality of service and security; along with a discussion of possible challenges in the application of metaheuristic search techniques. ?? 2009 Elsevier B.V. All rights reserved.},
	Author = {Afzal, Wasif and Torkar, Richard and Feldt, Robert},
	Doi = {10.1016/j.infsof.2008.12.005},
	File = {:Users/naubergois/Dropbox/X12-searchbased-testing-afzal-ist09.pdf:pdf},
	Isbn = {0950-5849},
	Issn = {09505849},
	Journal = {Information and Software Technology},
	Keywords = {Non-functional system properties,Search-based software testing,Systematic review},
	Number = {6},
	Pages = {957--976},
	Publisher = {Elsevier B.V.},
	Title = {{A systematic review of search-based testing for non-functional system properties}},
	Volume = {51},
	Year = {2009}}

@inproceedings{Stations,
	Author = {{Wegener, Joachim and Pitschinetz, Roman and Sthamer}, Harmen},
	Journal = {Proceedings of the 1st International Workshop on Automated Program Analysis, Testing and Verification (WAPATV'00)},
	Title = {{Automated Testing of Real-Time Tasks}},
	Year = {2000}}

@inproceedings{Nevedrov2007,
	Author = {Nevedrov, Dmitri},
	Pages = {1--11},
	Title = {{Using JMeter to Performance Test Web Services}},
	Year = {2007}}

@book{Molyneaux2009,
	Author = {Molyneaux, Ian},
	Isbn = {9780596551056},
	Keywords = {COMPUTERS / Computer Literacy,COMPUTERS / Computer Science,COMPUTERS / Data Processing,COMPUTERS / Hardware / General,COMPUTERS / Machine Theory,COMPUTERS / Reference,Computers / Information Technology,Computers / Software Development \& Engineering / G,Computers / Software Development \& Engineering / S,Computers / Web / Design},
	Language = {en},
	Mendeley-Tags = {COMPUTERS / Computer Literacy,COMPUTERS / Computer Science,COMPUTERS / Data Processing,COMPUTERS / Hardware / General,COMPUTERS / Machine Theory,COMPUTERS / Reference,Computers / Information Technology,Computers / Software Development \& Engineering / G,Computers / Software Development \& Engineering / S,Computers / Web / Design},
	Month = jan,
	Pages = {159},
	Publisher = {"O'Reilly Media, Inc."},
	Shorttitle = {The Art of Application Performance Testing},
	Title = {{The Art of Application Performance Testing: Help for Programmers and Quality Assurance}},
	Year = {2009},
	edition  = {1st}}

@inproceedings{Sullivan,
	Author = {Sullivan, Michael O and V\"{o}ssner, Siegfried and Wegener, Joachim and Ag, Daimler-benz},
	File = {:Users/naubergois/Dropbox/eurostar1998.pdf:pdf},
	Pages = {1--20},
    Year = {1998},
	Title = {{Testing Temporal Correctness of Real-Time Systems --- A New Approach Using Genetic Algorithms and Cluster Analysis ---}}}

@inproceedings{Draheim2006b,
	Author = {Draheim, D. and Grundy, J. and Hosking, J. and Lutteroth, C. and Weber, G.},
	Booktitle = {Conference on Software Maintenance and Reengineering (CSMR'06)},
	Doi = {10.1109/CSMR.2006.43},
	Isbn = {0-7695-2536-9},
	Issn = {1052-8725},
	Title = {{Realistic load testing of Web applications}},
	Year = {2006}}


@inproceedings{Vetoio2011,
author = {Vetoio, Via},
file = {:Users/naubergois/Downloads/PhDThesis-CatiaTrubiani.pdf:pdf},
journal = {Language},
title = {{PhD Thesis in Computer Science Automated generation of architectural feedback from software performance analysis results Catia Trubiani}},
year = {2011}
}

	
	
@book{brown1998antipatterns,
  title={AntiPatterns: refactoring software, architectures, and projects in crisis},
  author={Brown, William H and Malveau, Raphael C and McCormick, Hays W and Mowbray, Thomas J},
  year={1998},
  publisher={John Wiley \& Sons, Inc.}
}
	
@inproceedings{Gois2016,
	Author = {Gois, N. and Porfirio, P. and Coelho, A. and Barbosa, T.},
	Booktitle = {Proceedings of the 2016 Latin American Computing Conference (CLEI)},
	Isbn = {978-1-5090-1632-7},
	Title = {{Improving Stress Search Based Testing using a Hybrid Metaheuristic Approach}},
	Pages = {718--728},
	Year = {2016}}	
	

@phdthesis{Luiz2011,
	Author = {Luiz, Artur and Freitas, Cunha and Prof, Orientadora and Vieira, Renata},
	School = {Pontif{\'\i}cia Universidade Cat{\'o}lica do Rio Grande do Sul},
	Title = {{Ontologias para Teste de Desempenho de Software}},
	Year = {2011}}

@inproceedings{Fe2004,
	Author = {F\'{e}, Iure De Sousa and dos Santos, Pedro de Alc\^{a}ntara},
	Title = {{Os custos dos Testes de Desempenho e Estresse}},
	Year = {2004}}

@inproceedings{Babbar2011,
	Author = {Babbar, C and Bajpai, N and Sarmah, Dk},
	Title = {{Web Application Performance Analysis based on Component Load Testing}},
	Isbn = {9789380544007},
	Journal = {International Journal of Technology},
	Shorttitle= {Web Application Performance Analysis based on Component Load Testing}, 
	Year = {2011}}

@inproceedings{Avritzer1995,
	Author = {Avritzer, A. and Weyuker, E.J.},
	Issn = {0098-5589},
	Journal = {Software Engineering, IEEE \ldots},
	Keywords = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
	Mendeley-Tags = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
	Number = {9},
	Pages = {705--716},
	Title = {{The automatic generation of load test suites and the assessment of the resulting software}},
	Volume = {21},
	Year = {1995}}

@inproceedings{Garousi2010,
	Author = {Garousi, Vahid},
	Doi = {10.1109/TSE.2010.5},
	Issn = {0098-5589},
	Journal = {IEEE Transactions on Software Engineering},
	Keywords = {empirical analysis,genetic algorithms,search-based testing,stress testing,test automation,test tools},
	Month = nov,
	Number = {6},
	Pages = {778--797},
	Title = {{A Genetic Algorithm-Based Stress Test Requirements Generator Tool and Its Empirical Evaluation}},
	Volume = {36},
	Year = {2010}}

@inproceedings{Avritzer1993d,
	Address = {New York, NY, USA},
	Annote = {From Duplicate 1 ( },
	Author = {Avritzer, Alberto and Larson, Brian},
	Booktitle = {ACM SIGSOFT Software Engineering Notes},
	Doi = {10.1145/154183.154244},
	Isbn = {0-89791-608-5},
	Pages = {82--88},
	Publisher = {ACM},
	Series = {ISSTA '93},
	Title = {{Load Testing Software Using Deterministic State Testing}},
	Year = {1993}}

@inproceedings{Avritzer1994,
	Address = {New York, New York, USA},
	Author = {Avritzer, Alberto and Weyuker, EJ},
	Doi = {10.1145/186258.186507},
	Isbn = {0897916832},
	Journal = {\ldots international symposium on Software testing \ldots},
	Pages = {44--57},
	Publisher = {ACM Press},
	Title = {{Generating test suites for software load testing}},
	Year = {1994}}

@inproceedings{Garousi2006,
	Author = {Garousi, Vahid},
	Isbn = {9780494262252},
	Number = {August},
	Title = {{Traffic-aware Stress Testing of Distributed Real-Time Systems based on UML Models using Genetic Algorithms}},
	Year = {2006}}

@inproceedings{Santos2011,
	Author = {Santos, I de Sousa and Santos, AR and Neto, PA dos Santos},
	Journal = {SEKE},
	Keywords = {- software testing,data generation,experimental study,however,limitations in,non-functional,of performance and stress,requirements,scripts,scripts from functional testing,testing,tool enabled the generation},
	Title = {{Reusing Functional Testing in order to Decrease Performance and Stress Testing Costs.}},
	Year = {2011}}

@book{bernard2012foundations,
	Author = {Bernard, Pierre},
	Publisher = {Van Haren},
	Title = {Foundations of ITIL},
	Year = {2012}}

@inproceedings{Abu-nimeh2001,
	Author = {Abu-nimeh, Saeed and Nair, Suku and Marchetti, Marco},
	Keywords = {bandwidth throttle,denial of service,ramp-up time,response time,stress-testing,think,time,ttfb,ttlb},
	Title = {{Avoiding Denial of Service via Stress Testing}},
	Year = {2001}}

@inproceedings{Garousi2008,
	Author = {Garousi, Vahid},
	Doi = {10.1145/1389095.1389433},
	Isbn = {9781605581309},
	Journal = {Proceedings of the 10th annual conference on Genetic and evolutionary computation - GECCO '08},
	Keywords = {empirical analysis,genetic algorithms,stress testing},
	Pages = {1743},
	Title = {{Empirical analysis of a genetic algorithm-based stress test technique}},
	Year = {2008}}

@inproceedings{Chakravarty2010,
	Author = {Chakravarty, A},
	Journal = {Information Technology: New Generations ( \ldots},
	Title = {{Stress testing an ai based web service: A case study}},
	Year = {2010}}

@inproceedings{Acharya2009,
	Author = {Acharya, Mithun and Kommineni, Vamshidhar},
	Doi = {10.1109/ASE.2009.95},
	Isbn = {9780769538914},
	Issn = {1527-1366},
	Journal = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
	Pages = {409--420},
	Title = {{Mining health models for performance monitoring of services}},
	Year = {2009}}

@inproceedings{Catelani2011,
	Doi = {10.1016/j.csi.2010.06.006},
	File = {:Users/naubergois/Dropbox/1-s2.0-S092054891000084X-main.pdf:pdf},
	Isbn = {09205489 (ISSN)},
	Issn = {09205489},
	Journal = {Computer Standards and Interfaces},
	Keywords = {Mean time to overflow,Quality in use,Software automated testing,Software reliability},
	Number = {2},
	Pages = {152--158},
	Publisher = {Elsevier B.V.},
	Title = {{Software automated testing: A solution to maximize the test plan coverage and to increase software reliability and quality in use}},
	Volume = {33},
	Year = {2011}}

@inproceedings{Wegener1997,
	Abstract = {The development of real-time systems is an essential industrial activity whose importance is increasing. The most important analytical method to assure the quality of real-time systems is dynamic testing. Testing is the only method which examines the actual run-time behaviour of real-time software, based on an execution in the real application environment. Dynamic aspects like the duration of computations, the memory actually needed, or the synchronization of parallel processes are of major importance for the correct function of real-time systems and have to be tested. A comprehensive investigation of existing software test methods shows that they mostly concentrate on testing for functional correctness. They are not suited for an examination of temporal correctness which is essential to real-time systems. Very small systems show a wide range of different execution times. Therefore, existing test procedures must be supplemented by new methods, which concentrate on determining whether the system violates its specified timing constraints. In general, this means that outputs are produced too early or their computation takes too long. The task of the tester is to find the inputs with the longest or shortest execution times to check whether they produce a temporal error. If the search for such inputs is interpreted as a problem of optimization, genetic algorithms can be used to find the inputs with the longest or shortest execution times automatically. The fitness function is the execution time measured in processor cycles. Experiments using genetic algorithms on a number of programs with up to 1511 LOC and 843 integer input parameters have successfully identified new longer and shorter paths than had been found using random testing or systematic testing. Genetic algorithms are able therefore to check large programs and they show considerable promise in establishing the validity of the temporal behaviour of real-time software.},
	Author = {Wegener, Joachim and Sthamer, Harmen and Jones, Bryan F and Eyres, David E},
	Doi = {10.1023/A:1018551716639},
	Issn = {0963-9314, 1573-1367},
	Journal = {Software Quality Journal},
	Keywords = {embedded systems,genetic algorithms,real time systems,temporal behaviour,testing},
	Number = {2},
	Pages = {127--135},
	Title = {{Testing real-time systems using genetic algorithms}},
	Url = {http://www.springerlink.com/index/uh26067rt3516765.pdf},
	Volume = {6},
	Year = {1997}}

@inproceedings{Alander,
	Abstract = {In this work we are studying possibilities to test software using genetic algorithm search. The idea is to produce test cases in order to find problematic situations like processing time extremes. The proposed test method comes under the heading of automated dynamic stress testing. Keywords: genetic algorithms, software engineering, dynamic stress testing 1 Introduction Real-time software is increasingly applied to products in which failure may have severe consequences, thus the requirements for correctness and reliability are getting higher, too. In very reliable sequential programs, the rate of errors should be less than 10 errors/1000 lines of code, to avoid functional failure. Achieving this level is very labourious, because the amount of program testing work grows exponentially with code size. Testing software manually is slow, expensive and demands inventiveness. Automated testing can reduce both the time and costs needed for performing tests. Exhaustive test data generation is...},
	Annote = {From Duplicate 1 ( },
	Author = {Alander, Jarmo T. JT and Mantere, Timo and Turunen, Pekka},
	Booktitle = {Neural Nets and Genetic Algorithms},
	Date-Modified = {2015-12-05 06:11:49 +0000},
	Title = {{Genetic Algorithm Based Software Testing}},
	Year = {1998}}

@inproceedings{Barros2007,
	Author = {Barros, Marcelo De and Shiau, Jing},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Barros, Shiau - 2007 - Web services wind tunnel On performance testing large-scale stateful web services.pdf:pdf},
	Journal = {\ldots and Networks, 2007. \ldots},
	Title = {{Web services wind tunnel: On performance testing large-scale stateful web services}},
	Year = {2007}}

@inproceedings{Weyuker2000,
	Abstract = {An approach to software performance testing is discussed. A case study describing the experience of using this approach for testing the performance of a system used as a gateway in a large industrial client/server transaction processing application is presented.},
	Author = {Weyuker, EJ and Vokolos, FI},
	Doi = {10.1109/32.888628},
	Issn = {0098-5589},
	Journal = {IEEE transactions on software engineering},
	Keywords = {Software performance testing,performance testing.,program testing,software testing},
	Mendeley-Tags = {Software performance testing,performance testing.,program testing,software testing},
	Number = {12},
	Pages = {1147--1156},
	Shorttitle = {Experience with Performance Testing of Software Sy},
	Title = {{Experience with performance testing of software systems: issues, an approach, and case study}},
	Volume = {26},
	Year = {2000}}

@inproceedings{Raiha2010,
	Abstract = {This survey investigates search-based approaches to software design. The basics of the most popular meta-heuristic algorithms are presented as background to the search-based viewpoint. Software design is considered from a wide viewpoint, including topics that can also be categorized as software maintenance or re-engineering. Search-based approaches have been used in research from the high architecture design level to software clustering and finally software refactoring. Enhancing and predicting software quality with search-based methods is also taken into account as a part of the design process. The background for the underlying software engineering problems is discussed, after which search-based approaches are presented. Summarizing remarks and tables collecting the fundamental issues of approaches for each type of problem are given. The choices regarding critical decisions, such as representation and fitness function, when used in meta-heuristic search algorithms, are emphasized and discussed in detail. Ideas for future research directions are also given. {\copyright} 2010 Elsevier Inc.},
	Author = {R\"{a}ih\"{a}, Outi},
	Doi = {10.1016/j.cosrev.2010.06.001},
	Isbn = {15740137},
	Issn = {15740137},
	Journal = {Computer Science Review},
	Keywords = {Search algorithms,Search-based software engineering,Software design,Software quality},
	Number = {4},
	Pages = {203--249},
	Publisher = {Elsevier Inc.},
	Title = {{A survey on search-based software design}},
	Volume = {4},
	Year = {2010}}

@inproceedings{Mohamed2012,
	Abstract = {With the recent rapid development of mobile devices in terms of processing power, memory and storage capabilities coupled with the advancements of wireless technology in terms of higher data transmission rates such as 3G and 4G, it has now become feasible to host Web services on mobile devices. In this paper we propose a lightweight framework for hosting Web services on mobile devices. We further evaluate and provide a comparative analysis for hosting RESTful Web services versus SOAP-based Web services on our framework. Our experimental results and analysis indicate that RESTful Web services are less resource-consuming and more efficient for the implementation and provisioning of Web services from resource-constrained mobile devices. ?? 2012 Published by Elsevier Ltd.},
	Author = {Mohamed, KamalEldin and Wijesekera, Duminda},
	Doi = {10.1016/j.procs.2012.06.095},
	Isbn = {1877-0509},
	Issn = {18770509},
	Journal = {Procedia Computer Science},
	Keywords = {Lightweight framework,Mobile web server,REST,SOAP,Web services},
	Pages = {744--751},
	Publisher = {Duminda Wijesekera},
	Title = {{Performance analysis of web services on mobile devices}},
	Volume = {10},
	Year = {2012}}

@book{reeves1993modern,
	Author = {Reeves, Colin R},
	Publisher = {John Wiley \& Sons, Inc.},
	Title = {Modern heuristic techniques for combinatorial problems},
	Year = {1993}}

@inproceedings{Sandler2004,
	Abstract = {The classic, landmark work on software testingThe hardware and software of computing have changed markedly in the three decades since the first edition of The Art of Software Testing, but this book's powerful underlying analysis has stood the test of time. Whereas most books on software testing target particular development techniques, languages, or testing methods, The Art of Software Testing, Third Edition provides a brief but powerful and comprehensive presentation of time-proven software testing approaches. If your software development project is mission critical, this book is an investment that will pay for itself with the first bug you find.The new Third Edition explains how to apply the book's classic principles to today's hot topics including:Testing apps for iPhones, iPads, BlackBerrys, Androids, and other mobile devicesCollaborative (user) programming and testingTesting for Internet applications, e-commerce, and agile programming environmentsWhether you're a student looking for a testing guide you'll use for the rest of your career, or an IT manager overseeing a software development team, The Art of Software Testing, Third Edition is an expensive book that will pay for itself many times over.},
	Author = {Sandler, Corey and Badgett, Tom and Thomas, TM},
	File = {:Users/naubergois/Downloads/The Art of Software Testing, 3rd Edition.pdf:pdf},
	Isbn = {9781118133156},
	Keywords = {Business \& Economics / Reference,Computers / Information Technology},
	Language = {en},
	Mendeley-Tags = {Business \& Economics / Reference,Computers / Information Technology},
	Month = sep,
	Pages = {200},
	Publisher = {John Wiley \& Sons},
	Title = {{The Art of Software Testing}},
	Year = {2004}}

@book{Erinle2013,
	Author = {Erinle, Bayo},
	File = {:Users/naubergois/Dropbox/OPR/papers/performance-testing-with-jmeter-2-9.pdf:pdf},
	Isbn = {9781782165842},
	Title = {{Performance Testing With JMeter 2.9}},
	Year = {2013}}

@misc{Corporation2007,
	Abstract = {Performance Testing Guidance for Web Applications provides an end-to-end approach for implementing performance testing. Whether you are new to performance testing or looking for ways to improve your current performance-testing approach, you will gain insights that you can tailor to your specific scenarios.},
	Address = {United States?},
	Author = {Corporation, Microsoft},
	Edition = {1 edition},
	Isbn = {9780735625709},
	Language = {English},
	Month = nov,
	Pages = {288},
	Publisher = {Microsoft Press},
	Title = {{Performance Testing Guidance for Web Applications}},
	Url = {http://www.amazon.com/Performance-Testing-Guidance-Web-Applications/dp/0735625700 http://msdn.microsoft.com/en-us/library/bb924375.aspx},
	Year = {2007},
	Bdsk-Url-1 = {http://www.amazon.com/Performance-Testing-Guidance-Web-Applications/dp/0735625700%20http://msdn.microsoft.com/en-us/library/bb924375.aspx}}

@inproceedings{Snellman,
	Author = {Snellman, Niclas and Ashraf, Adnan and Porres, Ivan},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Snellman, Ashraf, Porres - Unknown - Towards Automatic Performance and Scalability Testing of Rich Internet Applications in the Cloud(2).pdf:pdf},
	Keywords = {-performance testing,a flat performance curve,application should ideally maintain,cloud computing,intended maximum load level,rich in-,scalability testing,ternet applications,until it reaches its},
	Title = {{Towards Automatic Performance and Scalability Testing of Rich Internet Applications in the Cloud}}}

@inproceedings{Cohen2004,
	Abstract = {This paper studies the use of statistical induction techniques as a basis for automated performance diagnosis and performance management. The goal of the work is to develop and evaluate tools for offline and online analysis of system metrics gathered from instrumentation in Internet server platforms. We use a promising class of probabilistic models (Tree-Augmented Bayesian Networks or TANs) to identify combinations of system-level metrics and threshold values that correlate with high-level with Service Level Objectives (SLOs) for average-case response timein a three-tier Web service under a variety of conditions. Experimental results from a testbed show that TAN models involving small subsets of metrics capture patterns of performance behavior in a way that is accurate and yields insights into the causes of observed performance effects. TANs are extremely efficient to represent and evaluate, and they have interpretability properties that make them excellent candidates for automated diagnosis and control. We explore the use of TAN models for offline forensic diagnosis, and in a limited online setting for performance forecasting with stable workloads.},
	Author = {Cohen, Ira and Goldszmidt, Moises and Kelly, Terence and Symons, Julie and Chase, Jeffrey S},
	File = {:Users/naubergois/Dropbox/HPL-2004-183.pdf:pdf},
	Journal = {Small},
	Number = {December},
	Pages = {6--8},
	Title = {{Correlating instrumentation data to system states : A building block for automated diagnosis and control performance forecasting automated performance diagnosis and performance management . The goal of the work is to develop and evaluate tools for offline}},
	Year = {2004}}

@inproceedings{Biolchini2005,
	Author = {Biolchini, Jorge and Mian, Paula Gomes and Candida, Ana and Natali, Cruz},
	Doi = {10.1007/978-3-540-70621-2},
	Isbn = {9783540706199},
	Issn = {18650929},
	Journal = {System Engineering and Computer Science Department COPPE/UFRJ, Technical Report ES},
	Number = {May},
	Pages = {165--176},
	Title = {{Systematic Review in Software Engineering}},
	Volume = {679},
	Year = {2005}}

@inproceedings{Goncalves2014,
	Author = {Gonçalves, Marcelo CanÁrio},
	Title = {{Um Processo de Infer\^{e}ncia de Desempenho para Apoiar o Planejamento da Capacidade de Aplicações na Nuvem Um Processo de Inferência de Desempenho para Apoiar o Planejamento da Capacidade de Aplicações na Nuvem}},
	Year = {2014}}

@book{Feitelson2013,
	Author = {Feitelson, Dror G},
	File = {:Users/naubergois/Dropbox/wlmod.pdf:pdf},
	Publisher = {Cambridge University Press},
	Title = {{Workload Modeling for Computer Systems Performance Evaluation}},
	Year = {2013}}

@inproceedings{Malik2010b,
	Author = {Malik, Haroon},
	Doi = {10.1145/1810295.1810408},
	File = {:Users/naubergois/Downloads/icse2010\_malik.pdf:pdf},
	Institution = {Queen's University, Kingston, ON, Canada},
	Isbn = {978-1-60558-719-6},
	Issn = {0270-5257},
	Journal = {Software Engineering, 2010 ACM/IEEE 32nd \ldots},
	Keywords = {automation,counters,load test,performance counters,principal component analysis},
	Pages = {421--424},
	Publisher = {IEEE},
	Title = {{A methodology to support load test analysis}},
	Volume = {2},
	Year = {2010}}

@inproceedings{Kuhn1997,
	Abstract = {What makes a distributed system reliable? A study of failures in
the US public switched telephone network (PSTN) shows that human
intervention is one key to this large system's reliability. Software is
not the weak link in the PSTN system's dependability. Extensive use of
built-in self-test and recovery mechanisms in major system components
(switches) contributed to software dependability and are significant
design features in the PSTN. The network's high dependability indicates
that the trade-off between dependability gains and complexity introduced
by built-in self-test and recovery mechanisms can be positive. Likewise,
the tradeoff between complex interactions and the loose coupling of
system components has been positive, permitting quick human intervention
in most system failures and resulting in an extremely reliable system
},
	Author = {Kuhn, D. Richard},
	Doi = {10.1109/2.585151},
	File = {:Users/naubergois/Dropbox/kuhn-97-pstn-failures.pdf:pdf},
	Issn = {00189162},
	Journal = {Computer},
	Number = {4},
	Pages = {31--36},
	Pmid = {150},
	Title = {{Sources of failure in the public switched telephone network}},
	Volume = {30},
	Year = {1997}}

@inproceedings{McMinn2004,
	Author = {McMinn, Philip and Court, Regent and Testing, Software and Street, Portobello},
	Doi = {10.1002/stvr.294},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/McMinn - 2004 - Search-based software test data generation a survey.pdf:pdf},
	Isbn = {1099-1689},
	Issn = {09600833},
	Journal = {Software testing, Verification and reliability},
	Keywords = {Automated software test data generation,Evolutionary algorithms,Evolutionary testing,Metaheuristic search,Search-based software engineering,Simulated annealing,algorithms,automated software test,automated software test data generation,data generation,evolutionary,evolutionary algorithms,evolutionary testing,metaheuristic search,search-based software engineering,simulated annealing},
	Pages = {1--58},
	Title = {{Search-based software test data generation: a survey}},
	Volume = {14},
	Year = {2004}}

@inproceedings{DiLucca2006,
	Author = {{Di Lucca}, Giuseppe a. and Fasolino, Anna Rita},
	Doi = {10.1016/j.infsof.2006.06.006},
	Isbn = {0-7695-2413-3},
	Issn = {09505849},
	Journal = {Information and Software Technology},
	Keywords = {Software testing,Web application testing,Web engineering},
	Pages = {1172--1186},
	Title = {{Testing Web-based applications: The state of the art and future trends}},
	Volume = {48},
	Year = {2006}}
	
@inproceedings{Harman2015,
abstract = {Search Based Software Testing (SBST) formulates testing as an optimisation problem, which can be attacked using computational search techniques from the field of Search Based Software Engineering (SBSE). We present an analysis of the SBST research agenda1, focusing on the open problems and chal- lenges of testing non-functional properties, in particular a topic we call ‘Search Based Energy Testing' (SBET), Multi-objective SBST and SBST for Test Strategy Identification. We conclude with a vision of FIFIVERIFY tools, which would automatically find faults, fix them and verify the fixes. We explain why we think such FIFIVERIFY tools constitute an exciting challenge for the SBSE community that already could be within its reach.},
author = {Harman, Mark and Jia, Yue and Zhang, Yuanyuan},
isbn = {9781479971251},
journal = {8th IEEE International Conference on Software Testing, Verification and Validation (ICST)},
number = {Icst},
title = {{Achievements , open problems and challenges for search based software testing}},
url = {http://www0.cs.ucl.ac.uk/staff/mharman/icst15.pdf},
year = {2015}
}
	

@inproceedings{Anand2013,
	Author = {Anand, Saswat and Burke, Edmund K. and Chen, Tsong Yueh and Clark, John and Cohen, Myra B. and Grieskamp, Wolfgang and Harman, Mark and Harrold, Mary Jean and McMinn, Phil},
	Doi = {10.1016/j.jss.2013.02.061},
	Issn = {01641212},
	Journal = {Journal of Systems and Software},
	Keywords = {Adaptive random testing,Combinatorial testing,Model-based testing,Orchestrated survey,Search-based software testing,Software testing,Symbolic execution,Test automation,Test case generation},
	Pages = {1978--2001},
	Title = {{An orchestrated survey of methodologies for automated software test case generation}},
	Volume = {86},
	Year = {2013}}

@inproceedings{Penta2007,
	Author = {Penta, Massimiliano Di and Canfora, Gerardo and Esposito, Gianpiero},
	Booktitle = {Proceedings of the 9th annual conference on Genetic and evolutionary computation},
	Isbn = {9781595936974},
	Keywords = {quality of,search-based testing,service level agreement},
	Pages = {1090--1097},
	Title = {{Search-based testing of service level agreements}},
	Year = {2007}}

@inproceedings{Barber1999,
	Author = {Barber, Scott},
	File = {:Users/naubergois/Dropbox/ucml\_1.1.pdf:pdf},
	Pages = {1--9},
	Title = {{User Community Modeling Language ( UCML {\texttrademark} ) v1 . 1 for Performance Test Workloads UCML {\texttrademark} Overview}},
	Year = {1999}}

@inproceedings{Silveira2011,
	Author = {da Silveira, MB and Rodrigues, EM and Zorzo, AF},
	Journal = {SEKE},
	Keywords = {- model-based testing,performance testing,software product line},
	Title = {{Generation of Scripts for Performance Testing Based on UML Models.}},
	Year = {2011}}

@inproceedings{Grechanik2012,
	Author = {Grechanik, Mark and Fu, Chen and Xie, Qing},
	Doi = {10.1109/ICSE.2012.6227197},
	Isbn = {978-1-4673-1067-3},
	Journal = {2012 34th International Conference on Software Engineering (ICSE)},
	Month = jun,
	Pages = {156--166},
	Publisher = {Ieee},
	Title = {{Automatically finding performance problems with feedback-directed learning software testing}},
	Year = {2012}}

@inproceedings{Barna2011,
	Author = {Barna, Cornel and Litoiu, M and Ghanbari, H},
	Isbn = {9781450306072},
	Journal = {International conference on Autonomi},
	Keywords = {autonomic system,performance,performance testing},
	Pages = {91--100},
	Title = {{Autonomic load-testing framework}},
	Year = {2011}}

@book{Everett2007,
	Author = {Everett, Gerald D and Jr., Raymond McLeod},
	Isbn = {9780471793717},
	Title = {{Software Testing: Testing Across the Entire Software Development Life Cycle}},
	Year = {2007}}

@inproceedings{Chen,
	Author = {Chen, Feifei},
	File = {:Users/naubergois/Downloads/13113010195260.pdf:pdf},
	Journal = {chinacloud.cn},
	Keywords = {as it requires,cloud computing,cost,effectiveness before the deployment,energy,however,of cloud systems,performance engineering,this is not a,trade-off analysis,trivial task},
	Title = {{Generating a Performance Test-bed for Cloud Computing Systems}}}
	
@misc{dean2003managing,
  title={Managing Software Requirements: A Use Case Approach},
  author={Dean, Leffingwell and Don, Widrig},
  year={2003},
  publisher={Addison Wesley}
}	

@inproceedings{Alba2008,
abstract = {In this paper we analyze the application of parallel and sequential evolutionary algorithms (EAs) to the automatic test data generation problem. The problem consists of automatically creating a set of input data to test a program. This is a fundamental step in software development and a time consuming task in existing software companies. Canonical sequential EAs have been used in the past for this task. We explore here the use of parallel EAs. Evidence of greater efficiency, larger diversity maintenance, additional availability of memory/CPU, and multi-solution capabilities of the parallel approach, reinforce the importance of the advances in research with these algorithms. We describe in this work how canonical genetic algorithms (GAs) and evolutionary strategies (ESs) can help in software testing, and what the advantages are (if any) of using decentralized populations in these techniques. In addition, we study the influence of some parameters of the proposed test data generator in the results. For the experiments we use a large benchmark composed of twelve programs that includes fundamental algorithms in computer science. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Alba, Enrique and Chicano, Francisco},
doi = {10.1016/j.cor.2007.01.016},
file = {:Users/naubergois/Downloads/testing-cor-sbse.pdf:pdf},
isbn = {0305-0548},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Evolutionary algorithms,Evolutionary testing,Parallel evolutionary algorithms,Software testing},
number = {10},
pages = {3161--3183},
title = {{Observations in using parallel and sequential evolutionary algorithms for automatic software testing}},
volume = {35},
year = {2008}
}

@inproceedings{Harman2010,
abstract = {Search-based optimization techniques have been applied to structural software test data generation since 1992, with a recent upsurge in interest and activity within this area. However, despite the large number of recent studies on the applicability of different search-based optimization approaches, there has been very little theoretical analysis of the types of testing problem for which these techniques are well suited. There are also few empirical studies that present results for larger programs. This paper presents a theoretical exploration of the most widely studied approach, the global search technique embodied by Genetic Algorithms. It also presents results from a large empirical study that compares the behavior of both global and local search-based optimization on real-world programs. The results of this study reveal that cases exist of test data generation problem that suit each algorithm, thereby suggesting that a hybrid global-local search (a Memetic Algorithm) may be appropriate. The paper presents a Memetic Algorithm along with further empirical results studying its performance.},
author = {Harman, Mark and McMinn, Phil},
doi = {10.1109/TSE.2009.71},
file = {:Users/naubergois/Downloads/Software engineering IEEE.Vol.36.Iss.2.A.6.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Artificial intelligence,Automated test data generation,Evolutionary testing,Genetic algorithms,Hill climbing,Problem solving,Royal road,Schema theory,Search-based software engineering,Search-based testing,Testing and debugging,Testing tools},
number = {2},
pages = {226--247},
title = {{A theoretical and empirical study of search-based testing: Local, global, and hybrid search}},
volume = {36},
year = {2010}
}

@book{MohammadS.Obaidat,
author = {{Mohammad S. Obaidat}, Petros Nicopolitidis and Faouzi Zarai},
file = {:Users/naubergois/Downloads/Mohammad S. Obaidat, Faouzi Zarai, Petros Nicopolitidis-Modeling and Simulation of Computer Networks and Systems{\_} Methodologies and Applications-Morgan Kaufmann (2015).pdf:pdf},
isbn = {9780128008874},
title = {{Modeling and Simulation of Computer Networks and Systems Methodologies and Applications}}
}

@book{Tobergte2013,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Raidl, Gunther R and Puchinger, Jakob and Blum}, Christian},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Hybrid Metaheuristics{\_} An Emerging Approach to Optimization.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Hybrid Metaheuristics An Emerging Approach}},
volume = {53},
year = {2013}
}

@book{Talbi2013,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Talbi, El-Ghazali},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Metaheuristics.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Metaheuristics: From Design to Implementation}},
volume = {53},
year = {2013}
}

@inproceedings{Greenwald2003,
abstract = {Bowling named two desiderata for multiagent learning algorithms: rationality and convergence. This paper introduces co{\~{}}elated-Q learning, a natural generaliza- tion of Nash-Q NashoQ converge. FF-Q satisfies convergence, but in general it is not rational. Correlated-Q satisfies rationality by construction. This papers demonstrates the empirical convergence of correlated-Q on a standard testbed of general-sum Markov games. satisfies rationality, but in general it does not and FF-Q that satisfies these criteria.},
author = {Greenwald, Amy and Hall, Keith and Serrano, R},
file = {:Users/naubergois/Downloads/SS02-02-012.pdf:pdf},
journal = {Icml},
number = {3},
pages = {84--89},
title = {{Correlated Q-learning}},
url = {http://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-02/SS02-02-012.pdf},
year = {2003}
}

@inproceedings{MarkUtting2012,
abstract = {Penetration testing is widely used to help ensure the security of web applications. Using penetration testing, testers discover vulnerabilities by simulating attacks on a target web application. To do this efﬁciently, testers rely on automated techniques that gather input vector information about the target web application and analyze the application's responses to determine whether an attack was successful. Techniques for performing these steps are often incomplete, which can leave parts of the web application untested and vulnerabilities undiscovered. This paper proposes a new approach to penetration testing that addresses the limitations of current techniques. The approach incorporates two recently developed analysis techniques to improve input vector identiﬁcation and detect when attacks have been successful against a web application. This paper compares the proposed approach against two popular penetration testing tools for a suite of web applications with known and unknown vulnerabilities. The evaluation results show that the proposed approach performs a more thorough penetration testing and leads to the discovery of more vulnerabilities than both the tools.},
author = {{Mark Utting}, Alexander Pretschner and Bruno Legeard},
doi = {10.1002/stvr},
file = {:Users/naubergois/Downloads/master{\_}pdflatex.pdf:pdf},
isbn = {1099-1689},
issn = {10991689},
journal = {Software Testing Verification and Reliability},
keywords = {model-based testing approaches,survey,taxonomy},
number = {8},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {24},
year = {2012}
}

@inproceedings{Hierons2009,
abstract = {Formal methods and testing are two important approaches that assist in the development of high-quality software.While traditionally these approaches have been seen as rivals, in recent years a new consensus has developed in which they are seen as complementary. This article reviews the state of the art regarding ways in which the presence of a formal specification can be used to assist testing.},
author = {Hierons, Robert M and Bogdanov, Kirill and Bowen, Jonathan P and Cleaveland, Rance and Derrick, John and Dick, Jeremy and Gheorghe, Marian and Harman, Mark and Kapoor, Kalpesh and Krause, Paul and L{\"{u}}ttgen, Gerald and Simons, Anthony J H and Vilkomir, Sergiy and Woodward, Martin R and Zedan, Hussein},
doi = {http://doi.acm.org/10.1145/1459352.1459354},
file = {:Users/naubergois/Downloads/hierons2009.pdf:pdf},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
number = {2},
pages = {1--76},
title = {{Using formal specifications to support testing}},
volume = {41},
year = {2009}
}

@phdthesis{shousha2003performance,
  title={Performance Stress Testing of Real-Time Systems Using Genetic Algorithms},
  author={Shousha, Marwa},
  year={2003},
  school={Carleton University Ottawa}
}

@inproceedings{hong2000simultaneously,
  title={Simultaneously applying multiple mutation operators in genetic algorithms},
  author={Hong, Tzung-Pei and Wang, Hong-Shung and Chen, Wei-Chou},
  journal={Journal of heuristics},
  volume={6},
  number={4},
  pages={439--455},
  year={2000},
  publisher={Springer}
}

@inproceedings{Vogele2016,
abstract = {The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy.},
author = {Vogele, Christian and van Hoorn, Andr{\'{e}} and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
doi = {10.1007/s10270-016-0566-5},
file = {:Users/naubergois/Downloads/VoegelevanHoornSchulzHasselbringKrcmar2016WESSBAS-SoSyM.pdf:pdf},
issn = {16191374},
journal = {Software and Systems Modeling},
keywords = {Load testing,Performance models,Performance prediction,Workload specifications},
number = {October},
pages = {1--35},
publisher = {Springer Berlin Heidelberg},
title = {{WESSBAS: extraction of probabilistic workload specifications for load testing and performance prediction???a model-driven approach for session-based application systems}},
url = {"http://dx.doi.org/10.1007/s10270-016-0566-5},
year = {2016}
}


@article{Menasce2002b,
author = {Menasc{\'{e}}, Daniel A},
file = {:Users/naubergois/Downloads/Load{\_}Testing{\_}Benchmarking{\_}and{\_}Application{\_}Performa.pdf:pdf},
journal = {Int. CMG Conference},
number = {January 2002},
pages = {271--282},
title = {{Load Testing, Benchmarking, and Application Performance Management for the Web}},
year = {2002}
}

@article{Rajeshwari2016,
author = {Rajeshwari, B S},
doi = {10.5120/ijca2015907358.CITATIONS},
file = {:Users/naubergois/Downloads/SLA-Baed-Scheduling Techniques-in-Cloud.pdf:pdf},
number = {January},
title = {{Service Level Agreement based Scheduling Techniques in Cloud : A Survey Service Level Agreement based Scheduling Techniques in Cloud : A Survey}},
year = {2016}
}



@inproceedings{Menasce2002a,
author = {Menasc{\'{e}}, Daniel A and Mason, George},
file = {:Users/naubergois/Downloads/10.1.1.468.8603.pdf:pdf},
number = {June},
pages = {1--6},
title = {{TPC-W : A Benchmark for E-commerce}},
year = {2002}
}


@inproceedings{Sutton2012,
archivePrefix = {arXiv},
arxivId = {1603.02199},
author = {Sutton, Richard S. and Barto, Andrew G.},
doi = {10.1109/MED.2013.6608833},
eprint = {1603.02199},
isbn = {0262193981},
issn = {18726240},
journal = {Learning},
number = {9},
pages = {322},
pmid = {18255791},
title = {Reinforcement learning},
volume = {3},
year = {2012}
}

@inproceedings{Szepesvari2010,
abstract = {Reinforcement learning is a learning paradigm concerned with learning to control a system so as to maximize a numerical performance measure that expresses a long-term objective.What distin- guishes reinforcement learning from supervised learning is that only partial feedback is given to the learner about the learner's predictions. Further, the predictions may have long term effects through influencing the future state of the controlled system. Thus, time plays a special role. The goal in reinforcement learning is to develop efficient learning algorithms, as well as to understand the al- gorithms' merits and limitations. Reinforcement learning is of great interest because of the large number of practical applications that it can be used to address, ranging from problems in artificial intelligence to operations research or control engineering. In this book,we focus on those algorithms of reinforcement learning that build on the powerful theory of dynamic programming.We give a fairly comprehensive catalog of learning problems, describe the core ideas, note a large number of state of the art algorithms, followed by the discussion of their theoretical properties and limitations.},
author = {Szepesv{\'{a}}ri, Csaba and Bartok, Gabor},
doi = {10.2200/S00268ED1V01Y201005AIM009},
file = {:Users/naubergois/Downloads/RLAlgsInMDPs-lecture.pdf:pdf},
isbn = {9781608454921},
issn = {1939-4608},
journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
number = {x},
pages = {1--103},
title = {{Algorithms for Reinforcement Learning}},
volume = {4},
year = {2010}
}



@inproceedings{Bertolino2008,
abstract = {A Web Service is commonly not an independent software entity, but plays a role in some business process. Hence, it depends on the services provided by external Web Services, to provide its own service. While developing and testing a Web Service, such external services are not always available, or their usage comes along with unwanted side effects like, e.g., utilization fees or database modifications. We present a model-based approach to generate stubs for Web Services which respect both an extra-functional contract expressed via a Service Level Agree- ment (SLA), and a functional contract modeled via a state machine. These stubs allow a developer to set up a testbed over the target plat- form, in which the extra-functional and functional behavior of a Web Service under development can be tested before its publication.},
author = {Bertolino, Antonia and Angelis, Guglielmo De},
doi = {10.1007/978-3-540-68524-1_19},
file = {:Users/naubergois/Downloads/BAFP08.pdf:pdf},
isbn = {978-3-540-68514-2, 978-3-540-68524-1},
issn = {978-3-540-68514-2},
journal = {Testing of Software and {\ldots}},
pages = {266--282},
title = {{Model-based generation of testbeds for web services}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-68524-1{\_}19},
year = {2008}
}

@inproceedings{MarkUtting2012,
abstract = {Penetration testing is widely used to help ensure the security of web applications. Using penetration testing, testers discover vulnerabilities by simulating attacks on a target web application. To do this efﬁciently, testers rely on automated techniques that gather input vector information about the target web application and analyze the application's responses to determine whether an attack was successful. Techniques for performing these steps are often incomplete, which can leave parts of the web application untested and vulnerabilities undiscovered. This paper proposes a new approach to penetration testing that addresses the limitations of current techniques. The approach incorporates two recently developed analysis techniques to improve input vector identiﬁcation and detect when attacks have been successful against a web application. This paper compares the proposed approach against two popular penetration testing tools for a suite of web applications with known and unknown vulnerabilities. The evaluation results show that the proposed approach performs a more thorough penetration testing and leads to the discovery of more vulnerabilities than both the tools.},
author = {{Mark Utting}, Alexander Pretschner and Bruno Legeard},
doi = {10.1002/stvr},
file = {:Users/naubergois/Downloads/master{\_}pdflatex.pdf:pdf},
isbn = {1099-1689},
issn = {10991689},
journal = {Software Testing Verification and Reliability},
keywords = {model-based testing approaches,survey,taxonomy},
number = {8},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {24},
year = {2012}
}

@inproceedings{Trent1995,
author = {Trent, G and Sake, M},
file = {:Users/naubergois/Downloads/WebSTONE{\_}The{\_}First{\_}Generation{\_}in{\_}HTTP{\_}Se.pdf:pdf},
journal = {WWW Conference'95},
title = {{WebSTONE: The first generation in {\{}HTTP{\}} server benchmarking}},
year = {1995}
}

@inproceedings{Luo2015,
abstract = {A goal of performance testing is to find situations when applications unexpectedly exhibit worsened characteristics for certain combinations of input values. A fundamental question of performance testing is how to select a manageable subset of the input data faster in order to automatically find performance bottlenecks in applications. We propose FOREPOST, a novel solution, for automatically finding performance bottlenecks in applications using black-box software testing. Our solution is an adaptive, feedback-directed learning testing system that learns rules from execution traces of applications. Theses rules are then used to automatically select test input data for performance testing. We hypothesize that FOREPOST can find more performance bottlenecks as compared to random testing. We have implemented our solution and applied it to a medium-size industrial application at a major insurance company and to two open-source applications. Performance bottlenecks were found automatically and confirmed by experienced testers and developers. We also thoroughly studied the factors (or independent variables) that impact the results of FOREPOST. {\&}copy; 2015 Springer Science+Business Media New York},
author = {Luo, Qi and Nair, Aswathy and Grechanik, Mark and Poshyvanyk, Denys},
doi = {10.1007/s10664-015-9413-5},
file = {:Users/naubergois/Downloads/10.1.1.699.7944.pdf:pdf},
isbn = {1066401594},
issn = {15737616},
journal = {Empirical Software Engineering},
keywords = {Feedback-directed learning system,Performance testing},
pages = {1--51},
title = {{FOREPOST: finding performance problems automatically with feedback-directed learning software testing}},
year = {2015}
}



@book{Talbi2012,
abstract = {The main goal of this book is to provide a state of the art of hybrid metaheuristics. The book provides a complete background that enables readers to design and implement hybrid metaheuristics to solve complex optimization problems (continuous/discrete, mono-objective/multi-objective, optimization under uncertainty) in a diverse range of application domains. Readers learn to solve large scale problems quickly and efficiently combining metaheuristics with complementary metaheuristics, mathematical programming, constraint programming and machine learning. Numerous real-world examples of problems and solutions demonstrate how hybrid metaheuristics are applied in such fields as networks, logistics and transportation, bio-medical, engineering design, scheduling.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Talbi, El-Ghazali},
doi = {10.1007/978-3-642-30671-6},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Hybrid{\_}Metaheuristics{\_}An{\_}Introduction.pdf:pdf},
isbn = {9783642306709},
issn = {1098-6596},
keywords = {learning,neighborhood search,online and offline tuning,project scheduling,stochastic local search},
number = {December 2016},
pages = {19--35},
pmid = {25246403},
title = {{Hybrid Metaheuristics}},
volume = {2},
year = {2012}
}




@inproceedings{Mendoza2005a,
	Author = {Mendoza, Valerie and Novick, Dg},
	Doi = {10.1145/1085313.1085348},
	Isbn = {9157475725},
	Journal = {SIGDOC '05 Proceedings of the 23rd annual international conference on Design of communication: documenting \& designing for pervasive information},
	Keywords = {training,usability},
	Pages = {151--158},
	Title = {{Usability over time}},
	Year = {2005}}

@inproceedings{Glover1989,
	Abstract = {This is the second half of a two part series devoted to the tabu search metastrategy for optimization problems. Part I introduced the fundamental ideas of tabu search as an approach for guiding other heuristics to overcome the limitations of local optimality, both in a deterministic and a probabilistic framework. Part I also reported successful applications from a wide range of settings, in which tabu search frequently made it possible to obtain higher quality solutions than previously obtained with competing strategies, generally with less computational effort. Part II, in this issue, examines refinements and more advanced aspects of tabu search. Following a brief review of notation, Part II introduces new dynamic strategies for managing tabu lists, allowing fuller exploitation of underlying evaluation functions. In turn, the elements of staged search and structured move sets are characterized, which bear on the issue of finiteness. Three ways of applying tabu search to the solution of integer programming problems are then described, providing connections also to certain nonlinear programming applications. Finally, the paper concludes with a brief survey of new applications of tabu search that have occurred since the developments reported in Part I. Together with additional comparisons with other methods on a wide body of problems, these include results of parallel processing implementations and the use of tabu search in settings ranging from telecommunications to neural networks.},
	Author = {Glover, Fred},
	Doi = {10.1287/ijoc.2.1.4},
	Isbn = {079239965X},
	Issn = {0899-1499},
	Journal = {ORSA journal on Computing},
	Number = {3},
	Pages = {4--32},
	Pmid = {2758},
	Title = {{Tabu Search - Part II}},
	Volume = {2 1},
	Year = {1989}}

@inproceedings{Kirkpatrick2007,
	Author = {Kirkpatrick},
	Doi = {10.1126/science.220.4598.671},
	Issn = {0036-8075},
	Number = {4598},
	Pages = {671--680},
	Pmid = {17813860},
	Title = {{Optimization by SA}},
	Volume = {220},
	Year = {2007}}

@inproceedings{Goffe1994,
	Abstract = {Many statistical methods rely on numerical optimization to estimate a model's parameters. Unfortunately, conventional algorithms sometimes fail. Even when they do converge, there is no assurance that they have found the global, rather than a local, optimum. We test a new optimization algorithm, simulated annealing, on four econometric problems and compare it to three common conventional algorithms. Not only can simulated annealing find the global optimum, it is also less likely to fail on difficult functions because it is a very robust algorithm. The promise of simulated annealing is demonstrated on the four econometric problems.},
	Author = {Goffe, William L. and Ferrier, Gary D. and Rogers, John},
	Doi = {10.1016/0304-4076(94)90038-8},
	Isbn = {0304-4076},
	Issn = {03044076},
	Journal = {Journal of Econometrics},
	Keywords = {simulated},
	Number = {1-2},
	Pages = {65--99},
	Title = {{Global optimization of statistical functions with simulated annealing}},
	Volume = {60},
	Year = {1994}}

@phdthesis{tracey2000search,
	Author = {Tracey, Nigel James},
	School = {Citeseer},
	Title = {A search-based automated test-data generation framework for safety-critical software},
	Year = {2000}}

@inproceedings{alander1996ga,
	Author = {Alander, Jarmo T and Mantere, Pekka Turunen and Virolainen, Jari},
	Publisher = {Citeseer},
	Title = {GA in program testing},
	Year = {1996}}

@inproceedings{Tracey1998,
	Abstract = {One of the major costs in a software project is the construction of test-data. This paper outlines a generalised test-case data generation framework based on optimisation techniques. The framework can incorporate a number of testing criteria, for both functional and non-functional properties. Application of the optimisation framework to testing specification failures and exception conditions is illustrated. The results of a number of small case studies are presented and show the efficiency and effectiveness of this dynamic optimisation-based approach to generating test-data},
	Author = {Tracey, N J and Clark, J a and Mander, K C},
	Keywords = {QA 76 Software, computer programming,},
	Title = {{Automated Programme Flaw Finding using Simulated Annealing}},
	Year = {1998}}

@inproceedings{Wegener1999,
	Abstract = {For real-time systems, correct system functionality depends on
logical as well as on temporal correctness. Static analysis alone is not
sufficient to verify the temporal behavior of real-time systems. Since
existing test methods are not specialized for the verification of
temporal correctness, we have developed a new testing method, namely
evolutionary testing. This paper illustrates results of the first
industrial application of the evolutionary test},
	Author = {Wegener, J. and Sthamer, H. and Pohlheim, H.},
	Doi = {10.1109/REAL.1999.818852},
	Isbn = {0-7695-0475-2},
	Issn = {1052-8725},
	Journal = {Proceedings 20th IEEE Real-Time Systems Symposium (Cat. No.99CB37054)},
	Title = {{Testing the temporal behavior of real-time tasks using extended evolutionary algorithms}},
	Year = {1999}}

@inproceedings{Mueller1998,
	Abstract = {The paper contrasts two methods to verify timing constraints of
real-time applications. The method of static analysis predicts the
worst-case and best-case execution times of a task's code by analyzing
execution paths and simulating processor characteristics without ever
executing the program or requiring the program's input. Evolutionary
testing is an iterative testing procedure, which approximates the
extreme execution times within several generations. By executing the
test object dynamically and measuring the execution times the inputs are
guided yielding gradually tighter predictions of the extreme execution
times. The authors examined both approaches on a number of real world
examples. The results show that static analysis and evolutionary testing
are complementary methods, which together provide upper and lower bounds
for both worst-case and best-case execution times},
	Author = {Mueller, F. and Wegener, J.},
	Doi = {10.1109/RTTAS.1998.683198},
	File = {:Users/naubergois/Dropbox/rtas98.pdf:pdf},
	Isbn = {0-8186-8569-7},
	Journal = {Proceedings. Fourth IEEE Real-Time Technology and Applications Symposium (Cat. No.98TB100245)},
	Title = {{A comparison of static analysis and evolutionary testing for the verification of timing constraints}},
	Year = {1998}}

@inproceedings{Puschner1998,
	Abstract = {Analytically derived worst case execution time (WCET) bounds are
prone to errors, because they often rely on information provided by the
user. The paper presents a method for testing the results of static WCET
analysis. The proposed test method is a blackbox test method that uses a
genetic algorithm (GA) for test case generation. Important properties of
the method are: (a) that it requires minimal information about possible
impact data from the user and (b) that the GA guides data generation
into directions that have a good chance to yield the real WCET of the
program under test. Experimental results show that GA based testing
produces results of high quality},
	Author = {Puschner, P. and Nossal, R.},
	Doi = {10.1109/REAL.1998.739738},
	Isbn = {0-8186-9212-X},
	Issn = {1052-8725},
	Journal = {Proceedings 19th IEEE Real-Time Systems Symposium (Cat. No.98CB36279)},
	Title = {{Testing the results of static worst-case execution-time analysis}},
	Year = {1998}}

@inproceedings{J.WegenerK.GrimmM.GrochtmannH.Sthamer1996,
	Author = {{J. Wegener, K. Grimm, M. Grochtmann, H. Sthamer}, B. Jones},
	File = {:Users/naubergois/Dropbox/eurostar1996.pdf:pdf},
	Journal = {EuroSTAR'96: Proceedings of the Fourth International Conference on Software Testing Analysis and Review},
	Title = {{Systematic testing of real-time systems}},
	Year = {1996}}

@inproceedings{Gro,
	Author = {Gro, Hans-Gerhard},
	Publisher = {Citeseer},
	Title = {A prediction system for dynamic optimisation-based execution time analysis},
	Year = {2001}}

@misc{Gross2003,
	Author = {Gross, Hg},
	Booktitle = {Proceedings of the International Conference on Information Technology: Prospects and Challenges in the 21st Century},
	File = {:Users/naubergois/Dropbox/grossITPC03\_RealTime.pdf:pdf},
	Title = {{An evaluation of dynamic, optimisation-based worst-case execution time analysis}},
	Year = {2003}}

@inproceedings{Briand2005,
	Author = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
	Doi = {10.1145/1068009.1068183},
	Isbn = {1595930108},
	Journal = {Proceedings of the 2005 conference on Genetic and evolutionary computation - GECCO '05},
	Keywords = {genetic algorithms,schedulability theory},
	Pages = {1021},
	Title = {{Stress testing real-time systems with genetic algorithms}},
	Year = {2005}}

@inproceedings{Canfora,
	Author = {Canfora, Gerardo and Penta, Massimiliano Di and Esposito, Raffaele and Villani, Maria Luisa},
	Isbn = {1595930108},
	Keywords = {oriented software engineering,qos,service},
	Year = {2005},
	Title = {{An approach for QoS-aware service composition based on genetic algorithms}}}

@inproceedings{gross2000structural,
	Author = {Gross, H-G and Jones, Bryan F and Eyres, David E},
	Journal = {IEE Proceedings-Software},
	Number = {2},
	Pages = {25--30},
	Publisher = {IET},
	Title = {Structural performance measure of evolutionary testing applied to worst-case timing of real-time systems},
	Volume = {147},
	Year = {2000}}

@inproceedings{goldberg1989messy,
	Author = {Goldberg, David E and Korb, Bradley and Deb, Kalyanmoy},
	Journal = {Complex systems},
	Number = {5},
	Pages = {493--530},
	Publisher = {Complex Systems Publications, Champaign, IL, USA},
	Title = {Messy genetic algorithms: Motivation, analysis, and first results},
	Volume = {3},
	Year = {1989}}

@inproceedings{wegener1998verifying,
	Author = {Wegener, Joachim and Grochtmann, Matthias},
	Journal = {Real-Time Systems},
	Number = {3},
	Pages = {275--298},
	Publisher = {Springer},
	Title = {Verifying timing constraints of real-time systems by means of evolutionary testing},
	Volume = {15},
	Year = {1998}}

@inproceedings{alander1998searching,
	Author = {Alander, Jarmo T and Mantere, Timo and Moghadampour, Ghodrat and Matila, Jukka},
	Journal = {Electric Power Systems Research},
	Number = {3},
	Pages = {229--233},
	Publisher = {Elsevier},
	Title = {Searching protection relay response time extremes using genetic algorithm---software quality by optimization},
	Volume = {46},
	Year = {1998}}

@inproceedings{Wegener1998,
	Abstract = {Many industrial products are based on the use of embedded computer systems. Usually, these systems have to fulfil real-time requirements, and correct system functionality depends on their logical correctness as well as on their temporal correctness. in order to verify the temporal behavior of real-time systems, previous scientific work has, to a large extent, concentrated on static analysis techniques. Although these techniques offer the possibility of providing safe estimates of temporal behavior for certain cases, there are a number of cases in practice for which static analysis can not be easily applied. Furthermore, no commercial tools for timing analysis of real-world programs are available. Therefore, the developed systems have to be thoroughly tested in order to detect existing deficiencies in temporal behavior, as well as to strengthen the confidence in temporal correctness. An investigation of existing test methods shows that they mostly concentrate on testing for logical correctness. They are nor specialised in the examination of temporal correctness which is also essential to real-rime systems. For this reason, existing test procedures must be supplemented by new methods which concentrate on determining whether the system violates its specified timing constraints. Normally, a violation means that outputs are produced too early, or their computation takes too long. The task of the tester therefore is to find the input situations with the longest or shortest execution limes, in order to check whether they produce a temporal error. If the starch for such inputs is interpreted as a problem of optimization, evolutionary computation can be used to automatically find the inputs with the longest or shortest execution rimes. This automatic search for accurate test data by means of evolutionary computation is called evolutionary testing. Experiments using evolutionary testing on a number of programs with up to 1511 LOC and 5000 input parameters have successfully identified new longer and shorter execution times than had been found using other testing techniques. Evolutionary testing, therefore, seems to be a promising approach for the verification of timing constraints. A combination of evolutionary testing and systematic testing offers further opportunities to improve the test quality, and could lead to an effective test strategy for real-time systems.},
	Author = {Wegener, J and Grochtmann, M},
	Doi = {Doi 10.1023/A:1008096431840},
	Isbn = {0922-6443},
	Issn = {0922-6443},
	Journal = {Real-Time Systems},
	Keywords = {evolutionary algorithm,evolutionary optimization,evolutionary testing,genetic algorithms,real-time systems,temporal behavior,temporal correctness,test strategy,testing,validation,verification},
	Number = {3},
	Pages = {275--298},
	Title = {{Verifying timing constraints of real-time systems by means of evolutionary testing}},
	Volume = {15},
	Year = {1998}}

@book{Halili2008,
	Abstract = {"This book introduces you to JMeter (version 2.3) and test automation, providing a step-by-step guide to testing with JMeter. You will learn how to measure the performance of a website using JMeter. While it discusses test automation generally, the bulk of this book gives specific, vivid, and easy-to-understand walkthroughs of JMeter's testing tools showing what they can do, and when and how to use them. Learn to load-test your website, test its functional behaviour, and measure its performance by implementing the features of Jmeter"--Resource description p.},
	Author = {Halili, Emily H},
	Isbn = {9786611737528 6611737529 9781847192967 1847192963 1847192955 9781847192950},
	Title = {{Apache JMeter a practical beginner's guide to automated testing and performance measurement for your websites}},
	Year = {2008}}

@inproceedings{wegener1997testing,
	Author = {Wegener, Joachim and Sthamer, Harmen and Jones, Bryan F and Eyres, David E},
	Journal = {Software Quality Journal},
	Number = {2},
	Pages = {127--135},
	Publisher = {Springer},
	Title = {Testing real-time systems using genetic algorithms},
	Volume = {6},
	Year = {1997}}
	
	@book{Lewis2005,
abstract = {It is often assumed that software testing is based on clearly defined requirements and software development standards. However, testing is typically performed against changing, and sometimes inaccurate, requirements. The third edition of a bestseller, Software Testing and Continuous Quality Improvement, Third Edition provides a continuous quality framework for the software testing process within traditionally structured and unstructured environments. This framework aids in creating meaningful test cases for systems with evolving requirements. This completely revised reference provides a comprehensive look at software testing as part of the project management process, emphasizing testing and quality goals early on in development. Building on the success of previous editions, the text explains testing in a Service Orientated Architecture (SOA) environment, the building blocks of a Testing Center of Excellence (COE), and how to test in an agile development. Fully updated, the sections on test effort estimation provide greater emphasis on testing metrics. The book also examines all aspects of functional testing and looks at the relation between changing business strategies and changes to applications in development. Includes New Chapters on Process, Application, and Organizational Metrics All IT organizations face software testing issues, but most are unprepared to manage them. Software Testing and Continuous Quality Improvement, Third Editionis enhanced with an up-to-date listing of free software tools and a question-and-answer checklist for choosing the best tools for your organization. It equips you with everything you need to effectively address testing issues in the most beneficial way for your business.},
author = {Lewis, William E. and Dobbs, David and Veerapillai, Gunasekaran},
file = {:Users/naubergois/Downloads/2005 Software.Testing.and.Continuous.Quality.Improvement.2nd.Ed{\_}bagus.pdf:pdf},
isbn = {1420080733},
pages = {688},
title = {{Software testing and continuous quality improvement}},
url = {http://books.google.com/books?id=fgaBDd0TfT8C{\&}pgis=1},
year = {2005}
}


@preamble{ "\newcommand{\noopsort}[1]{} "
	# "\newcommand{\printfirst}[2]{#1} "
	# "\newcommand{\singleletter}[1]{#1} "
	# "\newcommand{\switchargs}[2]{#2#1} " }

@inproceedings{Gois2016,
	Author = {Gois, N. and Porfirio, P. and Coelho, A. and Barbosa, T.},
	Booktitle = {Proceedings of the 2016 Latin American Computing Conference (CLEI)},
	Isbn = {978-1-5090-1632-7},
	Title = {{Improving Stress Search Based Testing using a Hybrid Metaheuristic Approach}},
	Pages = {718--728},
	Year = {2016}}	

@article{Piel2010,
author = {Piel, {\'{E}}ric and Gonz{\'{a}}lez-Sanchez, Alberto and Gro{\ss}, Hans-Gerhard},
doi = {10.1007/978-3-642-16573-3},
file = {:Users/naubergois/Downloads/rbtcg{\_}preprint.pdf:pdf},
isbn = {978-3-642-16572-6},
journal = {Ictss},
number = {October},
pages = {79--94},
title = {{Testing Software and Systems}},
url = {http://dblp.uni-trier.de/db/conf/pts/ictss2010.html{\#}PielGG10},
volume = {6435},
year = {2010}
}


@phdthesis{Ganapathi2009,
abstract = {The complexity of modern computer systems makes performance modeling an invaluable resource for guiding crucial decisions such as workload management, conﬁguration management, and resource provisioning. With continually evolving systems, it is diﬃcult to obtain ground truth about system behavior. Moreover, system management policies must adapt to changes in workload and conﬁguration to continue making eﬃcient decisions. Thus, we require data-driven modeling techniques that auto-extract relationships between a system's input workload, its conﬁguration parameters, and consequent performance. This dissertation argues that statistical machine learning (SML) techniques are a powerful asset to system performance modeling. We present an SML-based methodology that extracts correlations between a workload's pre-execution characteristics or conﬁguration parameters, and post-execution performance observations. We leverage these correlations for performance prediction and optimization. We present three success stories that validate the usefulness of our methodology on storage and compute based parallel systems. In all three scenarios, we outperform state of the art alternatives. Our results strongly suggest the use of SML-based performance modeling to improve the quality of system management decisions.},
author = {Ganapathi, As},
booktitle = {UC Berkeley},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Ganapathi - 2009 - Predicting and optimizing system utilization and performance via statistical machine learning(20).pdf:pdf},
isbn = {8888888888888},
number = {UCB/EECS-2009-181},
pages = {97},
title = {{Predicting and optimizing system utilization and performance via statistical machine learning}},
url = {http://escholarship.org/uc/item/9b92g2pz.pdf http://www.mendeley.com/research/predicting-optimizing-system-utilization-performance-via-statistical-machine-learning/{\%}5Cnhttp://www.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-181.pdf},
year = {2009}
}

@article{Kiran2015,
abstract = {Unified Authentication platform is a Single sign-on (SSO) mechanism which is integrated into Web applications to remove the necessity for multiple application-specific login credentials. Unified Authentication platform (UAP) is a unique platform developed by MIMOS with capability to support multiple authentication mechanism and can be integrated to any Web application to provide Single Sign On (SSO) solution. Performance testing of such web applications using UAP poses some unique challenges because the Jmeter script does not capture all the dynamic values, such as SAML Request, Relay State, Signature Algorithm, Authorization State, Cookie Time, Persistent ID (PID), JSession ID and Shibboleth, generated using single sign-on mechanism of Unified Authentication Platform. This paper explains some of the challenges {\&} experiences to identify an appropriate solution for conducting performance testing on such web application.},
author = {Kiran, Sandhya and Mohapatra, Akshyansu and Swamy, Rajashekara},
doi = {10.1109/ISTMET.2015.7359004},
file = {:Users/naubergois/Downloads/kiran2015.pdf:pdf},
isbn = {9781479917235},
journal = {2nd International Symposium on Technology Management and Emerging Technologies, ISTMET 2015 - Proceeding},
keywords = {Jmeter,Performance Testing,Single Sign-On,Unified Authentication Platform},
pages = {74--78},
title = {{Experiences in performance testing of web applications with Unified Authentication platform using Jmeter}},
year = {2015}
}


@article{White2010,
abstract = {Virtualization has rapidly become a go-to technology for increasing efficiency in the data center. With virtualization technologies providing tremendous flexibility, even disparate architectures may be deployed on a single machine without interference. Awareness of limitations and requirements of physical hosts to be used for virtualization is important. This paper reviews the present virtualization methods, virtual computing software, and provides a brief analysis of the performance issues inherent to each. In the end we present testing results of KVM-QEMU on two current Multi-Core CPU Architectures and System Configurations.},
archivePrefix = {arXiv},
arxivId = {1010.3233},
author = {White, Joshua and Pilbeam, Adam},
doi = {10.1.1.74.371},
eprint = {1010.3233},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/White, Pilbeam - 2010 - A Survey of Virtualization Technologies With Performance Testing.pdf:pdf},
keywords = {-virtual computing,isolation,security},
pages = {6},
title = {{A Survey of Virtualization Technologies With Performance Testing}},
url = {http://arxiv.org/abs/1010.3233},
year = {2010}
}

@inproceedings{Nivas2011,
author = {Nivas, Tuli and Csallner, Cristoph},
booktitle = {European Conference on Software Engineering / Foundations of Software Engineering},
file = {::},
title = {{Managing Performance Testing With Release Certification and Data Correlation}},
year = {2011}
}
    
@article{Geiger,
abstract = {The purpose of this case study is to evaluate how and which performance testing tools which can be used in continuous integration (CI) environments. By doing so, developers can see the effects of changes immediately and react against performance problems of their applications. This will help companies to eliminate performance issues which the media is reporting about more often every day. CI provides the reference platform for executing the performance tests and the performance testing tools provide metrics like response time and percentage of errors. These metrics can be combined through CI plugins. The results of this combination can be visualized in form of graphs and tables. Through this case study, we give a short market overview of current CI servers and performance testing tools. In respect of the requirements by adesso AG, we will only evaluate performance testing tools, which can be integrated into the Atlassian Bamboo or Jenkins CI. We evaluated six performance testing tools of which four were integratable into the CI servers. Based on the results of our evaluation we will give a recommendation.},
author = {Geiger, Chris},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Geiger - 2014 - Performance Testing in Continuous Integration Environments(6).pdf:pdf},
keywords = {continuous integration environment,performance testing},
title = {{Performance Testing in Continuous Integration Environments}},
url = {ftp://ftp.informatik.uni-stuttgart.de/pub/library/medoc.ustuttgart{\_}fi/FACH-0188/FACH-0188.pdf},
year = {2014}
}


@inproceedings{Alebrahim,
abstract = {Performance as one of the critical quality requirements for the success of a software system must be integrated into software development from the beginning to prevent performance problems. Analyzing and modeling performance demands knowledge of performance experts and analysts. In order to integrate performance analysis into software analysis and design methods, performance-specific properties known as domain knowledge have to be identified, analyzed, and documented properly. In this paper, we propose the performance analysis method PoPeRA to guide the requirements engineer in dealing with performance problems as early as possible in requirements analysis. Our structured method provides support for identifying potential performance problems using performance-specific domain knowledge attached to the requirement models. To deal with identified performance problems, we make use of performance analysis patterns to be applied to the requirement models in the requirements engineering phase. To show the application of our approach, we illustrate it with the case study CoCoME, a trading system to be deployed in supermarkets for handling sales.},
author = {Alebrahim, Azadeh and Heisel, Maritta},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2855321.2855357},
isbn = {978-1-4503-3847-9},
keywords = {Computational linguistics,Requirements engineering},
title = {{Applying performance patterns for requirements analysis}},
url = {http://dx.doi.org/10.1145/2855321.2855357},
volume = {08-12-July},
year = {2015}
}
    
    
@inproceedings{Gias2014,
abstract = {In case of large scale web-based systems, scripts for performance testing are updated iteratively. In each script, multiple URLs of the system are considered depending on intuitions that those URLs will expose the performance bugs. This paper proposes a Bayesian approach for including a URL to a test script based on its probability of being time intensive. As the testing goes on the scheme adaptively updates its knowledge regarding a URL. The comparison with existing methods shows that the proposed technique performs similar in guiding applications towards intensive tasks, which helps to expose performance bugs.},
author = {Gias, Alim Ul and Sakib, Kazi},
booktitle = {Proceedings of the 28th international conference on Software engineering},
doi = {10.1145/2591062.2591139},
file = {::},
isbn = {9781450327688},
keywords = {bayesian learning,performance testing,web-based sys-},
number = {undefined},
pages = {608--609},
title = {{An adaptive bayesian approach for URL selection to test performance of large scale web-based systems}},
url = {http://dx.doi.org/10.1145/2591062.2591139},
volume = {undefined},
year = {2014}
}

@article{Lutteroth2008,
author = {Lutteroth, Christof and Weber, Gerald},
doi = {10.1109/EDOC.2008.40},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Lutteroth, Weber - 2008 - Modeling a Realistic Workload for Performance Testing.pdf:pdf},
isbn = {978-0-7695-3373-5},
journal = {2008 12th International IEEE Enterprise Distributed Object Computing Conference},
month = {sep},
pages = {149--158},
publisher = {Ieee},
title = {{Modeling a Realistic Workload for Performance Testing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4634766},
year = {2008}
}


@article{Aguilera2003,
abstract = {Many interesting large-scale systems are distributed systems of multiple communicating components. Such systems can be very hard to debug, especially when they exhibit poor performance. The problem becomes much harder when systems are composed of "black-box" components: software from many different (perhaps competing) vendors, usually without source code available. Typical solutions-provider employees are not always skilled or experienced enough to debug these systems efficiently. Our goal is to design tools that enable modestly-skilled programmers (and experts, too) to isolate performance bottlenecks in distributed systems composed of black-box nodes.We approach this problem by obtaining message-level traces of system activity, as passively as possible and without any knowledge of node internals or message semantics. We have developed two very different algorithms for inferring the dominant causal paths through a distributed system from these traces. One uses timing information from RPC messages to infer inter-call causality; the other uses signal-processing techniques. Our algorithms can ascribe delay to specific nodes on specific causal paths. Unlike previous approaches to similar problems, our approach requires no modifications to applications, middleware, or messages.},
author = {Aguilera, Marcos K. and Mogul, Jeffrey C. and Wiener, Janet L. and Reynolds, Patrick and Muthitacharoen, Athicha},
doi = {10.1145/1165389.945454},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Aguilera et al. - 2003 - Performance debugging for distributed systems of black boxes.pdf:pdf},
isbn = {1581137575},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {black box systems,distributed systems,performance analysis,performance debugging},
pages = {74},
title = {{Performance debugging for distributed systems of black boxes}},
volume = {37},
year = {2003}
}


@article{Bazilinskyy2013,
author = {Bazilinskyy, Pavlo and Brunner, Markus},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Bazilinskyy, Brunner - 2013 - Performance Engineering and Testing.pdf:pdf},
journal = {Student Conference on Optimisation of Software},
keywords = {perfomance engineering,performance,software metrics,software optimisation,testing},
title = {{Performance engineering and testing: The challenges on mobile platforms}},
url = {http://www0.cs.ucl.ac.uk/staff/Yuanyuan.Zhang/StuConOS2013/stuconos2013{\_}submission{\_}3.pdf},
year = {2013}
}

    


@book{Oliner2011,
abstract = {This thesis is concerned with understanding the behavior of complex systems, particularly in the common case where instrumentation data is noisy or incomplete. We begin with an empirical study of logs from production systems, which characterizes the content of those logs and the challenges associated with analyzing them automatically, and present an algorithm for identifying surprising messages in such logs. The principal contribution is a method, called influence, that identifies relationships among components---even when the underlying mechanism of interaction is unknown---by looking for correlated surprise. Two components are said to share an influence if they tend to exhibit surprising behavior that is correlated in time. We represent the behavior of components as surprise (deviation from typical or expected behavior) over time and use signal-processing techniques to find correlations. The method makes few assumptions about the underlying systems or the data they generate, so it is applicable to a variety of unmodified production systems, including supercomputers, clusters, and autonomous vehicles. We then extend the idea of influence by presenting a query language and online implementation, which allow the method to scale to systems with hundreds of thousands of signals. In collaboration with system administrators, we applied these tools to real systems and discovered correlated problems, failure cascades, skewed clocks, and performance bugs. According to the administrators, it also generated information useful for diagnosing and fixing these issues.},
author = {Oliner, Adam Jamison},
language = {en},
mendeley-groups = {Zotero - Zotero Library},
pages = {153},
publisher = {Stanford University},
title = {{Using Influence to Understand Complex Systems}},
url = {http://books.google.com.br/books?id=bynaAuMtiSAC},
year = {2011}
}


@article{Fritzsche2007,
abstract = {The increase in the use of parallel distributed architectures in order to solve large-scale scientific problems has generated the need for performance prediction for both deterministic applications and non-deterministic applications. The development of a new prediction methodology to estimate the execution time of a hard data-dependent parallel application that solves the traveling salesman problem (TSP) is the primary target of this study. The prediction methodology is an analytical process designed to explore a group of cities in search of patterns and/or relationships between these cities, and then to validate performance prediction for new cities sets by applying the detected patterns. The TSP problem is of considerable importance not only from a theoretical point of view. There are important cases of practical problems that can be formulated as TSP problems and many other problems are generalizations of this problem. Therefore, there is a tremendous need for TSP algorithms and still more for knowing their performance values. Three different parallel algorithms of the Euclidean TSP are used to apply the proposed methodology. The experimental results are quite promising; the capacity of prediction is greater than 75{\%}.},
author = {Fritzsche, P.C. and Rexachs, D. and Luque, E.},
doi = {10.1109/IDAACS.2007.4488453},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Fritzsche, Rexachs, Luque - 2007 - TSP Performance Prediction Using Data Mining.pdf:pdf},
isbn = {978-1-4244-1347-8},
journal = {2007 4th IEEE Workshop on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications},
keywords = {Data mining,Performance prediction,Traveling salesman problem},
title = {{TSP Performance Prediction Using Data Mining}},
year = {2007}
}


@article{Deb2011,
abstract = {As the name suggests, multi-objective optimization involves optimizing a number of objectives si- multaneously. The problem becomes challenging when the objectives are of conflict to each other, that is, the optimal solution of an objective function is different from that of the other. In solving such problems, with or without the presence of constraints, these problems give rise to a set of trade-off opti- mal solutions, popularly known as Pareto-optimal solutions. Due to the multiplicity in solutions, these problems were proposed to be solved suitably using evolutionary algorithms which use a population ap- proach in its search procedure. Starting with parameterized procedures in early nineties, the so-called evolutionary multi-objective optimization (EMO) algorithms is now an established field of research and application with many dedicated texts and edited books, commercial softwares and numerous freely downloadable codes, a biannual conference series running successfully since 2001, special sessions and workshops held at all major evolutionary computing conferences, and full-time researchers from uni- versities and industries from all around the globe. In this chapter, we provide a brief introduction to its operating principles and outline the current research and application studies of EMO.},
author = {Deb, Kalyanmoy},
doi = {2011003},
file = {:Users/naubergois/k2011003.pdf:pdf},
isbn = {0-471-87339-X},
journal = {Multi-objective evolutionary optimisation for product design and manufacturing},
pages = {1--24},
title = {{Multi-objective optimization using evolutionary algorithms: an introduction}},
year = {2011}
}

@book{Dustin1999,
abstract = {"Automated Software Testing is a comprehensive, step-by-step guide to the most effective tools, techniques, and methods for automated testing. Using numerous case studies of successful industry implementations, this book presents everything you need to know to successfully incorporate automated testing into the development process."-BOOK JACKET. "In particular, this book focuses on the Automated Test Lifecycle Methodology (ATLM), a structured process for designing and executing testing that parallels the Rapid Application Development methodology commonly used today. Automated Software Testing is designed to lead you through each step of this structured program, from the initial decision to implement automated software testing through test planning, execution, and reporting. Included are test automation and test management guidance for: acquiring management support; test tool evaluation and selection; the automated testing introduction process; test effort and test team sizing; test team composition, recruiting, and management; test planning and preparation; test procedure development guidelines; automation reuse analysis and reuse library; and best practices for test automation."-BOOK JACKET.},
author = {Dustin, Elfriede and Rashka, Jeff and Paul, John},
booktitle = {Addison-Wesley Professional},
file = {:Users/naubergois/Downloads/Elfriede Dustin, Jeff Rashka, John Paul-Automated Software Testing{\_} Introduction, Management, and Performance-Addison-Wesley Professional (1999).pdf:pdf},
isbn = {0201432870},
pages = {575},
title = {{Automated Software Testing: Introduction, Management, and Performance}},
year = {1999}
}

@book{Perry2004,
author = {Perry, William E.},
booktitle = {Jhon Wiley {\&} Sons},
doi = {10.1002/1521-3773(20010316)40:6<9823::AID-ANIE9823>3.3.CO;2-C},
file = {:Users/naubergois/Downloads/EMFST.pdf:pdf},
isbn = {9780764598371},
issn = {14337851},
title = {{Effective methods for software testing}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/cbdv.200490137/abstract$\backslash$nhttp://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Effective+Methods+for+Software+Testing{\#}2$\backslash$nhttp://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Effective+methods+for},
year = {2004}
}

@book{Kaczanowski2012,
abstract = {1782},
author = {Kaczanowski, Tomasz},
file = {:Users/naubergois/Downloads/Practical-Unit-Testing-with-JUnit-and-Mockito{\_}2013-04{\_}Tomek.Kaczanowsk.pdf:pdf},
isbn = {9788393489305},
pages = {426},
title = {{Practical unit testing with testNG and Mockito}},
year = {2012}
}

@article{Acharya2009,
abstract = {Online services such as search and live applications rely on large infrastructures in data centers, consisting of both stateless servers (e.g., web servers) and stateful servers (e.g., database servers). Acceptable performance of such infrastructures, and hence the availability of online services, rely on a very large number of parameters such as per-process resources and configurable system/application parameters. These parameters are available for collection as performance counters distributed across various machines, but services have had a hard time determining which performance counters to monitor and what thresholds to use for performance alarms in a production environment. In this paper, we present a novel framework called PerfAnalyzer, a storage-efficient and pro-active performance monitoring framework for correlating service health with performance counters. PerfAnalyzer automatically infers and builds health models for any service by running the standard suite of predeployment tests for the service and data mining the resulting performance counter data-set. A filtered set of performance counters and thresholds of alarms are produced by our framework. The health model inferred by our framework can then be used to detect performance degradation and collect detailed data for root-cause analysis in a production environment. We have applied PerfAnalyzer on five simple stress scenarios - CPU, memory, I/O, disk, and network, and two real system - Microsoft's SQL Server 2005 and IIS 7.0 Web Server, with promising results.},
author = {Acharya, Mithun and Kommineni, Vamshidhar},
doi = {10.1109/ASE.2009.95},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Acharya, Kommineni - 2009 - Mining health models for performance monitoring of services.pdf:pdf},
isbn = {9780769538914},
issn = {1527-1366},
journal = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
keywords = {Performance Monitoring,Performance evaluation},
mendeley-tags = {Performance Monitoring,Performance evaluation},
pages = {409--420},
title = {{Mining health models for performance monitoring of services}},
year = {2009}
}

@incollection{Avritzer2012a,
abstract = {Performance degradation and/or irregularity are often indicators of system instability. By applying the principle that average performance measures vary little under constant load in a stable system without periodic behavior, we can use performance metrics to anticipate instability within the system. We describe how to use that information to isolate the cause of observed instability and how to structure load tests to identify scenarios in which system instability is likely to occur. We discuss resilience assessment based on performance measurements. Specifically, we present our experience generating load tests and analyzing the performance testing results. We discuss how we have used these results for security, reliability and performance assessment. We discuss the conditions required for system stability and identify some of the causes for system instability, such as security attacks, quality problems, and queuing for system resources. We present a metric that can be used to assess some dimensions of system security, reliability and performance using data obtained from the execution of performance testing. In addition, we present the associated testing activities that are required to collect data for the required modeling and analysis activities, and to help track system security, reliability and performance. We illustrate the presented methodology with empirical results obtained by testing for security, reliability, and performance.},
author = {Avritzer, Alberto and Bondi, Andre B.},
booktitle = {Resilience Assessment and Evaluation of Computing Systems},
pages = {305--322},
title = {{Resilience Assessment Based on Performance Testing}},
year = {2012}
}

@inproceedings{Jiang2008b,
abstract = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags {\&}lt; 0.01{\%} of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice.},
author = {Jiang, Zhen Ming ZM and Hassan, Ahmed E. AE and Hamann, Gilbert and Flora, Parminder},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Jiang et al. - 2008 - Automatic identification of load testing problems(2).pdf:pdf},
pages = {307--316},
title = {{Automatic identification of load testing problems}},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=4658079{\&}url=http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4658079 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4658079},
year = {2008}
}

@inproceedings{Yu2010a,
abstract = {Testing-as-a-service (TaaS) is a new model to provide testing capabilities to end users. Users save the cost of complicated maintenance and upgrade effort, and service providers can upgrade their services without impact on the end-users. Due to uneven volumes of concurrent requests, it is important to address the elasticity of TaaS platform in a cloud environment. Scheduling and dispatching algorithms are developed to improve the utilization of computing resources. We develop a prototype of TaaS over cloud, and evaluate the scalability of the platform by increasing the test task load, analyze the distribution of computing time on test task scheduling and test task processing over the cloud, and examine the performance of proposed algorithms by comparing others.},
author = {Yu, Lian and Tsai, Wei Tek and Chen, Xiangji and Liu, Linqing and Zhao, Yan and Tang, Liangjie and Zhao, Wei},
booktitle = {Proceedings - 5th IEEE International Symposium on Service-Oriented System Engineering, SOSE 2010},
doi = {10.1109/SOSE.2010.36},
isbn = {9780769540818},
keywords = {Cloud,Cloud computing,Ontology,SaaS (Software as a Service),Scheduling and dispatching,TaaS (Testing as a Service),Testing as Service},
mendeley-tags = {Cloud,Testing as Service},
pages = {181--188},
title = {{Testing as a service over cloud}},
year = {2010}
}

@article{Yang1996,
author = {Yang, Cheer-Sun D and Pollock, Lori L},
doi = {10.1145/226295.226318},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
keywords = {Load Testing,Structural Test},
mendeley-tags = {Load Testing,Structural Test},
number = {3},
pages = {201--208},
title = {{Towards a Structural Load Testing Tool}},
url = {http://dl.acm.org/citation.cfm?id=226318 http://doi.acm.org/10.1145/226295.226318},
volume = {21},
year = {1996}
}

@article{El-far2001,
author = {El-far, Ibrahim K and Whittaker, James a},
doi = {10.1002/0471028959.sof207},
isbn = {9780471028956},
journal = {Encyclopedia of Software Engineering},
keywords = {finite state machines,grammars,markov chains,software behavior models,statecharts,test automation,test case generation,unified modeling language},
pages = {1--22},
title = {Model Based Software Testing},
year = {2001}
}


@article{Dumitrescu2004,
abstract = {We present DiPerF, a distributed performance-testing framework, aimed at simplifying and automating service performance evaluation. DiPerF coordinates a pool of machines that test a target service, collects and aggregates performance metrics, and generates performance statistics. The aggregate data collected provide information on service throughput, on service fairness' when serving multiple clients concurrently, and on the impact of network latency on service performance. Furthermore, using this data, it is possible to build predictive models that estimate a service performance given the service load. We have tested DiPerF on 100+machines on two testbeds, Grid3 and PlanetLab, and explored the performance of job submission services (pre-WS GRAM and WS GRAM) included with Globus Toolkit{\&}reg; 3.2.},
archivePrefix = {arXiv},
arxivId = {cs/0410012},
author = {Dumitrescu, Catalin and Raicu, Ioan and Ripeanu, Matei and Foster, Ian},
doi = {10.1109/GRID.2004.21},
eprint = {0410012},
isbn = {0769522564},
issn = {15505510},
journal = {Proceedings - IEEE/ACM International Workshop on Grid Computing},
pages = {289--296},
primaryClass = {cs},
title = {{DiPerF: An automated distributed Performance testing framework}},
year = {2004}
}

@article{Cai2007,
abstract = {Accurate web application performance testing relies on the use of loading tests based on a realistic client behaviour load model. Unfortunately developing such load models and associated test plans and scripts is tedious and error-prone with most existing web performance testing tools providing limited client load modelling capabilities. We describe a new approach and toolset that we have developed, MaramaMTE+, which improves the ability to model realistic web client load behaviour, automatically generates complex web application testing plans and scripts, and integrates load behaviour modelling with a generic performance engineering tool. MaramaMTE+ uses a stochastic form chart as its client loading model. A 3rd party web crawler application extracts structural information from a target web site, aggregating the collected data into a crawler database that is then used for form chart model generation. The performance engineer then augments this synthesized form probabilities. Realistic web loading tests for a 3rd party web load testing tool are then automatically generated from this resultant stochastic form chart client load model. We chart with client loading describe the development of our MaramaMTE+ environment, example usage of the tool, and compare and contrast the results obtained from our generated performance load tests against hand-built 3rd party tool load tests.},
author = {Cai, Yuhong and Grundy, John and Hosking, John},
doi = {10.1145/1321631.1321684},
isbn = {9781595938824},
journal = {Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering - ASE '07},
pages = {353},
title = {{Synthesizing client load models for performance engineering via web crawling}},
url = {http://portal.acm.org/citation.cfm?doid=1321631.1321684},
year = {2007}
}

@article{Bayan2008,
abstract = {Many software applications must provide services to hundreds or thousands of users concurrently. These applications must be load tested to ensure that they can function correctly under high load. Problems in load testing are due to problems in the load environment, the load generators, and the application under test. It is important to identify and address these problems to ensure that load testing results are correct and these problems are resolved. It is difficult to detect problems in a load test due to the large amount of data which must be examined. Current industrial practice mainly involves time-consuming manual checks which, for example, grep the logs of the application for error messages. In this paper, we present an approach which mines the execution logs of an application to uncover the dominant behavior (i.e., execution sequences) for the application and flags anomalies (i.e., deviations) from the dominant behavior. Using a case study of two open source and two large enterprise software applications, we show that our approach can automatically identify problems in a load test. Our approach flags {\&}lt; 0.01{\%} of the log lines for closer analysis by domain experts. The flagged lines indicate load testing problems with a relatively small number of false alarms. Our approach scales well for large applications and is currently used daily in practice.},
author = {Bayan, Mohamad and Cangussu, Jo{\~{a}}o W.},
doi = {10.1145/1363686.1363847},
file = {:Users/naubergois/Downloads/bayan2008.pdf:pdf},
isbn = {9781595937537},
issn = {1063-6773},
journal = {Proceedings of the 2008 ACM symposium on Applied computing - SAC '08},
pages = {661},
title = {{Automatic feedback, control-based, stress and load testing}},
url = {http://portal.acm.org/citation.cfm?doid=1363686.1363847},
year = {2008}
}

@article{Nguyen2011,
abstract = {Load testing is an important phase in the software development process.$\backslash$nIt is very time consuming but there is usually little time for it.$\backslash$nAs a solution to the tight testing schedule, software companies automate$\backslash$ntheir testing procedures. However, existing automation only reduces$\backslash$nthe time required to run load tests. The analysis of the test results$\backslash$nis still performed manually. A typical load test outputs thousands$\backslash$nof performance counters. Analyzing these counters manually requires$\backslash$ntime and tacit knowledge of the system-under-test from the performance$\backslash$nengineers. The goal of this study is to derive an approach to automatically$\backslash$nverify load tests results. We propose an approach based on a statistical$\backslash$nquality control technique called control charts. Our approach can$\backslash$na) automatically determine if a test run passes or fails and b) identify$\backslash$nthe subsystem where performance problem originated. We conduct two$\backslash$ncase studies on a large commercial telecommunication software and$\backslash$nan open-source software system to evaluate our approach. Our results$\backslash$nwarrant further development of control chart based techniques in$\backslash$nperformance verification. {\&}copy; 2011 IEEE.},
author = {Nguyen, Thanh H D and Adams, Bram and Jiang, Zhen Ming and Hassan, Ahmed E. and Nasser, Mohamed and Flora, Parminder},
doi = {10.1109/APSEC.2011.59},
isbn = {9780769546094},
issn = {15301362},
journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
keywords = {Load Testing,Mining software repository,Performance Testing},
pages = {282--289},
title = {{Automated verification of load tests using control charts}},
year = {2011}
}


@article{Shoaib2011,
abstract = {In this paper, a Layered Queueing Network (LQN) performance model is used for studying an Apache-PHP web application with PostgreSQL backend-database. Performance evaluation is done by obtaining load test measurements and by solving the LQN model. Model validation is performed by comparing the model results with the load test results. With average error of 3.77{\%} for throughput and 12.15{\%} for response times the model is shown to capture the web application's performance. Furthermore, performance analysis is done to determine the system configuration which would ease the identified bottleneck resource. ?? 2011 Elsevier B.V.},
author = {Shoaib, Yasir and Das, Olivia},
doi = {10.1016/j.entcs.2011.09.009},
file = {::},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Layered Queueing Networks,Load Testing,PHP,Performance measurement,Performance modeling and validation,Software Performance Engineering},
pages = {123--142},
publisher = {Elsevier B.V.},
title = {{Web Application Performance Modeling Using Layered Queueing Networks}},
url = {http://dx.doi.org/10.1016/j.entcs.2011.09.009},
volume = {275},
year = {2011}
}


@article{Zhang2011,
abstract = {Load tests aim to validate whether system performance is acceptable under peak conditions. Existing test generation techniques induce load by increasing the size or rate of the input. Ignoring the particular input values, however, may lead to test suites that grossly mischaracterize a system's performance. To address this limitation we introduce a mixed symbolic execution based approach that is unique in how it 1) favors program paths associated with a performance measure of interest, 2) operates in an iterative-deepening beam-search fashion to discard paths that are unlikely to lead to high-load tests, and 3) generates a test suite of a given size and level of diversity. An assessment of the approach shows it generates test suites that induce program response times and memory consumption several times worse than the compared alternatives, it scales to large and complex inputs, and it exposes a diversity of resource consuming program behavior.},
author = {Zhang, Pingyu and Elbaum, Sebastian and Dwyer, Matthew B},
doi = {10.1109/ASE.2011.6100093},
isbn = {978-1-4577-1638-6},
issn = {1938-4300},
journal = {Proceedings of the 2011 26th IEEE/ACM International Conference on Automated Software Engineering},
keywords = {-load testing,symbolic execution},
pages = {43--52},
title = {{Automatic generation of load tests}},
url = {http://dl.acm.org/citation.cfm?id=2190151 http://dx.doi.org/10.1109/ASE.2011.6100093},
year = {2011}
}

@article{Yan2012,
author = {Yan, Minzhi and Sun, Hailong and Wang, Xu and Liu, Xudong},
doi = {10.1109/CLUSTER.2012.20},
isbn = {978-0-7695-4807-4},
journal = {2012 IEEE International Conference on Cluster Computing},
keywords = {-web services,Load Testing,WebService,cloud computing,load testing,testing},
mendeley-tags = {Load Testing,WebService},
number = {2},
pages = {576--579},
title = {{Building a TaaS Platform for Web Service Load Testing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6337826},
year = {2012}
}


@article{Vasar2012,
abstract = {By allowing resources to be acquired on-demand and in variable amounts, cloud computing provides an appealing environment for deploying pilot projects and for performance testing of Web applications and services. However, setting up cloud environments for performance testing still requires a significant amount of manual effort. To aid performance engineers in this task, we developed a framework that integrates several common benchmarking and monitoring tools. The framework helps performance engineers to test applications under various configurations and loads. Furthermore, the framework supports dynamic server allocation based on incoming load using a response-time-aware heuristics. We validated the framework by deploying and stress-testing the MediaWiki application. An experimental evaluation was conducted aimed at comparing the response-time-aware heuristics against Amazon Auto-Scale. Copyright 2012 ACM.},
author = {Vasar, Martti and Srirama, Satish Narayana and Dumas, Marlon},
doi = {10.1145/2361999.2362008},
isbn = {9781450315685},
journal = {Proceedings of the WICSA/ECSA 2012 Companion Volume on - WICSA/ECSA '12},
keywords = {Cloud computing,Software architecture,World Wide W,World Wide Web},
pages = {53},
title = {{Framework for monitoring and testing web application scalability on the cloud}},
url = {http://dx.doi.org/10.1145/2361999.2362008$\backslash$nhttp://dl.acm.org/citation.cfm?doid=2361999.2362008},
year = {2012}
}

@article{Malik2013a,
author = {Malik, Haroon and Hemmati, Hadi and Hassan, Ahmed E},
isbn = {9781467330749},
pages = {1012--1021},
title = {{Automatic Detection of Performance Deviations in the Load Testing of Large Scale Systems}},
year = {2013}
}

@article{Barna2013,
author = {Barna, Cornel and Shtern, Mark and Smit, Michael and Tzerpos, Vassilios and Litoiu, Marin},
doi = {10.1145/0000000.0000000},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Barna et al. - 2013 - Mitigating DoS Attacks using Performance Model-driven Adaptive Algorithms.pdf:pdf},
number = {February},
title = {{Mitigating DoS Attacks using Performance Model-driven Adaptive Algorithms}},
volume = {X},
year = {2013}
}

@article{Jiang2015,
author = {Jiang, Zhen Ming and Hassan, Ahmed},
doi = {10.1109/TSE.2015.2445340},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {1--1},
title = {{A Survey on Load Testing of Large-Scale Software Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7123673},
volume = {5589},
year = {2015}
}

@phdthesis{Shousha2003,
author = {Shousha, Marwa},
file = {:Users/naubergois/Downloads/shousha-performancestresstestingofrealtimesystems.pdf:pdf},
school = {Carleton University},
title = {{Performance Stress Testing of Real-Time Systems Using Genetic-Algorithms}},
year = {2003}
}


@article{Avritzer1995,
abstract = {Three automatic test case generation algorithms intended to test the resource allocation mechanisms of telecommunications software systems are introduced. Although these techniques were specifically designed for testing telecommunications software, they can be used to generate test cases for any software system that is modelable by a Markov chain provided operational profile data can either be collected or estimated. These algorithms have been used successfully to perform load testing for several real industrial software systems. Experience generating test suites for five such systems is presented. Early experience with the algorithms indicate that they are highly effective at detecting subtle faults that would have been likely to be missed if load testing had been done in the more traditional way, using hand-crafted test cases. A domain-based reliability measure is applied to systems after the load testing algorithms have been used to generate test data. Data are presented for the same five industrial telecommunications systems in order to track the reliability as a function of the degree of system degradation experienced},
author = {Avritzer, A. and Weyuker, E.J.},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Avritzer, Weyuker - 1995 - The automatic generation of load test suites and the assessment of the resulting software.html:html},
issn = {0098-5589},
journal = {Software Engineering, IEEE {\ldots}},
keywords = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
mendeley-tags = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
number = {9},
pages = {705--716},
title = {{The automatic generation of load test suites and the assessment of the resulting software}},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=464549{\&}url=http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=464549 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=464549},
volume = {21},
year = {1995}
}

@incollection{Mayo2013,
abstract = {A novel framework for predicting regression test failures is proposed. The basic principle embodied in the framework is to use performance analysis tools to capture the runtime behaviour of a program as it executes each test in a regression suite. The performance information is then used to build a dynamically predictive model of test outcomes. Our framework is evaluated using a genetic algorithm for dynamic metric selection in combination with state-of-the-art machine learning classifiers. We show that if a program is modified and some tests subsequently fail, then it is possible to predict with considerable accuracy which of the remaining tests will also fail which can be used to help prioritise tests in time constrained testing environments.},
annote = {From Duplicate 2 ( 

Predicting Regression Test Failures Using Genetic Algorithm-Selected Dynamic Performance Analysis Metrics

- Mayo, Michael; Spacey, Simon )



Mayo presents a novel framework for predicting regression test failures.The framework use a performance analysis tools to capture runtime behaviour of a program},
author = {Mayo, Michael and Spacey, Simon},
editor = {Ruhe, G{\"{u}}nther and Zhang, Yuanyuan},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Mayo, Spacey - 2013 - Predicting Regression Test Failures Using Genetic Algorithm-Selected Dynamic Performance Analysis Metrics.pdf:pdf},
isbn = {978-3-642-39741-7, 978-3-642-39742-4},
keywords = {Algorithm Analysis and Problem Complexity,Computation by Abstract Devices,Pattern Recognition,Programming Languages- Compilers- Interpreters,Programming Techniques,Software Engineering,genetic metric selection,machine learning,program analysis,regression testing,test failure prediction},
mendeley-tags = {Algorithm Analysis and Problem Complexity,Computation by Abstract Devices,Pattern Recognition,Programming Languages- Compilers- Interpreters,Programming Techniques,Software Engineering,genetic metric selection,machine learning,program analysis,regression testing,test failure prediction},
month = {jan},
pages = {158--171},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Predicting Regression Test Failures Using Genetic Algorithm-Selected Dynamic Performance Analysis Metrics}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-39742-4{\_}13},
year = {2013}
}

@article{Barber2004,
author = {Barber, S},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Barber - 2004 - Creating effective load models for performance testing with incomplete empirical data.pdf:pdf},
journal = {{\ldots} Energy Conference, 2004. INTELEC 2004. 26th {\ldots}},
pages = {1--13},
title = {{Creating effective load models for performance testing with incomplete empirical data}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1410995},
year = {2004}
}

@article{Ag2006,
author = {Ag, Daimler Chrysler and Berlin, D- and Wappler, Stefan},
file = {:Users/naubergois/Downloads/tlili2006.pdf:pdf},
isbn = {1595931864},
journal = {Proceedings of the 8th annual conference on Genetic and evolutionary computation},
keywords = {Execution Time Testing,Software Tools,Software engineering,Stress testing},
pages = {1917--1924},
title = {{Improving Evolutionary Real-Time Testing Categories and Subject Descriptors}},
year = {2006}
}

@article{Afzal2008,
abstract = {Automated software test generation has been applied across the spectrum of test case design methods; this includes white-box (structural), black-box (functional), grey-box (combination of structural and functional) and non-functional testing. In this paper, we undertake a systematic mapping study to present a broad review of primary studies on the application of search-based optimization techniques to non-functional testing. The motivation is to identify the evidence available on the topic and to identify gaps in the application of search-based optimization techniques to different types of non-functional testing. The study is based on a comprehensive set of 35 papers obtained after using a multi-stage selection criteria and are published in workshops, conferences and journals in the time span 1996-2007. We conclude that the search-based software testing community needs to do more and broader studies on non-functional search-based software testing (NFSBST) and the results from our systematic map can help direct such efforts.},
author = {Afzal, Wasif and Torkar, Richard and Feldt, Robert},
isbn = {1891706225},
journal = {Proceedings of the Twentieth International Conference on Software Engineering {\&} Knowledge Engineering (SEKE'2008)},
keywords = {Search-Based Test,Stress testing,Systematic Review},
mendeley-tags = {Search-Based Test,Stress testing,Systematic Review},
number = {October 2015},
pages = {488--493},
title = {{A systematic mapping study on non-functional search-based software testing}},
url = {http://richard.torkar.googlepages.com/a{\_}systematic{\_}mapping{\_}study{\_}on{\_}non-fu.pdf},
year = {2008}
}


@article{Jiang2009a,
abstract = {The goal of a load test is to uncover functional and per- formance problems of a system under load. Performance problems refer to the situations where a system suffers from unexpectedly high response time or low throughput. It is difficult to detect performance problems in a load test due to the absence of formally-defined performance objectives and the large amount of data that must be examined. In this paper, we present an approach which automati- cally analyzes the execution logs of a load test for perfor- mance problems. We first derive the systems performance baseline from previous runs. Then we perform an in-depth performance comparison against the derived performance baseline. Case studies show that our approach produces few false alarms (with a precision of 77{\%}) and scales well to large industrial systems.},
author = {Jiang, Zhen Ming and Hassan, Ahmed E and Hamann, Gilbert and Flora, Parminder},
doi = {10.1109/ICSM.2009.5306331},
isbn = {9781424448975},
issn = {1063-6773},
journal = {2009 IEEE International Conference on Software Maintenance},
pages = {125--134},
title = {{Automated performance analysis of load tests}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5306331},
year = {2009}
}




@article{Avritzer1995,
abstract = {Three automatic test case generation algorithms intended to test the resource allocation mechanisms of telecommunications software systems are introduced. Although these techniques were specifically designed for testing telecommunications software, they can be used to generate test cases for any software system that is modelable by a Markov chain provided operational profile data can either be collected or estimated. These algorithms have been used successfully to perform load testing for several real industrial software systems. Experience generating test suites for five such systems is presented. Early experience with the algorithms indicate that they are highly effective at detecting subtle faults that would have been likely to be missed if load testing had been done in the more traditional way, using hand-crafted test cases. A domain-based reliability measure is applied to systems after the load testing algorithms have been used to generate test data. Data are presented for the same five industrial telecommunications systems in order to track the reliability as a function of the degree of system degradation experienced},
author = {Avritzer, A. and Weyuker, E.J.},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Avritzer, Weyuker - 1995 - The automatic generation of load test suites and the assessment of the resulting software.html:html},
issn = {0098-5589},
journal = {Software Engineering, IEEE {\ldots}},
keywords = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
mendeley-tags = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
number = {9},
pages = {705--716},
title = {{The automatic generation of load test suites and the assessment of the resulting software}},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=464549{\&}url=http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=464549 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=464549},
volume = {21},
year = {1995}
}


@book{Havelund2006,
author = {Havelund, Klaus and N{\'{u}}{\~{n}}ez, Manuel and Roşu, Grigore and Wolff, Burkhart},
booktitle = {Serious Games Development and Applications},
file = {:Users/naubergois/Downloads/Deterministic{\_}dynamic{\_}monitors{\_}for{\_}linea.pdf:pdf},
isbn = {9783642238338},
pages = {155},
title = {{Formal Approaches to Software Testing and Runtime Verification}},
url = {http://www.ulb.tu-darmstadt.de/tocs/79304567.pdf},
year = {2006}
}

@article{Meinke2010,
abstract = {We present an application of learning-based testing to the problem of automated test case generation (ATCG) for numerical software. Our approach uses n-dimensional polynomial models as an algorithmically learned abstraction of the SUT which supports n-wise testing. Test cases are iteratively generated by applying a satisfiability algorithm to first-order program specifications over real closed fields and iteratively refined piecewise polynomial models. We benchmark the performance of our iterative ATCG algorithm against iterative random testing, and empirically analyse its performance in finding injected errors in numerical codes. Our results show that for software with small errors, or long mean time to failure, learning-based testing is increasingly more efficient than iterative random testing. {\textcopyright} 2010 IFIP International Federation for Information Processing.},
author = {Meinke, Karl and Niu, Fei},
doi = {10.1007/978-3-642-16573-3_16},
file = {:Users/naubergois/Downloads/64350220.pdf:pdf},
isbn = {3642165729},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {221--235},
title = {{A learning-based approach to unit testing of numerical software}},
volume = {6435 LNCS},
year = {2010}
}


@article{Kamali2007,
abstract = {In traditional optimal control and design problems, the control gains and design parameters are usually derived to minimize a cost function reflecting the system performance and control effort. One major challenge of such approaches is the selection of weighting matrices in the cost function, which are usually determined via trial-and-error and human intuition. While various techniques have been proposed to automate the weight selection process, they either can not address complex design problems or suffer from slow convergence rate and high computational costs. We propose a layered approach based on Q-learning, a reinforcement learning technique, on top of genetic algorithms (GA) to determine the best weightings for optimal control and design problems. The layered approach allows for reuse of knowledge. Knowledge obtained via Q-learning in a design problem can be used to speed up the convergence rate of a similar design problem. Moreover, the layered approach allows for solving optimizations that cannot be solved by GA alone. To test the proposed method, we perform numerical experiments on a sample active-passive hybrid vibration control problem, namely adaptive structures with active-passive hybrid piezoelectric networks. These numerical experiments show that the proposed Q-learning scheme is a promising approach for automation of weight selection for complex design problems. (27 References).},
author = {Kamali, Kaivan and Jiang, L. J. and Yen, John and Wang, K. W.},
doi = {10.1115/1.2739502},
file = {:Users/naubergois/Downloads/kamali2007.pdf:pdf},
isbn = {0-7918-4739-X},
issn = {15309827},
journal = {Journal of Computing and Information Science in Engineering},
keywords = {genetic algorithms,optimal control,q-learning},
number = {December 2007},
pages = {302},
title = {{Using Q-Learning and Genetic Algorithms to Improve the Efficiency of Weight Adjustments for Optimal Control and Design Problems}},
volume = {7},
year = {2007}
}

	
@inproceedings{sato2015automatic,
  title={Automatic Generation of Specification-Based Test Cases by Applying Genetic Algorithms in Reinforcement Learning},
  author={Sato, Yuji and Sugihara, Taku},
  booktitle={International Workshop on Structured Object-Oriented Formal Language and Method},
  pages={59--71},
  year={2015},
  organization={Springer}
}	
	
@article{Boyan2000,
abstract = {This paper describes algorithms that learn to improve search performance on large-scale optimization tasks. The main algorithm, STAGE, works by learning an evaluation function that predicts the outcome of a local search algorithm, such as hillclimbing or Walksat, from features of states visited during search. The learned evaluation function is then used to bias future search trajectories toward better optima on the same problem. Another algorithm, X-STAGE, transfers previously learned evaluation functions to new, similar optimization problems. Empirical results are provided on seven large-scale optimization domains: bin-packing, channel routing, Bayesian network structure-finding, radiotherapy treatment planning, cartogram design, Boolean satisfiability, and Boggle board setup.},
author = {Boyan, Justin A. and Moore, Andrew W.},
file = {:Users/naubergois/Downloads/boyan00a.pdf:pdf},
issn = {1533-7928},
journal = {Journal of Machine Learning Research},
pages = {77--112},
title = {{Learning Evaluation Functions to Improve Local Search}},
url = {http://citeseer.nj.nec.com/boyan00learning.html},
volume = {1},
year = {2000}
}


@book{talbi2009metaheuristics,
  title={Metaheuristics: from design to implementation},
  author={Talbi, El-Ghazali},
  volume={74},
  year={2009},
  publisher={John Wiley \& Sons}
}

@book{Battiti2009,
abstract = {This book is about learning for problem solving. [...] Human problem solving is strongly connected to learning. Learning takes places when the problem at hand is not well known at the beginning, and its structure becomes more and more clear when more experience with the problem is available. [...] What is critical for men is critical also in many human-developed problem solving strategies. It is not surprising that many methods for solving problems in Artificial Intelligence, Operations Research and related areas, follow the search scheme [...] We aim at giving the main principles and at developing some fresh intuition for the approaches. We like mathematics but we also think that hiding the underlying motivations and sources of inspiration takes some color out of the scientific work [...]. On the other hand, pictures and hand-waving can be very dangerous in isolation and we try to avoid these pitfalls by giving also the basic equations when possible, or by at least directing the reader to the bibliographic references for deepening a topic. The point of view of the book is to look at the zoo of different optimization beasts to underline opportunities for learning and self-tuning strategies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Battiti, Roberto and Brunato, Mauro and Mascia, Franco},
booktitle = {Operations Research/ Computer Science Interfaces Series},
doi = {10.1007/978-0-387-09624-7},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/book{\_}reactive{\_}search{\_}and{\_}iIntelligent{\_} optimization.pdf:pdf},
isbn = {9780387096230},
issn = {1387666X},
pmid = {25246403},
title = {{Reactive search and intelligent optimization}},
volume = {45},
year = {2009}
}


@article{Smith2002,
author = {Smith, C.U. and Williams, L.G.},
file = {:Users/naubergois/Downloads/24fe255149e4fc0d7e1e8924c243a85dd676.pdf:pdf},
journal = {Cmg-Conference-},
pages = {797--806},
title = {{Software Performance AntiPatterns; Common Performance Problems and their Solutions}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.6968{\&}rep=rep1{\&}type=pdf},
volume = {2},
year = {2002}
}

@article{Bennett2006,
abstract = {The fields of machine learning and mathematical programming are increasingly intertwined. Optimization problems lie at the heart of most machine learning approaches. The Special Topic on Machine Learning and Large Scale Optimization examines this interplay. Machine learning researchers have embraced the advances in mathematical programming allowing new types of models to be pursued. The special topic includes models using quadratic, linear, second-order cone, semi-definite, and semi-infinite programs. We observe that the qualities of good optimization algorithms from the machine learning and optimization perspectives can be quite different. Mathematical programming puts a premium on accuracy, speed, and robustness. Since generalization is the bottom line in machine learning and training is normally done off-line, accuracy and small speed improvements are of little concern in machine learning. Machine learning prefers simpler algorithms that work in reasonable computational time for specific classes of problems. Reducing machine learning problems to well-explored mathematical programming classes with robust general purpose optimization codes allows machine learning researchers to rapidly develop new techniques. In turn, machine learning presents new challenges to mathematical programming. The special issue include papers from two primary themes: novel machine learning models and novel optimization approaches for existing models. Many papers blend both themes, making small changes in the underlying core mathematical program that enable the develop of effective new algorithms.},
archivePrefix = {arXiv},
arxivId = {math/0601771},
author = {Bennett, Kristin P},
doi = {10.1051/ps},
eprint = {0601771},
file = {:Users/naubergois/Downloads/MLOPT-intro06a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {convex optimization,machine learning,mathematical programming},
number = {November},
pages = {1265--1281},
primaryClass = {math},
title = {{The Interplay of Optimization and Machine Learning Research}},
url = {http://portal.acm.org/citation.cfm?id=1248593},
volume = {7},
year = {2006}
}


@article{Gambardella1995,
author = {Gambardella, Luca M and Dorigo, Marco},
file = {:Users/naubergois/Downloads/gambardella95-icml (1).pdf:pdf},
pages = {252--260},
title = {{Ant-Q : A Reinforcement Learning approach to the traveling salesman problem}},
volume = {5625},
year = {1995}
}

@article{Matsuura2015,
author = {Matsuura, Jackson and Bianchi, Reinaldo A C},
file = {:Users/naubergois/Downloads/sbia2815.pdf:pdf},
number = {March},
title = {{Heuristically Accelerated Q – Learning : a new approach to speed up Reinforcement Learning}},
year = {2015}
}




@article{Wang2013,
author = {Wang, Xingen and Zhou, Bo and Li, Wei},
doi = {10.1080/02533839.2012.726028},
file = {:Users/naubergois/Downloads/wang2013.pdf:pdf},
issn = {0253-3839},
journal = {Journal of the Chinese Institute of Engineers},
keywords = {Model Based Test,Stress testing,load testing,markov chains,usage model},
number = {1},
pages = {74--86},
title = {{Model-based load testing of web applications}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02533839.2012.726028},
volume = {36},
year = {2013}
}


@article{Baars2011,
abstract = {The Future Internet will be a complex interconnection$\backslash$nof services, applications, content and media, on which$\backslash$nour society will become increasingly dependent. Time to$\backslash$nmarket is crucial in Internet applications and hence$\backslash$nrelease cycles grow ever shorter. This, coupled with$\backslash$nthe highly dynamic nature of the Future Internet will$\backslash$nplace new demands on software testing. Search-Based$\backslash$nTesting is ideally placed to address these emerging$\backslash$nchallenges. Its techniques are highly flexible and$\backslash$nrobust to only partially observable systems. This paper$\backslash$npresents an overview of Search-Based Testing and$\backslash$ndiscusses some of the open challenges remaining to make$\backslash$nsearch-based techniques applicable to the Future$\backslash$nInternet.},
author = {Baars, Arthur I and Lakhotia, Kiran and Vos, Tanja E J and Wegener, Joachim},
file = {:Users/naubergois/Downloads/fedcsis11.pdf:pdf},
isbn = {9788360810392},
journal = {Federated Conference on Computer Science and Information Systems (FedCSIS 2011)},
keywords = {Evolutionary computation,Internet,Optimisation,SBSE,Search Based Test,Search problems,Software,Testing,evolutionary testing,future Internet testing,genetic algorithms,genetic programming,search-based testing,software testing,time to market},
pages = {917--923},
title = {{Search-based testing, the underlying engine of Future Internet testing}},
url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=6078178},
year = {2011}
}


@article{Brown2003,
author = {Brown, Matthew a and Tapolcsanyi, Eli},
file = {:Users/naubergois/Downloads/Brown-mock-objects.pdf:pdf},
journal = {Matrix},
pages = {1--17},
title = {{Mock Object Patterns}},
year = {2003}
}


@article{Hunt2002,
author = {Hunt, Editors Andy and Thomas, Dave and Pragmatic, I The and Hunt, Andy and Mackinnon, Tim and Freeman, Steve},
doi = {10.1109/MS.2004.1259177},
file = {:Users/naubergois/Downloads/may{\_}02{\_}mock.pdf:pdf},
issn = {0740-7459},
journal = {Ieee Software},
number = {June},
pages = {22--24},
title = {{Software Construction}},
year = {2002}
}

@article{Bertolino2008,
isbn = {978-3-540-68514-2, 978-3-540-68524-1},
issn = {978-3-540-68514-2},
journal = {Testing of Software and {\ldots}},
pages = {266--282},
title = {{Model-based generation of testbeds for web services}},
year = {2008}
}

@book{GendreauMichelandPotvin2010,
author = {{Gendreau, Michel and Potvin}, Jean-Yves},
doi = {10.1007/978-1-4614-1900-6},
file = {:Users/naubergois/Downloads/Artificial{\_}Immune{\_}Systems.pdf:pdf},
isbn = {9781441979605},
title = {{Handbook of Metaheuristics}},
volume = {157},
year = {2010}
}




@article{Mackinnon2001,
abstract = {Unit testing is a fundamental practice in Extreme Programming, but most non-trivial code is difficult to test in isolation. It is hard to avoid writing test suites that are complex, incomplete, and difficult to maintain and interpret. Using Mock Objects for unit testing improves both domain code and test suites. They allow unit tests to be written for everything, simplify test structure, and avoid polluting domain code with testing infrastructure.},
author = {Mackinnon, Tim and Freeman, Steve and Craig, Philip},
file = {:Users/naubergois/Downloads/mockobjects.pdf:pdf},
isbn = {0201710404},
journal = {Extreme programming examined},
keywords = {extreme programming,mock objects,stubs,unit testing},
pages = {287--301},
title = {{Endo-Testing : Unit Testing with Mock Objects}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.3214{\&}rep=rep1{\&}type=pdf},
year = {2001}
}



@article{Wert2013a,
abstract = {Performance problems pose a significant risk to software vendors. If left undetected, they can lead to lost customers, increased operational costs, and damaged reputation. Despite all efforts, software engineers cannot fully prevent performance problems being introduced into an application. Detecting and resolving such problems as early as possible with minimal effort is still an open challenge in software performance engineering. In this paper, we present a novel approach for Performance Problem Diagnostics (PPD) that systematically searches for well-known performance problems (also called performance antipatterns) within an application. PPD automatically isolates the problem's root cause, hence facilitating problem solving. We applied PPD to a well established transactional web e-Commerce benchmark (TPC-W) in two deployment scenarios. PPD automatically identified four performance problems in the benchmark implementation and its deployment environment. By fixing the problems, we increased the maximum throughput of the benchmark from 1800 requests per second to more than 3500.},
author = {Wert, Alexander and Happe, Jens and Happe, Lucia},
doi = {10.1109/ICSE.2013.6606601},
file = {:Users/naubergois/Downloads/ICSE-2013-PerformanceProblemDiagnostics.pdf:pdf},
isbn = {9781467330763},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {measurement,performance,problem detection},
number = {May},
pages = {552--561},
title = {{Supporting swift reaction: Automatically uncovering performance problems by systematic experiments}},
year = {2013}
}

@article{Smith2003,
abstract = {Performance antipatterns document common software performance problems as well as their solutions. These problems are often introduced during the architectural or design phases of software development, but not detected until later in testing or deployment. Solutions usually require software changes as opposed to system tuning changes. This paper presents three new performance antipatterns and gives examples to illustrate them. These antipatterns will help developers and performance engineers avoid common perfor- mance problems. 1.0},
author = {Smith, Connie U and Williams, Lloyd G},
file = {:Users/naubergois/Downloads/moreanti.pdf:pdf},
journal = {Computer Measurement Group Conference},
pages = {717--725},
title = {{More New Software Performance AntiPatterns: EvenMore Ways to Shoot Yourself in the Foot}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.4517{\&}rep=rep1{\&}type=pdf},
year = {2003}
}



@article{Glover1986,
abstract = {Tabu Search is a meta-heuristic that guides a local heuristic search procedure to explore the solution space beyond local optimality. One of the main components of Tabu Search of Tabu Search is its use of adaptive memory, which creates a more flexible search behavior.},
author = {Glover, Fred and Mart{\'{i}}, Rafael},
file = {:Users/naubergois/Downloads/ts2.pdf:pdf},
journal = {Tabu Search},
pages = {1--16},
title = {{Tabu Search}},
year = {1986}
}

@article{Gay,
author = {Gay, Gregory},
file = {:Users/naubergois/Downloads/16mockito.pdf:pdf},
keywords = {automated unit test generation,real faults,search-based testing},
pages = {1--6},
year={2016},
title = {{Challenges in Using Search-Based Test Generation to Identify Real Faults in Mockito}}
}

@article{Deb2000,
abstract = {Multi-objective evolutionary algorithms which use non-dominated sorting and sharing have been mainly criticized for their (i) O(MN 3) computational complexity (where M is the number of objectives and N is the population size), (ii) non-elitism approach, and (iii) the need for specifying a sharing parameter. In this paper, we suggest a non-dominated sorting based multi-objective evolutionary algorithm (we called it the Non-dominated Sorting GA-II or NSGA-II) which alleviates all the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN 2) computational complexity is presented. Second, a selection operator is presented which creates a mating pool by combining the parent and child populations and selecting the best (with respect to fitness and spread) N solutions. Simulation results on five difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to PAES and SPEA—two other elitist multi-objective EAs which pay special attention towards creating a diverse Pareto-optimal front. Because of NSGA-II's low computational requirements, elitist approach, and parameter-less sharing approach, NSGA-II should find increasing applications in the years to come.},
author = {Deb, Kalyanmoy and Agrawal, Samir and Pratap, Amrit and Meyarivan, T},
doi = {10.1007/3-540-45356-3_83},
file = {:Users/naubergois/Downloads/2-a.pdf:pdf},
isbn = {978-3-540-41056-0},
issn = {10871357},
journal = {Parallel Problem Solving from Nature PPSN VI},
mendeley-groups = {Metaheuristics/MultiObjective},
pages = {849--858},
pmid = {18559531},
title = {{A fast elitist non-dominated sorting genetic algorithm for multi-objective optimization: NSGA-II}},
url = {http://repository.ias.ac.in/83498/},
year = {2000}
}

@article{DiAlesio2017,
author = {Di Alesio, Stefano and Sen, Sagar},
doi = {10.1007/s10270-017-0585-x},
issn = {1619-1366},
journal = {Software and Systems Modeling},
keywords = {UML/MARTE,Real-time systems,Safety-critical systems,Performance tuning,Stress testing,Constrained optimization,constrained optimization,critical systems,marte,performance tuning,real-time systems,safety-,stress testing,uml},
publisher = {Springer Berlin Heidelberg},
title = {{Using UML/MARTE to support performance tuning and stress testing in real-time systems}},
url = {http://link.springer.com/10.1007/s10270-017-0585-x},
year = {2017}
}


@article{Yoo2007,
abstract = {Previous work has treated test case selection as a single objective optimisation problem. This paper introduces the concept of Pareto efficiency to test case selection. The Pareto efficient approach takes multiple objectives such as code coverage, past fault-detection history and execution cost, and constructs a group of non-dominating, equivalently optimal test case subsets. The paper describes the potential bene?ts of Pareto efficient multi-objective test case selection, illustrating with empirical studies of two and three objective formulations.},
author = {Yoo, Shin and Harman, Mark},
doi = {10.1145/1273463.1273483},
file = {:Users/naubergois/Downloads/yoo07 (1).pdf:pdf},
isbn = {9781595937346},
journal = {Proceedings of the 2007 international symposium on Software testing and analysis - ISSTA '07},
keywords = {multi-objective evolution-,test case selection},
mendeley-groups = {Search-Based Tests/Multi objective tests/Test Case Selection,Search-Based Tests/Multi objective tests/NSGA-II,Search-Based Tests/Multi objective tests/Multo-objective tests},
pages = {140},
title = {{Pareto efficient multi-objective test case selection}},
url = {http://doi.acm.org/10.1145/1273463.1273483{\%}5Cnhttp://dl.acm.org/ft{\_}gateway.cfm?id=1273483{\&}type=pdf{\%}5Cnhttp://portal.acm.org/citation.cfm?doid=1273463.1273483},
year = {2007}
}


@article{Wert2014,
abstract = {Performance problems such as high response times in software applications have a significant effect on the customer's satisfaction. In enterprise applications, performance problems are frequently manifested in inefficient or unnecessary communication patterns between software components originating from poor architectural design or implementation. Due to high manual effort, thorough performance analysis is often neglected, in practice. In order to overcome this problem, automated engineering approaches are required for the detection of performance problems. In this paper, we introduce several heuristics for measurement-based detection of well-known performance anti-patterns in inter-component communications. The detection heuristics comprise load and instrumentation descriptions for performance tests as well as corresponding detection rules. We integrate these heuristics with Dynamic Spotter, a framework for automatic detection of performance problems. We evaluate our heuristics on four evaluation scenarios based on an e-commerce benchmark (TPC-W) where the heuristics detect the expected communication performance anti-patterns and pinpoint their root causes. Copyright {\&}copy; 2014 ACM 978-1-4503-2577-6/14/06 ...{\$}15.00.},
author = {Wert, Alexander and Oehler, Marius and Heger, Christoph and Farahbod, Roozbeh},
doi = {10.1145/2602576.2602579},
file = {:Users/naubergois/Downloads/2014-qosa-messaging.pdf:pdf},
isbn = {9781450325776},
journal = {QoSA 2014 - Proceedings of the 10th International ACM SIGSOFT Conference on Quality of Software Architectures (Part of CompArch 2014)},
keywords = {Application programs;Customer satisfaction;},
pages = {3--12},
title = {{Automatic detection of performance anti-patterns in inter-component communications}},
url = {http://dx.doi.org/10.1145/2602576.2602579},
year = {2014}
}

@article{Arcelli2012,
abstract = {Identifying and removing the causes of poor performance in software systems are complex problems due to a variety of factors to take into account. Nowadays these problems are usually tackled after the software deployment only with human-based means, which frequently boil down to developer skills and previous experiences. Performance antipatterns can be used to cope with these problems since they capture typical design patterns that are known leading to performance problems, as well as refactoring actions that can be taken to remove them. The goal of this paper is to introduce an approach that allows the refactoring of architectural models, based on antipatterns, that aims at providing performance improvement. To this end, we use a Role-Based Modeling Language to represent: (i) antipattern problems as Source Role Models (SRMs), and (ii) antipattern solutions as Target Role Models (TRMs). Hence, SRM-TRM pairs represent new instruments in the hands of developers to achieve architectural model refactorings aimed at removing sources of performance problems. Model refactoring for antipattern removal can be in fact obtained by replacing an SRM with the corresponding TRM. This approach has been applied to a case study in the e-commerce domain, whose experimental results demonstrate its effectiveness. Copyright {\textcopyright} 2012 ACM.},
author = {Arcelli, Davide and Cortellessa, Vittorio and Trubiani, Catia},
doi = {10.1145/2304696.2304704},
file = {:Users/naubergois/Downloads/antipatterns-QoSA-2012.pdf:pdf},
isbn = {9781450313469},
journal = {Proceedings of the 8th international ACM SIGSOFT conference on Quality of Software Architectures (QoSA '12)},
keywords = {model refactoring,performance an-,software performance},
pages = {33--42},
title = {{Antipattern-Based Model Refactoring for Software Performance Improvement}},
url = {http://doi.acm.org/10.1145/2304696.2304704},
year = {2012}
}

@article{Cortellessa2007,
author = {Cortellessa, Vittorio and Frittella, Laurento},
file = {:Users/naubergois/Downloads/10.1007@978-3-540-75211-013.pdf:pdf},
keywords = {architectural,feedback,layered queueing networks,performance indices,software performance},
pages = {171--185},
title = {{A Framework for Automated Generation of Architectural Feedback from Software Performance Analysis}},
year = {2007}
}

@article{Smith2000,
author = {Smith, Connie U. and Williams, Lloyd G.},
doi = {10.1145/350391.350420},
file = {:Users/naubergois/Downloads/antipat.pdf:pdf},
isbn = {158113195X},
journal = {Proceedings of the second international workshop on Software and performance  - WOSP '00},
pages = {127--136},
title = {{Software performance antipatterns}},
url = {http://portal.acm.org/citation.cfm?doid=350391.350420},
year = {2000}
}



@book{Halili2008,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Halili, Emily H.},
booktitle = {PACKT Publishing},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {jmeter},
pmid = {25246403},
title = {{Apache JMeter: A practical beginner's guide to automated testing and performance measurement for your websites.}},
year = {2008}
}

@article{Aleti2016,
author = {Aleti, Aldeida and Moser, I. and Grunske, Lars},
doi = {10.1007/s10515-016-0197-7},
isbn = {1051501601},
issn = {15737535},
journal = {Automated Software Engineering},
keywords = {Fitness landscape characterisation,Genetic algorithms,Test data generation},
pages = {1--19},
title = {{Analysing the fitness landscape of search-based software testing problems}},
year = {2016}
}


@book{Jaziri2008,
author = {Jaziri, Wassim},
isbn = {9783902613349},
pages = {294},
title = {{Local Search Techniques: Focus on Tabu Search}},
year = {2008}
}


@article{Blum2003,
abstract = {The emergence of metaheuristics for solving difficult combinatorial optimization problems is one of the most notable achievements of the last two decades in operations research. This paper provides an account of the most recent developments in the field and identifies some common issues and trends. Examples of applications are also reported for vehicle routing and scheduling problems.},
author = {Blum, C. and Roli, A.},
doi = {10.1007/s10479-005-3971-7},
isbn = {0254-5330},
issn = {02545330},
journal = {ACM Computing Surveys},
keywords = {Combinatorial optimization,Metaheuristics,Unifying framework,Vehicle routing},
number = {3},
pages = {189--213},
title = {{Metaheuristics in combinatorial optimization: overview and conceptual comparison}},
volume = {35},
year = {2003}
}


@incollection{raidl2010metaheuristic,
  title={Metaheuristic hybrids},
  author={Raidl, G{\"u}nther R and Puchinger, Jakob and Blum, Christian},
  booktitle={Handbook of metaheuristics},
  pages={469--496},
  year={2010},
  publisher={Springer}
}

@article{DiAlesio2014,
	Abstract = {Real-Time Embedded Systems (RTES) in safety-critical domains, such as maritime and energy, must satisfy strict performance requirements to be deemed safe. Therefore, such systems have to be thoroughly tested to ensure their correct behavior even under the worst operating conditions. In this paper, we address the need of deriving worst case scenarios with respect to three common performance requirements, namely task deadlines, response time, and CPU usage. Specifically, we investigate whether this worst-case analysis can be effectively re-expressed as a Constrained Optimization Problem (COP) over the space of possible inputs to the system. Solving this problem means finding the sets of inputs that maximize the chance to violate performance requirements at runtime. Such inputs can in turn be used to test if the target RTES meets the expected performance even in the worst case. We develop an OPL model for IBM ILOG CP Optimizer that implements a task priority-based preemptive scheduling, and apply it to a case study from the maritime and energy domain. Our validation shows that (1) the input to our model can be provided with reasonable effort in an industrial setting, and (2) the COP effectively identifies test cases that maximize deadline misses, response time, and CPU usage.},
	Author = {{Di Alesio}, Stefano and Nejati, Shiva and Briand, Lionel and Gotlieb, Arnaud},
	Doi = {10.1007/978-3-319-10428-7{\_}58},
	Journal = {Principles and Practice of Constraint Programming},
	Pages = {813--830},
	Title = {{Worst-Case Scheduling of Software Tasks -- A Constraint Optimization Model to Support Performance Testing}},}

@article{DiAlesio2013,
	Abstract = {Safety-critical Real Time Embedded Systems (RT-ESs) are usually subject to strict timing and performance requirements that must be satisfied for the system to be deemed safe. In this paper, we use effective search strategies whose goal is finding worst case scenarios with respect to deadline misses. Such scenarios can in turn be used to test the target RTES and ensure that it satisfies its timing requirements even under worst case conditions. Specifically, we develop an approach based on Constraint Programming (CP) to automate the generation of test cases that reveal, or are likely to, task deadline misses. We evaluate it through a comparison with a state-of-the-art approach based on Genetic Algorithms (GA). In particular, we compare CP and GA in five case studies for efficiency, effectiveness, and scalability. Our experimental results show that, on the largest and more complex case studies, CP performs significantly better than GA. Furthermore, CP offers some advantages over GA, such as it guarantees a complete search when there is sufficient time, and, being deterministic, it doesn't rely on parameters that potentially have a significant effect on the search and therefore need to be tuned. Hence, we conclude that our results are encouraging and suggest this is an advantageous approach for stress testing of RTESs with respect to timing constraints.},
	Author = {{Di Alesio}, S and Nejati, S and Briand, L and Gotlieb, A},
	Doi = {10.1109/ISSRE.2013.6698915},
	File = {:Users/naubergois/Documents/10.0000@www.computer.org@generic-DD33B05EC8B4.pdf:pdf},
	Isbn = {9781479923663},
	Journal = {IEEE Xplore},
	Keywords = {constraint pro-,real-time systems,stress testing},
	Pages = {158--167},
	Title = {{Stress testing of task deadlines: A constraint programming approach}},
	Year = {2013}}

@article{Alesio2015,
	Author = {Alesio, Stefano D I and Briand, Lionel C and Nejati, Shiva and Gotlieb, Arnaud},
	File = {:Users/naubergois/Documents/a4-dialesio.pdf:pdf},
	Journal = {ACM Transactions on Software Engineering and Methodology},
	Number = {1},
	Title = {{Combining Genetic Algorithms and Constraint Programming}},
	Volume = {25},
	Year = {2015}}

@article{Raidl2006,
	Abstract = {Manifold possibilities of hybridizing individual metaheuristics with each other and/or with algorithms from other fields exist. A large number of publications documents the benefits and great success of such hybrids. This article overviews several popular hybridization approaches and classifies them based on various characteristics. In particular with respect to low-level hybrids of different metaheuristics, a unified view based on a common pool template is described. It helps in making similarities and different key components of existing metaheuristics explicit. We then consider these key components as a toolbox for building new, effective hybrid metaheuristics. This approach of thinking seems to be superior to sticking too strongly to the philosophies and historical backgrounds behind the different metaheuristic paradigms. Finally, particularly promising possibilities of combining metaheuristics with constraint programming and integer programming techniques are highlighted.},
	Author = {Raidl, R},
	Doi = {10.1007/11890584{\_}1},
	File = {:Users/naubergois/Documents/pres{\_}gunther.pdf:pdf},
	Isbn = {9783540463849},
	Issn = {03029743},
	Journal = {Hybrid Metaheuristics (LNCS 4030)},
	Pages = {1--12},
	Title = {{A Unified View on Hybrid Metaheuristics}},
	Year = {2006}}

@article{Pohlheim2005,
	Abstract = {Whereas the verification of non-safety-related embedded software typically focuses on demonstrating that the implementation fulfills its functional requirements, this is not sufficient for safety-relevant systems. In this case, the control software must also meet application- specific safety requirements.Safety requirements typically arise from the application of hazard and/or safety analysis techniques, e.g., FMEA, FTA or SHARD. During the downstream development process it must be shown that these requirements cannot be violated. This can be achieved utilizing different techniques. One way of providing evidence that violations of the safety properties identified cannot occur is to thoroughly test each of the safety requirements.This paper introduces Evolutionary Safety Testing (EST), a fully automated procedure for the safety testing of embedded control software. EST employs extended evolutionary algorithms in an optimization process which aggressively tries to find test data sequences that cause the test object to violate a given safety requirement.A compact description formalism for input sequences for safety testing is presented, which is compatible with description techniques used during other test process stages. This compact description allows 1) an efficient application of evolutionary algorithms (and other optimization techniques) and 2) the description of long test sequences necessary for the adequate stimulation of real-world systems. The objective function is designed in such a way that optimal values represent test data sequences which violate a given safety requirement. By means of repeated input sequence generation, software execution and the subsequent evaluation of the objective function each safety requirement is extensively tested.The use of EST for the safety testing of automotive control software is demonstrated using safety requirements of an adaptive cruise control (ACC) system.The EST approach can easily be integrated into an overall software test strategy which combines different test design techniques with specific test objectives.},
	Author = {Pohlheim, Hartmut and Conrad, Mirko and Griep, Arne},
	Doi = {10.4271/2005-01-0750},
	Journal = {Analysis},
	Number = {724},
	Pages = {804----814},
	Title = {{Evolutionary Safety Testing of Embedded Control Software by Automatically Generating Compact Test Data Sequences}},
	Year = {2005}}

@article{Gross2000,
	Abstract = {Software architecture design approaches typically treat architecture as an abstraction of the implemented system. However, doing so means that the concepts, languages, notations, and tools for architecture are much more closely related to those of detailed design and implementation than to those of software requirements. Thus the gap between requirements and architecture represents a paradigm shift, while that between architecture and detailed design does not. Global Analysis, which is part of the Siemens Four Views architecture design approach, is a set of activities that serves to reduce the magnitude of this gap by guiding the architecture design process, capturing design rationale, and supporting traceability between requirements and architecture. In this paper Global Analysis is re-examined in light of five years of teaching it, reflecting on it, comparing it to other approaches, and examining how it was applied in four new systems. This experience confirms the value of the Global Analysis activities and the importance of capturing its results. In some cases the benefit went beyond that envisioned, and in other cases Global Analysis was not applied as expected. Because the templates that are provided for Global Analysis results have such a strong influence on how the activities were performed, this will be the focus of future changes},
	Author = {Gross, Hg and Jones, Bryan F and Eyres, David E},
	Doi = {10.1049/ip-sen},
	File = {:Users/naubergois/Documents/gross2000.pdf:pdf},
	Isbn = {0818669101},
	Issn = {14625970},
	Journal = {Software, IEE Proceedings-},
	Number = {2},
	Pages = {25--30},
	Pmid = {18015135},
	Title = {{Structural performance measure of evolutionary testing applied to worst-case timing of real-time systems}},
	Volume = {147},
	Year = {2000}}

@article{Smeral2014,
	Author = {\v{S}meral, Ron},
	File = {:Users/naubergois/Dropbox/dp.pdf:pdf},
	Title = {{Modern Performance Tools Applied}},
	Year = {2014}}

@article{Puchinger2005,
	Abstract = {In this survey we discuss different state-of-the-art approaches of combining exact algorithms and metaheuristics to solve combinatorial optimization problems. Some of these hybrids mainly aim at providing optimal solutions in shorter time, while others primarily focus on getting better heuristic solutions. The two main categories in which we divide the approaches are collaborative versus integrative combinations.We further classify the different techniques in a hierarchical way. Altogether, the surveyed work on combinations of exact algorithms and metaheuristics documents the usefulness and strong potential of this research direction.},
	Author = {Puchinger, Jakob and Raidl, R},
	Doi = {10.1007/11499305\_5},
	File = {:Users/naubergois/Documents/puchinger-05.pdf:pdf},
	Isbn = {9783540263197},
	Issn = {03029743},
	Journal = {Artificial Intelligence and Knowledge Engineering Applications a Bioinspired Approach},
	Pages = {41--53},
	Title = {{Combining Metaheuristics and Exact Algorithms in Combinatorial Optimization : A Survey and Classification}},
	Volume = {3562},
	Year = {2005}}

@article{Blum2012,
	Abstract = {Research in metaheuristics for combinatorial optimization problems has lately experienced a noteworthy shift towards the hybridization of metaheuristics with other techniques for optimization. At the same time, the focus of research has changed from being rather algorithm-oriented to being more problem-oriented. Nowadays the focus is on solving the problem at hand in the best way possible, rather than promoting a certain metaheuristic. This has led to an enormously fruitful cross-fertilization of different areas of optimization. This cross-fertilization is documented by a multitude of powerful hybrid algorithms that were obtained by combining components from several different optimization techniques. Hereby, hybridization is not restricted to the combination of different metaheuristics but includes, for example, the combination of exact algorithms and metaheuristics. In this work we provide a survey of some of the most important lines of hybridization. The literature review is accompanied by the presentation of illustrative examples. {\copyright} 2010 Elsevier B.V. All rights reserved.},
	Author = {Blum, Christian},
	Doi = {10.1007/978-3-642-33860-1\_1},
	File = {:Users/naubergois/Documents/blum-11.pdf:pdf},
	Isbn = {9783642338595},
	Issn = {03029743},
	Journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	Keywords = {combinatorial optimization,hybrid metaheuristics},
	Number = {6},
	Pages = {1--10},
	Publisher = {Elsevier B.V.},
	Title = {{Hybrid metaheuristics in combinatorial optimization: A tutorial}},
	Volume = {7505 LNCS},
	Year = {2012}}

@article{Wang2010,
	Author = {Wang, Xingen and Zhou, Bo and Li, Wei},
	Doi = {10.1109/ISPA.2010.24},
	File = {:Users/naubergois/Dropbox/WangXingen-ISPA2010.pdf:pdf},
	Isbn = {978-1-4244-8095-1},
	Journal = {International Symposium on Parallel and Distributed Processing with Applications},
	Keywords = {load model,load testing,markov chains,model,performance engineering,usage},
	Pages = {483--490},
	Title = {{Model Based Load Testing of Web Applications}},
	Year = {2010}}

@book{Smith:2012qr,
	Author = {Smith, J.~M. and Jones, A.~B.},
	Edition = {7th},
	Publisher = {Publisher},
	Title = {{B}ook {T}itle},
	Year = {2012}}

@article{Smith:2013jd,
	Author = {Jones, A.~B. and Smith, J.~M.},
	Journal = {{J}ournal {T}itle},
	Month = {March},
	Number = {52},
	Pages = {123-456},
	Publisher = {Publisher},
	Title = {{A}rticle {T}itle},
	Volume = {13},
	Year = {2013}}

@article{Tlili1917,
	Author = {Tlili, Marouane and Wappler, Stefan and Sthamer, Harmen},
	Isbn = {1595931864},
	Journal = {Technology},
	Keywords = {daimler-,harmen,sthamer},
	Pages = {1917--1924},
	Title = {{Improving Evolutionary Real-Time Testing}},
	Year = {1917}}

@phdthesis{Jiang2010,
	Author = {Jiang, ZM},
	Booktitle = {\ldots symposium on Software testing and analysis},
	Title = {{Automated analysis of load testing results}},
	Url = {http://dl.acm.org/citation.cfm?id=1831726},
	Year = {2010}}

@article{Jiang2009,
	Abstract = {The goal of a load test is to uncover functional and per- formance problems of a system under load. Performance problems refer to the situations where a system suffers from unexpectedly high response time or low throughput. It is difficult to detect performance problems in a load test due to the absence of formally-defined performance objectives and the large amount of data that must be examined. In this paper, we present an approach which automati- cally analyzes the execution logs of a load test for perfor- mance problems. We first derive the system's performance baseline from previous runs. Then we perform an in-depth performance comparison against the derived performance baseline. Case studies show that our approach produces few false alarms (with a precision of 77\%) and scales well to large industrial systems.},
	Author = {Jiang, ZM and Hassan, AE},
	Journal = {\ldots , 2009. ICSM 2009. IEEE \ldots},
	Title = {{Automated performance analysis of load tests}},
	Year = {2009}}

@article{Afzal2009a,
	Abstract = {Search-based software testing is the application of metaheuristic search techniques to generate software tests. The test adequacy criterion is transformed into a fitness function and a set of solutions in the search space are evaluated with respect to the fitness function using a metaheuristic search technique. The application of metaheuristic search techniques for testing is promising due to the fact that exhaustive testing is infeasible considering the size and complexity of software under test. Search-based software testing has been applied across the spectrum of test case design methods; this includes white-box (structural), black-box (functional) and grey-box (combination of structural and functional) testing. In addition, metaheuristic search techniques have also been applied to test non-functional properties. The overall objective of undertaking this systematic review is to examine existing work into non-functional search-based software testing (NFSBST). We are interested in types of non-functional testing targeted using metaheuristic search techniques, different fitness functions used in different types of search-based non-functional testing and challenges in the application of these techniques. The systematic review is based on a comprehensive set of 35 articles obtained after a multi-stage selection process and have been published in the time span 1996-2007. The results of the review show that metaheuristic search techniques have been applied for non-functional testing of execution time, quality of service, security, usability and safety. A variety of metaheuristic search techniques are found to be applicable for non-functional testing including simulated annealing, tabu search, genetic algorithms, ant colony methods, grammatical evolution, genetic programming (and its variants including linear genetic programming) and swarm intelligence methods. The review reports on different fitness functions used to guide the search for each of the categories of execution time, safety, usability, quality of service and security; along with a discussion of possible challenges in the application of metaheuristic search techniques. ?? 2009 Elsevier B.V. All rights reserved.},
	Author = {Afzal, Wasif and Torkar, Richard and Feldt, Robert},
	Doi = {10.1016/j.infsof.2008.12.005},
	File = {:Users/naubergois/Dropbox/X12-searchbased-testing-afzal-ist09.pdf:pdf},
	Isbn = {0950-5849},
	Issn = {09505849},
	Journal = {Information and Software Technology},
	Keywords = {Non-functional system properties,Search-based software testing,Systematic review},
	Number = {6},
	Pages = {957--976},
	Publisher = {Elsevier B.V.},
	Title = {{A systematic review of search-based testing for non-functional system properties}},
	Volume = {51},
	Year = {2009}}

@article{Stations,
	Author = {{Wegener, Joachim and Pitschinetz, Roman and Sthamer}, Harmen},
	Journal = {Proceedings of the 1st International Workshop on Automated Program Analysis, Testing and Verification (WAPATV'00)},
	Title = {{Automated Testing of Real-Time Tasks}},
	Year = {2000}}

@article{Nevedrov2007,
	Author = {Nevedrov, Dmitri},
	Pages = {1--11},
	Title = {{Using JMeter to Performance Test Web Services}},
	Year = {2007}}

@book{Molyneaux2009,
	Abstract = {This practical book provides a step-by-step approach to testing mission-critical applications for scalability and performance before they're deployed -- a vital topic to which other books devote one chapter, if that. Businesses today live and die by network applications and web services. Because of the increasing complexity of these programs, and the pressure to deploy them quickly, many professionals don't take the time to ensure that they'll perform well and scale effectively. The Art of Application Performance Testing explains the complete life cycle of the testing process, and demonstrates best practices to help you plan, gain approval for, coordinate, and conduct performance tests on your applications. With this book, you'll learn to: Set realistic performance testing goals Implement an effective application performance testing strategy Interpret performance test results Cope with different application technologies and architectures Use automated performance testing tools Test traditional local applications, web-based applications, and web services (SOAs) Recognize and resolves issues that are often overlooked in performance tests Written by a consultant with 30 years of experience in the IT industry and over 12 years experience with performance testing, this easy-to-read book is illustrated with real-world examples and packed with practical advice. The Art of Application Performance Testing thoroughly explains the pitfalls of an inadequate testing strategy and offers you a robust, structured approach for ensuring that your applications perform well and scale effectively when the need arises. "Ian has maintained a vendor-agnostic methodology beautifully in this material. The metrics and graphs, along with background information provided in his case studies, eloquently convey to the reader, 'Methodology above all, tools at your discretion...' Ian's expertise shines through throughout the entire reading experience." -- Matt St. Onge, Enterprise Solution Architect, HCL Technologies America / Teradyne},
	Author = {Molyneaux, Ian},
	File = {:home/74397176353/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Molyneaux - 2009 - The Art of Application Performance Testing(2).pdf:pdf},
	Isbn = {9780596551056},
	Keywords = {COMPUTERS / Computer Literacy,COMPUTERS / Computer Science,COMPUTERS / Data Processing,COMPUTERS / Hardware / General,COMPUTERS / Machine Theory,COMPUTERS / Reference,Computers / Information Technology,Computers / Software Development \& Engineering / G,Computers / Software Development \& Engineering / S,Computers / Web / Design},
	Language = {en},
	Mendeley-Tags = {COMPUTERS / Computer Literacy,COMPUTERS / Computer Science,COMPUTERS / Data Processing,COMPUTERS / Hardware / General,COMPUTERS / Machine Theory,COMPUTERS / Reference,Computers / Information Technology,Computers / Software Development \& Engineering / G,Computers / Software Development \& Engineering / S,Computers / Web / Design},
	Month = jan,
	Pages = {159},
	Publisher = {"O'Reilly Media, Inc."},
	Shorttitle = {The Art of Application Performance Testing},
	Title = {{The Art of Application Performance Testing: Help for Programmers and Quality Assurance}},
	Year = {2009},
	edition  = {1st}}

@article{Sullivan,
	Author = {Sullivan, Michael O and V\"{o}ssner, Siegfried and Wegener, Joachim and Ag, Daimler-benz},
	File = {:Users/naubergois/Dropbox/eurostar1998.pdf:pdf},
	Pages = {1--20},
	Title = {{Testing Temporal Correctness of Real-Time Systems --- A New Approach Using Genetic Algorithms and Cluster Analysis ---}}}

@inproceedings{Draheim2006b,
	Author = {Draheim, D. and Grundy, J. and Hosking, J. and Lutteroth, C. and Weber, G.},
	Booktitle = {Conference on Software Maintenance and Reengineering (CSMR'06)},
	Doi = {10.1109/CSMR.2006.43},
	Isbn = {0-7695-2536-9},
	Issn = {1052-8725},
	Title = {{Realistic load testing of Web applications}},
	Year = {2006}}


@article{Vetoio2011,
author = {Trubiani, Catia},
file = {:Users/naubergois/Downloads/PhDThesis-CatiaTrubiani.pdf:pdf},
journal = {Language},
title = {{PhD Thesis in Computer Science Automated generation of architectural feedback from software performance analysis results Catia Trubiani}},
year = {2011}
}


	
	
@book{brown1998antipatterns,
  title={AntiPatterns: refactoring software, architectures, and projects in crisis},
  author={Brown, William H and Malveau, Raphael C and McCormick, Hays W and Mowbray, Thomas J},
  year={1998},
  publisher={John Wiley \& Sons, Inc.}
}
	
@inproceedings{Gois2016,
	Author = {Gois, N. and Porfirio, P. and Coelho, A. and Barbosa, T.},
	Booktitle = {Proceedings of the 2016 Latin American Computing Conference (CLEI)},
	Isbn = {978-1-5090-1632-7},
	Title = {{Improving Stress Search Based Testing using a Hybrid Metaheuristic Approach}},
	Pages = {718--728},
	Year = {2016}}	


@article{Saeed2017,
author = {Saeed, Aneesa and {Ab Hamid}, Siti Hafizah and Sani, Asmiza Abdul},
doi = {10.1142/S021819401750022X},
file = {:Users/naubergois/Downloads/saeed2017.pdf:pdf},
isbn = {0218194017500},
issn = {0218-1940},
journal = {International Journal of Software Engineering and Knowledge Engineering},
keywords = {model driven,model transformation,model-based testing,ques,search-based techni-,software testing,test case generation},
number = {04},
pages = {601--622},
title = {{Cost and Effectiveness of Search-Based Techniques for Model-Based Testing: An Empirical Analysis}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S021819401750022X},
volume = {27},
year = {2017}
}

@article{Woehrle2012,
abstract = {The operation of wireless network protocol stacks is heavily dependent on the actual deployment of the system and especially on the corresponding network topology, e.g. due to channel contention. The nature of wireless communication does not allow for a-priori determination of network topology, network-defining metrics such as neighbor density and routing span may drastically differ for various deployments. Therefore, it is a difficult problem to foresee and consider the large number of possible topologies that a system may run on during protocol stack development. We propose to use an automated approach for searching topologies for which a protocol stack exhibits particularly poor quantitative performance. We formulate stress testing of protocol stacks on specific topologies as a multi-objective optimization problem and use an evolutionary algorithm for finding a set of small topologies that particularly stress the protocol stack of a wireless network. For searching the topology space, we present novel problem-specific variation operators and show their improvements on search performance in case studies. We showcase our results on stress testing using two protocol stacks for wireless sensor networks.},
author = {Woehrle, Matthias},
doi = {10.1109/ICST.2012.178},
file = {:Users/naubergois/Downloads/presentation{\_}3.pdf:pdf},
isbn = {9780769546704},
issn = {2159-4848},
journal = {Proceedings - IEEE 5th International Conference on Software Testing, Verification and Validation, ICST 2012},
keywords = {Software Testing,Testing,Wireless Networks,Wireless Sensor Networks},
pages = {794--803},
title = {{Search-based stress testing of wireless network protocol stacks}},
year = {2012}
}


@article{Durillo2006,
author = {Durillo, Juan J and Nebro, Antonio J and Luna, Francisco and Alba, Enrique and Teatinos, Campus De},
file = {:Users/naubergois/Downloads/jMetal{\_}a{\_}Java{\_}framework{\_}for{\_}developing{\_}multi-objec.pdf:pdf},
journal = {Science And Technology},
number = {March 2016},
pages = {1--12},
title = {jMetal: a Java Framework for Developing Multi-Objective Optimization Metaheuristics},
volume = {01},
year = {2006}
}

@article{Parasuraman1991,
author = {Parasuraman, Atul and Berry, Leonard L and Zeithaml, Valarie A},
file = {:Users/naubergois/Downloads/Understanding{\_}Customer{\_}Expectations{\_}of{\_}Service.pdf:pdf},
journal = {Sloan Management Review},
number = {3},
pages = {39--48},
title = {{Understanding customer expectations of service}},
volume = {32},
year = {1991}
}

	
	
@article{Fiebrink2005,
abstract = {Music classification continues to be an important component of music information retrieval research. An underutilized tool for improving the performance of classifiers is feature weighting. A major reason for its unpopularity, despite its benefits, is the potentially infinite calculation time it requires to achieve optimal results. Genetic algorithms offer potentially sub-optimal but reasonable solutions at much reduced calculation time, yet they are still quite costly. We investigate the advantages of implementing genetic ...},
author = {Fiebrink, Rebecca and Mckay, Cory and Fujinaga, Ichiro},
file = {:Users/naubergois/Downloads/2121.pdf:pdf},
isbn = {0-9551179-0-9},
journal = {Ismir},
keywords = {classification,feature weighting,parallel},
pages = {510--513},
title = {{Combining d2k and jgap for efficient feature weighting for classification tasks in music information retrieval}},
url = {ismir2005.ismir.net/proceedings/2121.pdf?},
year = {2005}
}
	
	
	

@inproceedings{Gois2017,
	Author = {Gois, N. and Porfirio, P. and Coelho, A.},
	Booktitle = {Proceedings of the 2017 IEEE International Conference on Computer and Information Technology (CIT)},
	Title = {{A multi-objective metaheuristic approach to search-based stress testing}},
	Year = {2017}}	
		
	

@phdthesis{Luiz2011,
	Author = {Luiz, Artur and Freitas, Cunha and Prof, Orientadora and Vieira, Renata},
	School = {Pontif{\'\i}cia Universidade Cat{\'o}lica do Rio Grande do Sul},
	Title = {{Ontologias para Teste de Desempenho de Software}},
	Year = {2011}}

@article{Fe2004,
	Author = {F\'{e}, Iure De Sousa and dos Santos, Pedro de Alc\^{a}ntara},
	Title = {{Os custos dos Testes de Desempenho e Estresse}},
	Year = {2004}}

@article{Babbar2011,
	Author = {Babbar, C and Bajpai, N and Sarmah, Dk},
	Isbn = {9789380544007},
	Journal = {International Journal of Technology},
	Title = {{Web Application Performance Analysis based on Component Load Testing}},
	Year = {2011}}

@article{Avritzer1995,
	Author = {Avritzer, A. and Weyuker, E.J.},
	Issn = {0098-5589},
	Journal = {Software Engineering, IEEE \ldots},
	Keywords = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
	Mendeley-Tags = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
	Number = {9},
	Pages = {705--716},
	Title = {{The automatic generation of load test suites and the assessment of the resulting software}},
	Volume = {21},
	Year = {1995}}

@article{Garousi2010,
	Author = {Garousi, Vahid},
	Doi = {10.1109/TSE.2010.5},
	Issn = {0098-5589},
	Journal = {IEEE Transactions on Software Engineering},
	Keywords = {empirical analysis,genetic algorithms,search-based testing,stress testing,test automation,test tools},
	Month = nov,
	Number = {6},
	Pages = {778--797},
	Title = {{A Genetic Algorithm-Based Stress Test Requirements Generator Tool and Its Empirical Evaluation}},
	Volume = {36},
	Year = {2010}}

@inproceedings{Avritzer1993d,
	Address = {New York, NY, USA},
	Annote = {From Duplicate 1 ( },
	Author = {Avritzer, Alberto and Larson, Brian},
	Booktitle = {ACM SIGSOFT Software Engineering Notes},
	Doi = {10.1145/154183.154244},
	Isbn = {0-89791-608-5},
	Pages = {82--88},
	Publisher = {ACM},
	Series = {ISSTA '93},
	Title = {{Load Testing Software Using Deterministic State Testing}},
	Year = {1993}}

@article{Avritzer1994,
	Address = {New York, New York, USA},
	Author = {Avritzer, Alberto and Weyuker, EJ},
	Doi = {10.1145/186258.186507},
	Isbn = {0897916832},
	Journal = {\ldots international symposium on Software testing \ldots},
	Pages = {44--57},
	Publisher = {ACM Press},
	Title = {{Generating test suites for software load testing}},
	Year = {1994}}

@phdthesis{Garousi2006,
author = {Garousi, Vahid},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Garousi - 2006 - Traffic-aware Stress Testing of Distributed Real-Time Systems based on UML Models using Genetic Algorithms(6).pdf:pdf},
isbn = {9780494262252},
number = {August},
title = {{Traffic-aware Stress Testing of Distributed Real-Time Systems based on UML Models using Genetic Algorithms}},
year = {2006}
}


@article{Santos2011,
	Author = {Santos, I de Sousa and Santos, AR and Neto, PA dos Santos},
	Journal = {SEKE},
	Keywords = {- software testing,data generation,experimental study,however,limitations in,non-functional,of performance and stress,requirements,scripts,scripts from functional testing,testing,tool enabled the generation},
	Title = {{Reusing Functional Testing in order to Decrease Performance and Stress Testing Costs.}},
	Year = {2011}}

@book{bernard2012foundations,
	Author = {Bernard, Pierre},
	Publisher = {Van Haren},
	Title = {Foundations of ITIL},
	Year = {2012}}

@article{Abu-nimeh2001,
	Author = {Abu-nimeh, Saeed and Nair, Suku and Marchetti, Marco},
	Keywords = {bandwidth throttle,denial of service,ramp-up time,response time,stress-testing,think,time,ttfb,ttlb},
	Title = {{Avoiding Denial of Service via Stress Testing}},
	Year = {2001}}

@article{Garousi2008,
	Author = {Garousi, Vahid},
	Doi = {10.1145/1389095.1389433},
	Isbn = {9781605581309},
	Journal = {Proceedings of the 10th annual conference on Genetic and evolutionary computation - GECCO '08},
	Keywords = {empirical analysis,genetic algorithms,stress testing},
	Pages = {1743},
	Title = {{Empirical analysis of a genetic algorithm-based stress test technique}},
	Year = {2008}}

@article{Chakravarty2010,
	Author = {Chakravarty, A},
	Journal = {Information Technology: New Generations ( \ldots},
	Title = {{Stress testing an ai based web service: A case study}},
	Year = {2010}}

@article{Acharya2009,
	Author = {Acharya, Mithun and Kommineni, Vamshidhar},
	Doi = {10.1109/ASE.2009.95},
	Isbn = {9780769538914},
	Issn = {1527-1366},
	Journal = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
	Pages = {409--420},
	Title = {{Mining health models for performance monitoring of services}},
	Year = {2009}}

@article{Catelani2011,
	Doi = {10.1016/j.csi.2010.06.006},
	File = {:Users/naubergois/Dropbox/1-s2.0-S092054891000084X-main.pdf:pdf},
	Isbn = {09205489 (ISSN)},
	Issn = {09205489},
	Journal = {Computer Standards and Interfaces},
	Keywords = {Mean time to overflow,Quality in use,Software automated testing,Software reliability},
	Number = {2},
	Pages = {152--158},
	Publisher = {Elsevier B.V.},
	Title = {{Software automated testing: A solution to maximize the test plan coverage and to increase software reliability and quality in use}},
	Volume = {33},
	Year = {2011}}

@article{Wegener1997,
	Abstract = {The development of real-time systems is an essential industrial activity whose importance is increasing. The most important analytical method to assure the quality of real-time systems is dynamic testing. Testing is the only method which examines the actual run-time behaviour of real-time software, based on an execution in the real application environment. Dynamic aspects like the duration of computations, the memory actually needed, or the synchronization of parallel processes are of major importance for the correct function of real-time systems and have to be tested. A comprehensive investigation of existing software test methods shows that they mostly concentrate on testing for functional correctness. They are not suited for an examination of temporal correctness which is essential to real-time systems. Very small systems show a wide range of different execution times. Therefore, existing test procedures must be supplemented by new methods, which concentrate on determining whether the system violates its specified timing constraints. In general, this means that outputs are produced too early or their computation takes too long. The task of the tester is to find the inputs with the longest or shortest execution times to check whether they produce a temporal error. If the search for such inputs is interpreted as a problem of optimization, genetic algorithms can be used to find the inputs with the longest or shortest execution times automatically. The fitness function is the execution time measured in processor cycles. Experiments using genetic algorithms on a number of programs with up to 1511 LOC and 843 integer input parameters have successfully identified new longer and shorter paths than had been found using random testing or systematic testing. Genetic algorithms are able therefore to check large programs and they show considerable promise in establishing the validity of the temporal behaviour of real-time software.},
	Author = {Wegener, Joachim and Sthamer, Harmen and Jones, Bryan F and Eyres, David E},
	Doi = {10.1023/A:1018551716639},
	Issn = {0963-9314, 1573-1367},
	Journal = {Software Quality Journal},
	Keywords = {embedded systems,genetic algorithms,real time systems,temporal behaviour,testing},
	Number = {2},
	Pages = {127--135},
	Title = {{Testing real-time systems using genetic algorithms}},
	Url = {http://www.springerlink.com/index/uh26067rt3516765.pdf},
	Volume = {6},
	Year = {1997}}

@inproceedings{Alander,
	Abstract = {In this work we are studying possibilities to test software using genetic algorithm search. The idea is to produce test cases in order to find problematic situations like processing time extremes. The proposed test method comes under the heading of automated dynamic stress testing. Keywords: genetic algorithms, software engineering, dynamic stress testing 1 Introduction Real-time software is increasingly applied to products in which failure may have severe consequences, thus the requirements for correctness and reliability are getting higher, too. In very reliable sequential programs, the rate of errors should be less than 10 errors/1000 lines of code, to avoid functional failure. Achieving this level is very labourious, because the amount of program testing work grows exponentially with code size. Testing software manually is slow, expensive and demands inventiveness. Automated testing can reduce both the time and costs needed for performing tests. Exhaustive test data generation is...},
	Annote = {From Duplicate 1 ( },
	Author = {Alander, Jarmo T. JT and Mantere, Timo and Turunen, Pekka},
	Booktitle = {Neural Nets and Genetic Algorithms},
	Date-Modified = {2015-12-05 06:11:49 +0000},
	Title = {{Genetic Algorithm Based Software Testing}},
	Year = {1998}}

@article{Barros2007,
	Author = {Barros, Marcelo De and Shiau, Jing},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Barros, Shiau - 2007 - Web services wind tunnel On performance testing large-scale stateful web services.pdf:pdf},
	Journal = {\ldots and Networks, 2007. \ldots},
	Title = {{Web services wind tunnel: On performance testing large-scale stateful web services}},
	Year = {2007}}

@article{Weyuker2000,
	Abstract = {An approach to software performance testing is discussed. A case study describing the experience of using this approach for testing the performance of a system used as a gateway in a large industrial client/server transaction processing application is presented.},
	Author = {Weyuker, EJ and Vokolos, FI},
	Doi = {10.1109/32.888628},
	Issn = {0098-5589},
	Journal = {IEEE transactions on software engineering},
	Keywords = {Software performance testing,performance testing.,program testing,software testing},
	Mendeley-Tags = {Software performance testing,performance testing.,program testing,software testing},
	Number = {12},
	Pages = {1147--1156},
	Shorttitle = {Experience with Performance Testing of Software Sy},
	Title = {{Experience with performance testing of software systems: issues, an approach, and case study}},
	Volume = {26},
	Year = {2000}}

@article{Raiha2010,
	Abstract = {This survey investigates search-based approaches to software design. The basics of the most popular meta-heuristic algorithms are presented as background to the search-based viewpoint. Software design is considered from a wide viewpoint, including topics that can also be categorized as software maintenance or re-engineering. Search-based approaches have been used in research from the high architecture design level to software clustering and finally software refactoring. Enhancing and predicting software quality with search-based methods is also taken into account as a part of the design process. The background for the underlying software engineering problems is discussed, after which search-based approaches are presented. Summarizing remarks and tables collecting the fundamental issues of approaches for each type of problem are given. The choices regarding critical decisions, such as representation and fitness function, when used in meta-heuristic search algorithms, are emphasized and discussed in detail. Ideas for future research directions are also given. {\copyright} 2010 Elsevier Inc.},
	Author = {R\"{a}ih\"{a}, Outi},
	Doi = {10.1016/j.cosrev.2010.06.001},
	Isbn = {15740137},
	Issn = {15740137},
	Journal = {Computer Science Review},
	Keywords = {Search algorithms,Search-based software engineering,Software design,Software quality},
	Number = {4},
	Pages = {203--249},
	Publisher = {Elsevier Inc.},
	Title = {{A survey on search-based software design}},
	Volume = {4},
	Year = {2010}}

@article{Mohamed2012,
	Abstract = {With the recent rapid development of mobile devices in terms of processing power, memory and storage capabilities coupled with the advancements of wireless technology in terms of higher data transmission rates such as 3G and 4G, it has now become feasible to host Web services on mobile devices. In this paper we propose a lightweight framework for hosting Web services on mobile devices. We further evaluate and provide a comparative analysis for hosting RESTful Web services versus SOAP-based Web services on our framework. Our experimental results and analysis indicate that RESTful Web services are less resource-consuming and more efficient for the implementation and provisioning of Web services from resource-constrained mobile devices. ?? 2012 Published by Elsevier Ltd.},
	Author = {Mohamed, KamalEldin and Wijesekera, Duminda},
	Doi = {10.1016/j.procs.2012.06.095},
	Isbn = {1877-0509},
	Issn = {18770509},
	Journal = {Procedia Computer Science},
	Keywords = {Lightweight framework,Mobile web server,REST,SOAP,Web services},
	Pages = {744--751},
	Publisher = {Duminda Wijesekera},
	Title = {{Performance analysis of web services on mobile devices}},
	Volume = {10},
	Year = {2012}}

@book{reeves1993modern,
	Author = {Reeves, Colin R},
	Publisher = {John Wiley \& Sons, Inc.},
	Title = {Modern heuristic techniques for combinatorial problems},
	Year = {1993}}

@article{Sandler2004,
	Abstract = {The classic, landmark work on software testingThe hardware and software of computing have changed markedly in the three decades since the first edition of The Art of Software Testing, but this book's powerful underlying analysis has stood the test of time. Whereas most books on software testing target particular development techniques, languages, or testing methods, The Art of Software Testing, Third Edition provides a brief but powerful and comprehensive presentation of time-proven software testing approaches. If your software development project is mission critical, this book is an investment that will pay for itself with the first bug you find.The new Third Edition explains how to apply the book's classic principles to today's hot topics including:Testing apps for iPhones, iPads, BlackBerrys, Androids, and other mobile devicesCollaborative (user) programming and testingTesting for Internet applications, e-commerce, and agile programming environmentsWhether you're a student looking for a testing guide you'll use for the rest of your career, or an IT manager overseeing a software development team, The Art of Software Testing, Third Edition is an expensive book that will pay for itself many times over.},
	Author = {Sandler, Corey and Badgett, Tom and Thomas, TM},
	File = {:Users/naubergois/Downloads/The Art of Software Testing, 3rd Edition.pdf:pdf},
	Isbn = {9781118133156},
	Keywords = {Business \& Economics / Reference,Computers / Information Technology},
	Language = {en},
	Mendeley-Tags = {Business \& Economics / Reference,Computers / Information Technology},
	Month = sep,
	Pages = {200},
	Publisher = {John Wiley \& Sons},
	Title = {{The Art of Software Testing}},
	Year = {2004}}

@book{Erinle2013,
	Author = {Erinle, Bayo},
	File = {:Users/naubergois/Dropbox/OPR/papers/performance-testing-with-jmeter-2-9.pdf:pdf},
	Isbn = {9781782165842},
	Title = {{Performance Testing With JMeter 2.9}},
	Year = {2013}}

@misc{Corporation2007,
	Abstract = {Performance Testing Guidance for Web Applications provides an end-to-end approach for implementing performance testing. Whether you are new to performance testing or looking for ways to improve your current performance-testing approach, you will gain insights that you can tailor to your specific scenarios.},
	Address = {United States?},
	Author = {Corporation, Microsoft},
	Edition = {1 edition},
	Isbn = {9780735625709},
	Language = {English},
	Month = nov,
	Pages = {288},
	Publisher = {Microsoft Press},
	Title = {{Performance Testing Guidance for Web Applications}},
	Url = {http://www.amazon.com/Performance-Testing-Guidance-Web-Applications/dp/0735625700 http://msdn.microsoft.com/en-us/library/bb924375.aspx},
	Year = {2007},
	Bdsk-Url-1 = {http://www.amazon.com/Performance-Testing-Guidance-Web-Applications/dp/0735625700%20http://msdn.microsoft.com/en-us/library/bb924375.aspx}}

@article{Snellman,
	Author = {Snellman, Niclas and Ashraf, Adnan and Porres, Ivan},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Snellman, Ashraf, Porres - Unknown - Towards Automatic Performance and Scalability Testing of Rich Internet Applications in the Cloud(2).pdf:pdf},
	Keywords = {-performance testing,a flat performance curve,application should ideally maintain,cloud computing,intended maximum load level,rich in-,scalability testing,ternet applications,until it reaches its},
	Title = {{Towards Automatic Performance and Scalability Testing of Rich Internet Applications in the Cloud}}}

@article{Cohen2004,
	Abstract = {This paper studies the use of statistical induction techniques as a basis for automated performance diagnosis and performance management. The goal of the work is to develop and evaluate tools for offline and online analysis of system metrics gathered from instrumentation in Internet server platforms. We use a promising class of probabilistic models (Tree-Augmented Bayesian Networks or TANs) to identify combinations of system-level metrics and threshold values that correlate with high-level with Service Level Objectives (SLOs) for average-case response timein a three-tier Web service under a variety of conditions. Experimental results from a testbed show that TAN models involving small subsets of metrics capture patterns of performance behavior in a way that is accurate and yields insights into the causes of observed performance effects. TANs are extremely efficient to represent and evaluate, and they have interpretability properties that make them excellent candidates for automated diagnosis and control. We explore the use of TAN models for offline forensic diagnosis, and in a limited online setting for performance forecasting with stable workloads.},
	Author = {Cohen, Ira and Goldszmidt, Moises and Kelly, Terence and Symons, Julie and Chase, Jeffrey S},
	File = {:Users/naubergois/Dropbox/HPL-2004-183.pdf:pdf},
	Journal = {Small},
	Number = {December},
	Pages = {6--8},
	Title = {{Correlating instrumentation data to system states : A building block for automated diagnosis and control performance forecasting automated performance diagnosis and performance management . The goal of the work is to develop and evaluate tools for offline}},
	Year = {2004}}

@article{Biolchini2005,
	Author = {Biolchini, Jorge and Mian, Paula Gomes and Candida, Ana and Natali, Cruz},
	Doi = {10.1007/978-3-540-70621-2},
	Isbn = {9783540706199},
	Issn = {18650929},
	Journal = {System Engineering and Computer Science Department COPPE/UFRJ, Technical Report ES},
	Number = {May},
	Pages = {165--176},
	Title = {{Systematic Review in Software Engineering}},
	Volume = {679},
	Year = {2005}}

@article{Goncalves2014,
	Author = {Gon\c{c}alves, Marcelo Can\'{a}rio},
	Title = {{Um Processo de Infer\^{e}ncia de Desempenho para Apoiar o Planejamento da Capacidade de Aplica\c{c}\~{o}es na Nuvem Um Processo de Infer\^{e}ncia de Desempenho para Apoiar o Planejamento da Capacidade de Aplica\c{c}\~{o}es na Nuvem}},
	Year = {2014}}

@book{Feitelson2013,
	Author = {Feitelson, Dror G},
	File = {:Users/naubergois/Dropbox/wlmod.pdf:pdf},
	Publisher = {Cambridge University Press},
	Title = {{Workload Modeling for Computer Systems Performance Evaluation}},
	Year = {2013}}

@article{Malik2010b,
	Author = {Malik, Haroon},
	Doi = {10.1145/1810295.1810408},
	File = {:Users/naubergois/Downloads/icse2010\_malik.pdf:pdf},
	Institution = {Queen's University, Kingston, ON, Canada},
	Isbn = {978-1-60558-719-6},
	Issn = {0270-5257},
	Journal = {Software Engineering, 2010 ACM/IEEE 32nd \ldots},
	Keywords = {automation,counters,load test,performance counters,principal component analysis},
	Pages = {421--424},
	Publisher = {IEEE},
	Title = {{A methodology to support load test analysis}},
	Volume = {2},
	Year = {2010}}

@article{Kuhn1997,
	Abstract = {What makes a distributed system reliable? A study of failures in
the US public switched telephone network (PSTN) shows that human
intervention is one key to this large system's reliability. Software is
not the weak link in the PSTN system's dependability. Extensive use of
built-in self-test and recovery mechanisms in major system components
(switches) contributed to software dependability and are significant
design features in the PSTN. The network's high dependability indicates
that the trade-off between dependability gains and complexity introduced
by built-in self-test and recovery mechanisms can be positive. Likewise,
the tradeoff between complex interactions and the loose coupling of
system components has been positive, permitting quick human intervention
in most system failures and resulting in an extremely reliable system
},
	Author = {Kuhn, D. Richard},
	Doi = {10.1109/2.585151},
	File = {:Users/naubergois/Dropbox/kuhn-97-pstn-failures.pdf:pdf},
	Issn = {00189162},
	Journal = {Computer},
	Number = {4},
	Pages = {31--36},
	Pmid = {150},
	Title = {{Sources of failure in the public switched telephone network}},
	Volume = {30},
	Year = {1997}}

@article{McMinn2004,
	Author = {McMinn, Philip and Court, Regent and Testing, Software and Street, Portobello},
	Doi = {10.1002/stvr.294},
	File = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/McMinn - 2004 - Search-based software test data generation a survey.pdf:pdf},
	Isbn = {1099-1689},
	Issn = {09600833},
	Journal = {Software testing, Verification and reliability},
	Keywords = {Automated software test data generation,Evolutionary algorithms,Evolutionary testing,Metaheuristic search,Search-based software engineering,Simulated annealing,algorithms,automated software test,automated software test data generation,data generation,evolutionary,evolutionary algorithms,evolutionary testing,metaheuristic search,search-based software engineering,simulated annealing},
	Pages = {1--58},
	Title = {{Search-based software test data generation: a survey}},
	Volume = {14},
	Year = {2004}}

@article{DiLucca2006,
	Author = {{Di Lucca}, Giuseppe a. and Fasolino, Anna Rita},
	Doi = {10.1016/j.infsof.2006.06.006},
	Isbn = {0-7695-2413-3},
	Issn = {09505849},
	Journal = {Information and Software Technology},
	Keywords = {Software testing,Web application testing,Web engineering},
	Pages = {1172--1186},
	Title = {{Testing Web-based applications: The state of the art and future trends}},
	Volume = {48},
	Year = {2006}}
	
@article{Harman2015,
abstract = {Search Based Software Testing (SBST) formulates testing as an optimisation problem, which can be attacked using computational search techniques from the field of Search Based Software Engineering (SBSE). We present an analysis of the SBST research agenda1, focusing on the open problems and chal- lenges of testing non-functional properties, in particular a topic we call ‘Search Based Energy Testing' (SBET), Multi-objective SBST and SBST for Test Strategy Identification. We conclude with a vision of FIFIVERIFY tools, which would automatically find faults, fix them and verify the fixes. We explain why we think such FIFIVERIFY tools constitute an exciting challenge for the SBSE community that already could be within its reach.},
author = {Harman, Mark and Jia, Yue and Zhang, Yuanyuan},
isbn = {9781479971251},
journal = {8th IEEE International Conference on Software Testing, Verification and Validation (ICST)},
number = {Icst},
title = {{Achievements , open problems and challenges for search based software testing}},
url = {http://www0.cs.ucl.ac.uk/staff/mharman/icst15.pdf},
year = {2015}
}
	

@article{Anand2013,
	Author = {Anand, Saswat and Burke, Edmund K. and Chen, Tsong Yueh and Clark, John and Cohen, Myra B. and Grieskamp, Wolfgang and Harman, Mark and Harrold, Mary Jean and McMinn, Phil},
	Doi = {10.1016/j.jss.2013.02.061},
	Issn = {01641212},
	Journal = {Journal of Systems and Software},
	Keywords = {Adaptive random testing,Combinatorial testing,Model-based testing,Orchestrated survey,Search-based software testing,Software testing,Symbolic execution,Test automation,Test case generation},
	Pages = {1978--2001},
	Title = {{An orchestrated survey of methodologies for automated software test case generation}},
	Volume = {86},
	Year = {2013}}

@inproceedings{Penta2007,
	Author = {Penta, Massimiliano Di and Canfora, Gerardo and Esposito, Gianpiero},
	Booktitle = {Proceedings of the 9th annual conference on Genetic and evolutionary computation},
	Isbn = {9781595936974},
	Keywords = {quality of,search-based testing,service level agreement},
	Pages = {1090--1097},
	Title = {{Search-based testing of service level agreements}},
	Year = {2007}}

@article{Barber1999,
	Author = {Barber, Scott},
	File = {:Users/naubergois/Dropbox/ucml\_1.1.pdf:pdf},
	Pages = {1--9},
	Title = {{User Community Modeling Language ( UCML {\texttrademark} ) v1 . 1 for Performance Test Workloads UCML {\texttrademark} Overview}},
	Year = {1999}}

@article{Silveira2011,
	Author = {da Silveira, MB and Rodrigues, EM and Zorzo, AF},
	Journal = {SEKE},
	Keywords = {- model-based testing,performance testing,software product line},
	Title = {{Generation of Scripts for Performance Testing Based on UML Models.}},
	Year = {2011}}

@article{Grechanik2012,
	Author = {Grechanik, Mark and Fu, Chen and Xie, Qing},
	Doi = {10.1109/ICSE.2012.6227197},
	Isbn = {978-1-4673-1067-3},
	Journal = {2012 34th International Conference on Software Engineering (ICSE)},
	Month = jun,
	Pages = {156--166},
	Publisher = {Ieee},
	Title = {{Automatically finding performance problems with feedback-directed learning software testing}},
	Year = {2012}}

@article{Barna2011,
	Author = {Barna, Cornel and Litoiu, M and Ghanbari, H},
	Isbn = {9781450306072},
	Journal = {International conference on Autonomi},
	Keywords = {autonomic system,performance,performance testing},
	Pages = {91--100},
	Title = {{Autonomic load-testing framework}},
	Year = {2011}}

@book{Everett2007,
	Author = {Everett, Gerald D and Jr., Raymond McLeod},
	Isbn = {9780471793717},
	Title = {{Software Testing: Testing Across the Entire Software Development Life Cycle}},
	Year = {2007}}

@article{Chen,
	Author = {Chen, Feifei},
	File = {:Users/naubergois/Downloads/13113010195260.pdf:pdf},
	Journal = {chinacloud.cn},
	Keywords = {as it requires,cloud computing,cost,effectiveness before the deployment,energy,however,of cloud systems,performance engineering,this is not a,trade-off analysis,trivial task},
	Title = {{Generating a Performance Test-bed for Cloud Computing Systems}}}
	
@misc{dean2003managing,
  title={Managing Software Requirements: A Use Case Approach},
  author={Dean, Leffingwell and Don, Widrig},
  year={2003},
  publisher={Addison Wesley}
}	

@article{Alba2008,
abstract = {In this paper we analyze the application of parallel and sequential evolutionary algorithms (EAs) to the automatic test data generation problem. The problem consists of automatically creating a set of input data to test a program. This is a fundamental step in software development and a time consuming task in existing software companies. Canonical sequential EAs have been used in the past for this task. We explore here the use of parallel EAs. Evidence of greater efficiency, larger diversity maintenance, additional availability of memory/CPU, and multi-solution capabilities of the parallel approach, reinforce the importance of the advances in research with these algorithms. We describe in this work how canonical genetic algorithms (GAs) and evolutionary strategies (ESs) can help in software testing, and what the advantages are (if any) of using decentralized populations in these techniques. In addition, we study the influence of some parameters of the proposed test data generator in the results. For the experiments we use a large benchmark composed of twelve programs that includes fundamental algorithms in computer science. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Alba, Enrique and Chicano, Francisco},
doi = {10.1016/j.cor.2007.01.016},
file = {:Users/naubergois/Downloads/testing-cor-sbse.pdf:pdf},
isbn = {0305-0548},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Evolutionary algorithms,Evolutionary testing,Parallel evolutionary algorithms,Software testing},
number = {10},
pages = {3161--3183},
title = {{Observations in using parallel and sequential evolutionary algorithms for automatic software testing}},
volume = {35},
year = {2008}
}

@article{Harman2010,
abstract = {Search-based optimization techniques have been applied to structural software test data generation since 1992, with a recent upsurge in interest and activity within this area. However, despite the large number of recent studies on the applicability of different search-based optimization approaches, there has been very little theoretical analysis of the types of testing problem for which these techniques are well suited. There are also few empirical studies that present results for larger programs. This paper presents a theoretical exploration of the most widely studied approach, the global search technique embodied by Genetic Algorithms. It also presents results from a large empirical study that compares the behavior of both global and local search-based optimization on real-world programs. The results of this study reveal that cases exist of test data generation problem that suit each algorithm, thereby suggesting that a hybrid global-local search (a Memetic Algorithm) may be appropriate. The paper presents a Memetic Algorithm along with further empirical results studying its performance.},
author = {Harman, Mark and McMinn, Phil},
doi = {10.1109/TSE.2009.71},
file = {:Users/naubergois/Downloads/Software engineering IEEE.Vol.36.Iss.2.A.6.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Artificial intelligence,Automated test data generation,Evolutionary testing,Genetic algorithms,Hill climbing,Problem solving,Royal road,Schema theory,Search-based software engineering,Search-based testing,Testing and debugging,Testing tools},
number = {2},
pages = {226--247},
title = {{A theoretical and empirical study of search-based testing: Local, global, and hybrid search}},
volume = {36},
year = {2010}
}

@book{MohammadS.Obaidat,
author = {{Mohammad S. Obaidat}, Petros Nicopolitidis and Faouzi Zarai},
file = {:Users/naubergois/Downloads/Mohammad S. Obaidat, Faouzi Zarai, Petros Nicopolitidis-Modeling and Simulation of Computer Networks and Systems{\_} Methodologies and Applications-Morgan Kaufmann (2015).pdf:pdf},
isbn = {9780128008874},
title = {{Modeling and Simulation of Computer Networks and Systems Methodologies and Applications}}
}

@book{Tobergte2013,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Raidl, Gunther R and Puchinger, Jakob and Blum}, Christian},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Hybrid Metaheuristics{\_} An Emerging Approach to Optimization.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Hybrid Metaheuristics An Emerging Approach}},
volume = {53},
year = {2013}
}

@book{Talbi2013,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Talbi, El-Ghazali},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Metaheuristics.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Metaheuristics: From Design to Implementation}},
volume = {53},
year = {2013}
}

@article{Greenwald2003,
abstract = {Bowling named two desiderata for multiagent learning algorithms: rationality and convergence. This paper introduces co{\~{}}elated-Q learning, a natural generaliza- tion of Nash-Q NashoQ converge. FF-Q satisfies convergence, but in general it is not rational. Correlated-Q satisfies rationality by construction. This papers demonstrates the empirical convergence of correlated-Q on a standard testbed of general-sum Markov games. satisfies rationality, but in general it does not and FF-Q that satisfies these criteria.},
author = {Greenwald, Amy and Hall, Keith and Serrano, R},
file = {:Users/naubergois/Downloads/SS02-02-012.pdf:pdf},
journal = {Icml},
number = {3},
pages = {84--89},
title = {{Correlated Q-learning}},
url = {http://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-02/SS02-02-012.pdf},
year = {2003}
}

@article{MarkUtting2012,
abstract = {Penetration testing is widely used to help ensure the security of web applications. Using penetration testing, testers discover vulnerabilities by simulating attacks on a target web application. To do this efﬁciently, testers rely on automated techniques that gather input vector information about the target web application and analyze the application's responses to determine whether an attack was successful. Techniques for performing these steps are often incomplete, which can leave parts of the web application untested and vulnerabilities undiscovered. This paper proposes a new approach to penetration testing that addresses the limitations of current techniques. The approach incorporates two recently developed analysis techniques to improve input vector identiﬁcation and detect when attacks have been successful against a web application. This paper compares the proposed approach against two popular penetration testing tools for a suite of web applications with known and unknown vulnerabilities. The evaluation results show that the proposed approach performs a more thorough penetration testing and leads to the discovery of more vulnerabilities than both the tools.},
author = {{Mark Utting}, Alexander Pretschner and Bruno Legeard},
doi = {10.1002/stvr},
file = {:Users/naubergois/Downloads/master{\_}pdflatex.pdf:pdf},
isbn = {1099-1689},
issn = {10991689},
journal = {Software Testing Verification and Reliability},
keywords = {model-based testing approaches,survey,taxonomy},
number = {8},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {24},
year = {2012}
}

@article{Hierons2009,
abstract = {Formal methods and testing are two important approaches that assist in the development of high-quality software.While traditionally these approaches have been seen as rivals, in recent years a new consensus has developed in which they are seen as complementary. This article reviews the state of the art regarding ways in which the presence of a formal specification can be used to assist testing.},
author = {Hierons, Robert M and Bogdanov, Kirill and Bowen, Jonathan P and Cleaveland, Rance and Derrick, John and Dick, Jeremy and Gheorghe, Marian and Harman, Mark and Kapoor, Kalpesh and Krause, Paul and L{\"{u}}ttgen, Gerald and Simons, Anthony J H and Vilkomir, Sergiy and Woodward, Martin R and Zedan, Hussein},
doi = {http://doi.acm.org/10.1145/1459352.1459354},
file = {:Users/naubergois/Downloads/hierons2009.pdf:pdf},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
number = {2},
pages = {1--76},
title = {{Using formal specifications to support testing}},
volume = {41},
year = {2009}
}

@phdthesis{shousha2003performance,
  title={Performance Stress Testing of Real-Time Systems Using Genetic Algorithms},
  author={Shousha, Marwa},
  year={2003},
  school={Carleton University Ottawa}
}

@article{hong2000simultaneously,
  title={Simultaneously applying multiple mutation operators in genetic algorithms},
  author={Hong, Tzung-Pei and Wang, Hong-Shung and Chen, Wei-Chou},
  journal={Journal of heuristics},
  volume={6},
  number={4},
  pages={439--455},
  year={2000},
  publisher={Springer}
}

@article{Vogele2016,
abstract = {The specification of workloads is required in order to evaluate performance characteristics of application systems using load testing and model-based performance prediction. Defining workload specifications that represent the real workload as accurately as possible is one of the biggest challenges in both areas. To overcome this challenge, this paper presents an approach that aims to automate the extraction and transformation of workload specifications for load testing and model-based performance prediction of session-based application systems. The approach (WESSBAS) comprises three main components. First, a system- and tool-agnostic domain-specific language (DSL) allows the layered modeling of workload specifications of session-based systems. Second, instances of this DSL are automatically extracted from recorded session logs of production systems. Third, these instances are transformed into executable workload specifications of load generation tools and model-based performance evaluation tools. We present transformations to the common load testing tool Apache JMeter and to the Palladio Component Model. Our approach is evaluated using the industry-standard benchmark SPECjEnterprise2010 and the World Cup 1998 access logs. Workload-specific characteristics (e.g., session lengths and arrival rates) and performance characteristics (e.g., response times and CPU utilizations) show that the extracted workloads match the measured workloads with high accuracy.},
author = {Vogele, Christian and van Hoorn, Andr{\'{e}} and Schulz, Eike and Hasselbring, Wilhelm and Krcmar, Helmut},
doi = {10.1007/s10270-016-0566-5},
file = {:Users/naubergois/Downloads/VoegelevanHoornSchulzHasselbringKrcmar2016WESSBAS-SoSyM.pdf:pdf},
issn = {16191374},
journal = {Software and Systems Modeling},
keywords = {Load testing,Performance models,Performance prediction,Workload specifications},
number = {October},
pages = {1--35},
publisher = {Springer Berlin Heidelberg},
title = {{WESSBAS: extraction of probabilistic workload specifications for load testing and performance prediction???a model-driven approach for session-based application systems}},
url = {"http://dx.doi.org/10.1007/s10270-016-0566-5},
year = {2016}
}


@article{Menasce2002a,
author = {Menasc{\'{e}}, Daniel A and Mason, George},
file = {:Users/naubergois/Downloads/10.1.1.468.8603.pdf:pdf},
number = {June},
pages = {1--6},
title = {{TPC-W : A Benchmark for E-commerce}},
year = {2002}
}


@article{Sutton2012,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1603.02199},
author = {Sutton, Richard S. and Barto, Andrew G.},
doi = {10.1109/MED.2013.6608833},
eprint = {1603.02199},
file = {:Users/naubergois/Downloads/SuttonBook.pdf:pdf},
isbn = {0262193981},
issn = {18726240},
journal = {Learning},
number = {9},
pages = {322},
pmid = {18255791},
title = {{Reinforcement learning}},
url = {https://books.google.com/books?id=CAFR6IBF4xYC{\&}pgis=1$\backslash$nhttp://incompleteideas.net/sutton/book/the-book.html$\backslash$nhttps://www.dropbox.com/s/f4tnuhipchpkgoj/book2012.pdf},
volume = {3},
year = {2012}
}

@article{Szepesvari2010,
abstract = {Reinforcement learning is a learning paradigm concerned with learning to control a system so as to maximize a numerical performance measure that expresses a long-term objective.What distin- guishes reinforcement learning from supervised learning is that only partial feedback is given to the learner about the learner's predictions. Further, the predictions may have long term effects through influencing the future state of the controlled system. Thus, time plays a special role. The goal in reinforcement learning is to develop efficient learning algorithms, as well as to understand the al- gorithms' merits and limitations. Reinforcement learning is of great interest because of the large number of practical applications that it can be used to address, ranging from problems in artificial intelligence to operations research or control engineering. In this book,we focus on those algorithms of reinforcement learning that build on the powerful theory of dynamic programming.We give a fairly comprehensive catalog of learning problems, describe the core ideas, note a large number of state of the art algorithms, followed by the discussion of their theoretical properties and limitations.},
author = {Szepesv{\'{a}}ri, Csaba and Bartok, Gabor},
doi = {10.2200/S00268ED1V01Y201005AIM009},
file = {:Users/naubergois/Downloads/RLAlgsInMDPs-lecture.pdf:pdf},
isbn = {9781608454921},
issn = {1939-4608},
journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
number = {x},
pages = {1--103},
title = {{Algorithms for Reinforcement Learning}},
volume = {4},
year = {2010}
}



@article{Bertolino2008,
abstract = {A Web Service is commonly not an independent software entity, but plays a role in some business process. Hence, it depends on the services provided by external Web Services, to provide its own service. While developing and testing a Web Service, such external services are not always available, or their usage comes along with unwanted side effects like, e.g., utilization fees or database modifications. We present a model-based approach to generate stubs for Web Services which respect both an extra-functional contract expressed via a Service Level Agree- ment (SLA), and a functional contract modeled via a state machine. These stubs allow a developer to set up a testbed over the target plat- form, in which the extra-functional and functional behavior of a Web Service under development can be tested before its publication.},
author = {Bertolino, Antonia and Angelis, Guglielmo De},
doi = {10.1007/978-3-540-68524-1_19},
file = {:Users/naubergois/Downloads/BAFP08.pdf:pdf},
isbn = {978-3-540-68514-2, 978-3-540-68524-1},
issn = {978-3-540-68514-2},
journal = {Testing of Software and {\ldots}},
pages = {266--282},
title = {{Model-based generation of testbeds for web services}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-68524-1{\_}19},
year = {2008}
}

@article{MarkUtting2012,
abstract = {Penetration testing is widely used to help ensure the security of web applications. Using penetration testing, testers discover vulnerabilities by simulating attacks on a target web application. To do this efﬁciently, testers rely on automated techniques that gather input vector information about the target web application and analyze the application's responses to determine whether an attack was successful. Techniques for performing these steps are often incomplete, which can leave parts of the web application untested and vulnerabilities undiscovered. This paper proposes a new approach to penetration testing that addresses the limitations of current techniques. The approach incorporates two recently developed analysis techniques to improve input vector identiﬁcation and detect when attacks have been successful against a web application. This paper compares the proposed approach against two popular penetration testing tools for a suite of web applications with known and unknown vulnerabilities. The evaluation results show that the proposed approach performs a more thorough penetration testing and leads to the discovery of more vulnerabilities than both the tools.},
author = {{Mark Utting}, Alexander Pretschner and Bruno Legeard},
doi = {10.1002/stvr},
file = {:Users/naubergois/Downloads/master{\_}pdflatex.pdf:pdf},
isbn = {1099-1689},
issn = {10991689},
journal = {Software Testing Verification and Reliability},
keywords = {model-based testing approaches,survey,taxonomy},
number = {8},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {24},
year = {2012}
}

@article{Trent1995,
author = {Trent, G and Sake, M},
file = {:Users/naubergois/Downloads/WebSTONE{\_}The{\_}First{\_}Generation{\_}in{\_}HTTP{\_}Se.pdf:pdf},
journal = {WWW Conference'95},
title = {{WebSTONE: The first generation in {\{}HTTP{\}} server benchmarking}},
year = {1995}
}

@article{Luo2015,
abstract = {A goal of performance testing is to find situations when applications unexpectedly exhibit worsened characteristics for certain combinations of input values. A fundamental question of performance testing is how to select a manageable subset of the input data faster in order to automatically find performance bottlenecks in applications. We propose FOREPOST, a novel solution, for automatically finding performance bottlenecks in applications using black-box software testing. Our solution is an adaptive, feedback-directed learning testing system that learns rules from execution traces of applications. Theses rules are then used to automatically select test input data for performance testing. We hypothesize that FOREPOST can find more performance bottlenecks as compared to random testing. We have implemented our solution and applied it to a medium-size industrial application at a major insurance company and to two open-source applications. Performance bottlenecks were found automatically and confirmed by experienced testers and developers. We also thoroughly studied the factors (or independent variables) that impact the results of FOREPOST. {\&}copy; 2015 Springer Science+Business Media New York},
author = {Luo, Qi and Nair, Aswathy and Grechanik, Mark and Poshyvanyk, Denys},
doi = {10.1007/s10664-015-9413-5},
file = {:Users/naubergois/Downloads/10.1.1.699.7944.pdf:pdf},
isbn = {1066401594},
issn = {15737616},
journal = {Empirical Software Engineering},
keywords = {Feedback-directed learning system,Performance testing},
pages = {1--51},
title = {{FOREPOST: finding performance problems automatically with feedback-directed learning software testing}},
year = {2015}
}



@book{Talbi2012,
abstract = {The main goal of this book is to provide a state of the art of hybrid metaheuristics. The book provides a complete background that enables readers to design and implement hybrid metaheuristics to solve complex optimization problems (continuous/discrete, mono-objective/multi-objective, optimization under uncertainty) in a diverse range of application domains. Readers learn to solve large scale problems quickly and efficiently combining metaheuristics with complementary metaheuristics, mathematical programming, constraint programming and machine learning. Numerous real-world examples of problems and solutions demonstrate how hybrid metaheuristics are applied in such fields as networks, logistics and transportation, bio-medical, engineering design, scheduling.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Talbi, El-Ghazali},
doi = {10.1007/978-3-642-30671-6},
eprint = {arXiv:1011.1669v3},
file = {:Users/naubergois/Downloads/Hybrid{\_}Metaheuristics{\_}An{\_}Introduction.pdf:pdf},
isbn = {9783642306709},
issn = {1098-6596},
keywords = {learning,neighborhood search,online and offline tuning,project scheduling,stochastic local search},
number = {December 2016},
pages = {19--35},
pmid = {25246403},
title = {{Hybrid Metaheuristics}},
volume = {2},
year = {2012}
}




@article{Mendoza2005a,
	Author = {Mendoza, Valerie and Novick, Dg},
	Doi = {10.1145/1085313.1085348},
	Isbn = {9157475725},
	Journal = {SIGDOC '05 Proceedings of the 23rd annual international conference on Design of communication: documenting \& designing for pervasive information},
	Keywords = {training,usability},
	Pages = {151--158},
	Title = {{Usability over time}},
	Year = {2005}}

@article{Glover1989,
	Abstract = {This is the second half of a two part series devoted to the tabu search metastrategy for optimization problems. Part I introduced the fundamental ideas of tabu search as an approach for guiding other heuristics to overcome the limitations of local optimality, both in a deterministic and a probabilistic framework. Part I also reported successful applications from a wide range of settings, in which tabu search frequently made it possible to obtain higher quality solutions than previously obtained with competing strategies, generally with less computational effort. Part II, in this issue, examines refinements and more advanced aspects of tabu search. Following a brief review of notation, Part II introduces new dynamic strategies for managing tabu lists, allowing fuller exploitation of underlying evaluation functions. In turn, the elements of staged search and structured move sets are characterized, which bear on the issue of finiteness. Three ways of applying tabu search to the solution of integer programming problems are then described, providing connections also to certain nonlinear programming applications. Finally, the paper concludes with a brief survey of new applications of tabu search that have occurred since the developments reported in Part I. Together with additional comparisons with other methods on a wide body of problems, these include results of parallel processing implementations and the use of tabu search in settings ranging from telecommunications to neural networks.},
	Author = {Glover, Fred},
	Doi = {10.1287/ijoc.2.1.4},
	Isbn = {079239965X},
	Issn = {0899-1499},
	Journal = {ORSA journal on Computing},
	Number = {3},
	Pages = {4--32},
	Pmid = {2758},
	Title = {{Tabu Search - Part II}},
	Volume = {2 1},
	Year = {1989}}

@article{Kirkpatrick2007,
	Author = {Kirkpatrick},
	Doi = {10.1126/science.220.4598.671},
	Issn = {0036-8075},
	Number = {4598},
	Pages = {671--680},
	Pmid = {17813860},
	Title = {{Optimization by SA}},
	Volume = {220},
	Year = {2007}}

@article{Goffe1994,
	Abstract = {Many statistical methods rely on numerical optimization to estimate a model's parameters. Unfortunately, conventional algorithms sometimes fail. Even when they do converge, there is no assurance that they have found the global, rather than a local, optimum. We test a new optimization algorithm, simulated annealing, on four econometric problems and compare it to three common conventional algorithms. Not only can simulated annealing find the global optimum, it is also less likely to fail on difficult functions because it is a very robust algorithm. The promise of simulated annealing is demonstrated on the four econometric problems.},
	Author = {Goffe, William L. and Ferrier, Gary D. and Rogers, John},
	Doi = {10.1016/0304-4076(94)90038-8},
	Isbn = {0304-4076},
	Issn = {03044076},
	Journal = {Journal of Econometrics},
	Keywords = {simulated},
	Number = {1-2},
	Pages = {65--99},
	Title = {{Global optimization of statistical functions with simulated annealing}},
	Volume = {60},
	Year = {1994}}

@phdthesis{tracey2000search,
	Author = {Tracey, Nigel James},
	School = {Citeseer},
	Title = {A search-based automated test-data generation framework for safety-critical software},
	Year = {2000}}

@article{alander1996ga,
	Author = {Alander, Jarmo T and Mantere, Pekka Turunen and Virolainen, Jari},
	Publisher = {Citeseer},
	Title = {GA in program testing},
	Year = {1996}}

@article{Tracey1998,
	Abstract = {One of the major costs in a software project is the construction of test-data. This paper outlines a generalised test-case data generation framework based on optimisation techniques. The framework can incorporate a number of testing criteria, for both functional and non-functional properties. Application of the optimisation framework to testing specification failures and exception conditions is illustrated. The results of a number of small case studies are presented and show the efficiency and effectiveness of this dynamic optimisation-based approach to generating test-data},
	Author = {Tracey, N J and Clark, J a and Mander, K C},
	Keywords = {QA 76 Software, computer programming,},
	Title = {{Automated Programme Flaw Finding using Simulated Annealing}},
	Year = {1998}}

@article{Wegener1999,
	Abstract = {For real-time systems, correct system functionality depends on
logical as well as on temporal correctness. Static analysis alone is not
sufficient to verify the temporal behavior of real-time systems. Since
existing test methods are not specialized for the verification of
temporal correctness, we have developed a new testing method, namely
evolutionary testing. This paper illustrates results of the first
industrial application of the evolutionary test},
	Author = {Wegener, J. and Sthamer, H. and Pohlheim, H.},
	Doi = {10.1109/REAL.1999.818852},
	Isbn = {0-7695-0475-2},
	Issn = {1052-8725},
	Journal = {Proceedings 20th IEEE Real-Time Systems Symposium (Cat. No.99CB37054)},
	Title = {{Testing the temporal behavior of real-time tasks using extended evolutionary algorithms}},
	Year = {1999}}

@article{Mueller1998,
	Abstract = {The paper contrasts two methods to verify timing constraints of
real-time applications. The method of static analysis predicts the
worst-case and best-case execution times of a task's code by analyzing
execution paths and simulating processor characteristics without ever
executing the program or requiring the program's input. Evolutionary
testing is an iterative testing procedure, which approximates the
extreme execution times within several generations. By executing the
test object dynamically and measuring the execution times the inputs are
guided yielding gradually tighter predictions of the extreme execution
times. The authors examined both approaches on a number of real world
examples. The results show that static analysis and evolutionary testing
are complementary methods, which together provide upper and lower bounds
for both worst-case and best-case execution times},
	Author = {Mueller, F. and Wegener, J.},
	Doi = {10.1109/RTTAS.1998.683198},
	File = {:Users/naubergois/Dropbox/rtas98.pdf:pdf},
	Isbn = {0-8186-8569-7},
	Journal = {Proceedings. Fourth IEEE Real-Time Technology and Applications Symposium (Cat. No.98TB100245)},
	Title = {{A comparison of static analysis and evolutionary testing for the verification of timing constraints}},
	Year = {1998}}

@article{Puschner1998,
	Abstract = {Analytically derived worst case execution time (WCET) bounds are
prone to errors, because they often rely on information provided by the
user. The paper presents a method for testing the results of static WCET
analysis. The proposed test method is a blackbox test method that uses a
genetic algorithm (GA) for test case generation. Important properties of
the method are: (a) that it requires minimal information about possible
impact data from the user and (b) that the GA guides data generation
into directions that have a good chance to yield the real WCET of the
program under test. Experimental results show that GA based testing
produces results of high quality},
	Author = {Puschner, P. and Nossal, R.},
	Doi = {10.1109/REAL.1998.739738},
	Isbn = {0-8186-9212-X},
	Issn = {1052-8725},
	Journal = {Proceedings 19th IEEE Real-Time Systems Symposium (Cat. No.98CB36279)},
	Title = {{Testing the results of static worst-case execution-time analysis}},
	Year = {1998}}

@article{J.WegenerK.GrimmM.GrochtmannH.Sthamer1996,
	Author = {{J. Wegener, K. Grimm, M. Grochtmann, H. Sthamer}, B. Jones},
	File = {:Users/naubergois/Dropbox/eurostar1996.pdf:pdf},
	Journal = {EuroSTAR'96: Proceedings of the Fourth International Conference on Software Testing Analysis and Review},
	Title = {{Systematic testing of real-time systems}},
	Year = {1996}}

@article{Gro,
	Author = {Gro, Hans-Gerhard},
	Publisher = {Citeseer},
	Title = {A prediction system for dynamic optimisation-based execution time analysis},
	Year = {2001}}

@misc{Gross2003,
	Author = {Gross, Hg},
	Booktitle = {Proceedings of the International Conference on Information Technology: Prospects and Challenges in the 21st Century},
	File = {:Users/naubergois/Dropbox/grossITPC03\_RealTime.pdf:pdf},
	Title = {{An evaluation of dynamic, optimisation-based worst-case execution time analysis}},
	Year = {2003}}

@article{Briand2005,
	Author = {Briand, Lionel C. and Labiche, Yvan and Shousha, Marwa},
	Doi = {10.1145/1068009.1068183},
	Isbn = {1595930108},
	Journal = {Proceedings of the 2005 conference on Genetic and evolutionary computation - GECCO '05},
	Keywords = {genetic algorithms,schedulability theory},
	Pages = {1021},
	Title = {{Stress testing real-time systems with genetic algorithms}},
	Year = {2005}}

@article{Canfora,
	Author = {Canfora, Gerardo and Penta, Massimiliano Di and Esposito, Raffaele and Villani, Maria Luisa},
	Isbn = {1595930108},
	Keywords = {aware composi-,oriented software engineering,qos,service},
	Title = {{2005., Canfora, G., An approach for QoS-aware service composition based on genetic algorithms}}}

@article{gross2000structural,
	Author = {Gross, H-G and Jones, Bryan F and Eyres, David E},
	Journal = {IEE Proceedings-Software},
	Number = {2},
	Pages = {25--30},
	Publisher = {IET},
	Title = {Structural performance measure of evolutionary testing applied to worst-case timing of real-time systems},
	Volume = {147},
	Year = {2000}}

@article{goldberg1989messy,
	Author = {Goldberg, David E and Korb, Bradley and Deb, Kalyanmoy},
	Journal = {Complex systems},
	Number = {5},
	Pages = {493--530},
	Publisher = {Complex Systems Publications, Champaign, IL, USA},
	Title = {Messy genetic algorithms: Motivation, analysis, and first results},
	Volume = {3},
	Year = {1989}}

@article{wegener1998verifying,
	Author = {Wegener, Joachim and Grochtmann, Matthias},
	Journal = {Real-Time Systems},
	Number = {3},
	Pages = {275--298},
	Publisher = {Springer},
	Title = {Verifying timing constraints of real-time systems by means of evolutionary testing},
	Volume = {15},
	Year = {1998}}

@article{alander1998searching,
	Author = {Alander, Jarmo T and Mantere, Timo and Moghadampour, Ghodrat and Matila, Jukka},
	Journal = {Electric Power Systems Research},
	Number = {3},
	Pages = {229--233},
	Publisher = {Elsevier},
	Title = {Searching protection relay response time extremes using genetic algorithm---software quality by optimization},
	Volume = {46},
	Year = {1998}}

@article{Wegener1998,
	Abstract = {Many industrial products are based on the use of embedded computer systems. Usually, these systems have to fulfil real-time requirements, and correct system functionality depends on their logical correctness as well as on their temporal correctness. in order to verify the temporal behavior of real-time systems, previous scientific work has, to a large extent, concentrated on static analysis techniques. Although these techniques offer the possibility of providing safe estimates of temporal behavior for certain cases, there are a number of cases in practice for which static analysis can not be easily applied. Furthermore, no commercial tools for timing analysis of real-world programs are available. Therefore, the developed systems have to be thoroughly tested in order to detect existing deficiencies in temporal behavior, as well as to strengthen the confidence in temporal correctness. An investigation of existing test methods shows that they mostly concentrate on testing for logical correctness. They are nor specialised in the examination of temporal correctness which is also essential to real-rime systems. For this reason, existing test procedures must be supplemented by new methods which concentrate on determining whether the system violates its specified timing constraints. Normally, a violation means that outputs are produced too early, or their computation takes too long. The task of the tester therefore is to find the input situations with the longest or shortest execution limes, in order to check whether they produce a temporal error. If the starch for such inputs is interpreted as a problem of optimization, evolutionary computation can be used to automatically find the inputs with the longest or shortest execution rimes. This automatic search for accurate test data by means of evolutionary computation is called evolutionary testing. Experiments using evolutionary testing on a number of programs with up to 1511 LOC and 5000 input parameters have successfully identified new longer and shorter execution times than had been found using other testing techniques. Evolutionary testing, therefore, seems to be a promising approach for the verification of timing constraints. A combination of evolutionary testing and systematic testing offers further opportunities to improve the test quality, and could lead to an effective test strategy for real-time systems.},
	Author = {Wegener, J and Grochtmann, M},
	Doi = {Doi 10.1023/A:1008096431840},
	Isbn = {0922-6443},
	Issn = {0922-6443},
	Journal = {Real-Time Systems},
	Keywords = {evolutionary algorithm,evolutionary optimization,evolutionary testing,genetic algorithms,real-time systems,temporal behavior,temporal correctness,test strategy,testing,validation,verification},
	Number = {3},
	Pages = {275--298},
	Title = {{Verifying timing constraints of real-time systems by means of evolutionary testing}},
	Volume = {15},
	Year = {1998}}

@book{Halili2008,
	Abstract = {"This book introduces you to JMeter (version 2.3) and test automation, providing a step-by-step guide to testing with JMeter. You will learn how to measure the performance of a website using JMeter. While it discusses test automation generally, the bulk of this book gives specific, vivid, and easy-to-understand walkthroughs of JMeter's testing tools showing what they can do, and when and how to use them. Learn to load-test your website, test its functional behaviour, and measure its performance by implementing the features of Jmeter"--Resource description p.},
	Author = {Halili, Emily H},
	Isbn = {9786611737528 6611737529 9781847192967 1847192963 1847192955 9781847192950},
	Title = {{Apache JMeter a practical beginner's guide to automated testing and performance measurement for your websites}},
	Year = {2008}}

@article{wegener1997testing,
	Author = {Wegener, Joachim and Sthamer, Harmen and Jones, Bryan F and Eyres, David E},
	Journal = {Software Quality Journal},
	Number = {2},
	Pages = {127--135},
	Publisher = {Springer},
	Title = {Testing real-time systems using genetic algorithms},
	Volume = {6},
	Year = {1997}}
	
	@book{Lewis2005,
abstract = {It is often assumed that software testing is based on clearly defined requirements and software development standards. However, testing is typically performed against changing, and sometimes inaccurate, requirements. The third edition of a bestseller, Software Testing and Continuous Quality Improvement, Third Edition provides a continuous quality framework for the software testing process within traditionally structured and unstructured environments. This framework aids in creating meaningful test cases for systems with evolving requirements. This completely revised reference provides a comprehensive look at software testing as part of the project management process, emphasizing testing and quality goals early on in development. Building on the success of previous editions, the text explains testing in a Service Orientated Architecture (SOA) environment, the building blocks of a Testing Center of Excellence (COE), and how to test in an agile development. Fully updated, the sections on test effort estimation provide greater emphasis on testing metrics. The book also examines all aspects of functional testing and looks at the relation between changing business strategies and changes to applications in development. Includes New Chapters on Process, Application, and Organizational Metrics All IT organizations face software testing issues, but most are unprepared to manage them. Software Testing and Continuous Quality Improvement, Third Editionis enhanced with an up-to-date listing of free software tools and a question-and-answer checklist for choosing the best tools for your organization. It equips you with everything you need to effectively address testing issues in the most beneficial way for your business.},
author = {Lewis, William E. and Dobbs, David and Veerapillai, Gunasekaran},
file = {:Users/naubergois/Downloads/2005 Software.Testing.and.Continuous.Quality.Improvement.2nd.Ed{\_}bagus.pdf:pdf},
isbn = {1420080733},
pages = {688},
title = {{Software testing and continuous quality improvement}},
url = {http://books.google.com/books?id=fgaBDd0TfT8C{\&}pgis=1},
year = {2005}
}

@article{Fang2012,
abstract = {AUTOSAR multicore RTOS is a safety-critical concurrent system, for which high quality is required. A conformance test is important to ensure the quality of the software, but the conventional test is low in coverage and high in cost. In this paper, we present a formal model-based test for multicore RTOS that supports AUTOSAR specifications. First, we developed a formal model. With the model, we developed a test case generator, from which an entire test suite can be extracted. Moreover, we proposed a test program generator, with which optimal executable test programs can be generated fully automatically. Both of the generators are assisted with model checking on the formal model. Bug analysis also becomes easy. Our method demonstrated its advantage over conventional testing by finding 33 test cases for three system service calls, whereas a conventional test carried out by a development team found only 10 test cases. Our method can improve the coverage of the test, clearly saving in cost and development time. It is expected to significantly improve the testing of the AUTOSAR multicore RTOS.},
author = {Fang, Ling and Kitamura, Takashi and Do, Thi Bich Ngoc and Ohsaki, Hitoshi},
doi = {10.1109/ICST.2012.105},
file = {:Users/naubergois/Downloads/fang2012.pdf:pdf},
isbn = {9780769546704},
issn = {2159-4848},
journal = {Proceedings - IEEE 5th International Conference on Software Testing, Verification and Validation, ICST 2012},
keywords = {AUTOSAR multicore RTOS,SPIN,model checking,model-based test,test automation},
mendeley-groups = {Model Based Test/State Machine Model},
pages = {251--259},
title = {{Formal model-based test for AUTOSAR multicore RTOS}},
year = {2012}
}
@article{XinyingCai2007,
author = {{Xinying Cai}, Hongwei Zeng},
file = {:Users/naubergois/Downloads/cai2013.pdf:pdf},
isbn = {9781479901746},
keywords = {software product line,test,test reuse,variability binding},
mendeley-groups = {Model Based Test/UML},
title = {{Model-based Test Generation for Software Product Line}},
year = {2007}
}
@article{SADEGHI2012,
author = {SADEGHI, ALIREZA and MIRIAN-HOSSEINABADI, SEYED-HASSAN},
doi = {10.1142/S0218194012500295},
file = {:Users/naubergois/Downloads/sadeghi2012.pdf:pdf},
issn = {0218-1940},
journal = {International Journal of Software Engineering and Knowledge Engineering},
keywords = {model based testing,software quality assurance,test driven development},
mendeley-groups = {Model Based Test},
number = {08},
pages = {1085--1102},
title = {{Mbtdd: Model Based Test Driven Development}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0218194012500295},
volume = {22},
year = {2012}
}
@article{Sridhar2013,
author = {Sridhar, Adepu and Srinivasulu, D. and Mohapatra, Durga Prasad},
doi = {10.1109/IAdCC.2013.6514434},
file = {:Users/naubergois/Downloads/sridhar2013.pdf:pdf},
isbn = {9781467345286},
journal = {Proceedings of the 2013 3rd IEEE International Advance Computing Conference, IACC 2013},
keywords = {Simulink/Stateflow,dependency graph,software testing,test sequences},
mendeley-groups = {Model Based Test/State Machine Model},
pages = {1414--1419},
title = {{Model-based test-case generation for Simulink/Stateflow using dependency graph approach}},
year = {2013}
}
@article{Ganesan2016,
author = {Ganesan, Dharmalingam and Lindvall, Mikael and Hafsteinsson, Stefan and Cleaveland, Rance and Strege, Susanne L. and Moleski, Walter},
doi = {10.1109/ISSRE.2016.47},
file = {:Users/naubergois/Downloads/ganesan2016.pdf:pdf},
isbn = {9781467390019},
issn = {10719458},
journal = {Proceedings - International Symposium on Software Reliability Engineering, ISSRE},
keywords = {Concurrency,Flight Software,Model Based Testing,Publish-Subscribe},
mendeley-groups = {Model Based Test/State Machine Model},
pages = {445--454},
title = {{Experience Report: Model-Based Test Automation of a Concurrent Flight Software Bus}},
year = {2016}
}
@article{SanMiguel2016,
author = {{San Miguel}, Jose Lorenzo and Takada, Shingo},
doi = {10.1145/3001854.3001865},
file = {:Users/naubergois/Downloads/10.1145@3001854.3001865.pdf:pdf},
isbn = {978-1-4503-4643-6},
journal = {Proceedings of the 1st International Workshop on Mobile Development},
keywords = {Android,GUI,Testing},
mendeley-groups = {Model Based Test/State Machine Model},
pages = {43--44},
title = {{GUI and Usage Model-based Test Case Generation for Android Applications with Change Analysis}},
url = {http://doi.acm.org/10.1145/3001854.3001865},
year = {2016}
}

@article{Arantes2014,
abstract = {Testing activities play an important role in order to obtain high quality software products. These activities become more important when considering critical software, for instance, space application software. Nowadays, there is an extensive collaboration among space institutions. So, it is more than natural to expect distributed development of software and software testing activities. Therefore, a collaborative tool hosted on the internet becomes quite useful. In this respect, WEB-PerformCharts 2.0 tool discussed in this paper moves in this direction. The tool focuses on supporting a single aspect of distributed software development: the activity of generating test cases via web. Moreover, it allows model-based test case generation by means of formal methods (formal languages statecharts and FSM) which are considered state of the art in software development. WEB-PerformCharts 2.0 can be used to generate test cases for any kind of reactive systems modelled in statecharts or FSM. We present three case studies in different application domains to demonstrate the feasibility of our tool. Copyright {\&}copy; 2014 Inderscience Enterprises Ltd.},
author = {Arantes, Alessandro Oliveira and {De Santiago}, Valdivino Alexandre and Vijaykumar, Nandamudi Lankalapalli and {De Souza}, Erica Ferreira},
doi = {10.1504/IJWET.2014.063041},
file = {:Users/naubergois/Downloads/arantes2014.pdf:pdf},
issn = {14761289},
journal = {International Journal of Web Engineering and Technology},
keywords = {Application programs,Formal languages,Model checki},
mendeley-groups = {Model Based Test/State Machine Model},
number = {1},
pages = {62--96},
title = {{Tool support for generating model-based test cases via web}},
url = {http://dx.doi.org/10.1504/IJWET.2014.063041},
volume = {9},
year = {2014}
}

@article{Williams2002,
author = {Williams, Lloyd G. and Smith, Connie U.},
doi = {10.1145/584369.584397},
file = {:Users/naubergois/Downloads/PASASM{\_}A{\_}method{\_}for{\_}the{\_}performance{\_}assessment{\_}of{\_}.pdf:pdf},
isbn = {1581135637},
journal = {Proceedings of the third international workshop on Software and performance - WOSP '02},
mendeley-groups = {Anti-Patterns,Other Aproaches,Other Aproaches/PASASM},
number = {January 2002},
pages = {179},
title = {{PASASM : A Method for the Performance Assessment of Software Architectures}},
url = {http://portal.acm.org/citation.cfm?doid=584369.584397},
year = {2002}
}

@article{Knowles1999,
abstract = {Most popular evolutionary algorithms for multiobjective$\backslash$noptimisation maintain a population of solutions from which individuals$\backslash$nare selected for reproduction. In this paper, we introduce a simpler$\backslash$nevolution scheme for multiobjective problems, called the Pareto archived$\backslash$nevolution strategy (PAES). We argue that PAES may represent the simplest$\backslash$npossible non-trivial algorithm capable of generating diverse solutions$\backslash$nin the Pareto optimal set. The algorithm is identified as being a (1+1)$\backslash$nevolution strategy, using local search from a population of one but$\backslash$nusing a reference archive of previously found solutions in order to$\backslash$nidentify the approximate dominance ranking of the current and candidate$\backslash$nsolution vectors. PAES is intended as a good baseline approach, against$\backslash$nwhich more involved methods may be compared, and may also serve well in$\backslash$nsome real-world applications when local search seems superior to or$\backslash$ncompetitive with population-based methods. The performance of the new$\backslash$nalgorithm is compared with that of a MOEA based on the niched Pareto GA$\backslash$non a real world application from the telecommunications field. In$\backslash$naddition, we include results from experiments carried out on a suite of$\backslash$nfour test functions, to demonstrate the algorithm's general capability$\backslash$n},
author = {Knowles, J. and Corne, D.},
doi = {10.1109/CEC.1999.781913},
file = {:Users/naubergois/Downloads/10[1].1.1.42.2856.pdf:pdf},
isbn = {0-7803-5536-9},
issn = {1879-1026},
journal = {Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406)},
pages = {98--105},
pmid = {19520416},
title = {{The Pareto archived evolution strategy: a new baseline algorithm$\backslash$nfor Pareto multiobjective optimisation}},
volume = {1},
year = {1999}
}


@article{Knowles1999,
abstract = {Most popular evolutionary algorithms for multiobjective$\backslash$noptimisation maintain a population of solutions from which individuals$\backslash$nare selected for reproduction. In this paper, we introduce a simpler$\backslash$nevolution scheme for multiobjective problems, called the Pareto archived$\backslash$nevolution strategy (PAES). We argue that PAES may represent the simplest$\backslash$npossible non-trivial algorithm capable of generating diverse solutions$\backslash$nin the Pareto optimal set. The algorithm is identified as being a (1+1)$\backslash$nevolution strategy, using local search from a population of one but$\backslash$nusing a reference archive of previously found solutions in order to$\backslash$nidentify the approximate dominance ranking of the current and candidate$\backslash$nsolution vectors. PAES is intended as a good baseline approach, against$\backslash$nwhich more involved methods may be compared, and may also serve well in$\backslash$nsome real-world applications when local search seems superior to or$\backslash$ncompetitive with population-based methods. The performance of the new$\backslash$nalgorithm is compared with that of a MOEA based on the niched Pareto GA$\backslash$non a real world application from the telecommunications field. In$\backslash$naddition, we include results from experiments carried out on a suite of$\backslash$nfour test functions, to demonstrate the algorithm's general capability$\backslash$n},
author = {Knowles, J. and Corne, D.},
doi = {10.1109/CEC.1999.781913},
file = {:Users/naubergois/Downloads/10[1].1.1.42.2856.pdf:pdf},
isbn = {0-7803-5536-9},
issn = {1879-1026},
journal = {Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406)},
pages = {98--105},
pmid = {19520416},
title = {{The Pareto archived evolution strategy: a new baseline algorithm$\backslash$nfor Pareto multiobjective optimisation}},
volume = {1},
year = {1999}
}

@article{Oltean2005,
abstract = {This paper proposes a novel adaptive representation for evolutionary multiobjective optimization for solving a stock modeling problem. The standard Pareto Achieved Evolu-tion Strategy (PAES) uses real or binary representation for encoding solutions. Adaptive Pareto Archived Evolution Strategy (APAES) uses dynamic alphabets for encoding so-lutions. APAES is applied for modeling two popular stock indices involving 4 objective functions. Further, two bench mark test functions for multiobjective optimization are also used to illustrate the performance of the algorithm. Empir-ical results demonstrate APAES performs well when com-pared to the standard PAES.},
author = {Oltean, Mihai and Abraham, Ajith and Mario, K},
file = {:Users/naubergois/Downloads/d034bfb70f683cf474c9419f7b80651fd0e9.pdf:pdf},
pages = {1--6},
title = {{Multiobjective Optimization Using Adaptive Pareto Archived Evolution Strategy}},
year = {2005}
}


@article{Zhang2007,
abstract = {Decomposition is a basic strategy in traditional multiobjective optimization. However, it has not yet been widely used in multiobjective evolutionary optimization. This paper proposes a multiobjective evolutionary algorithm based on decomposition (MOEA/D). It decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously. Each subproblem is optimized by only using information from its several neighboring subproblems, which makes MOEA/D have lower computational complexity at each generation than MOGLS and nondominated sorting genetic algorithm II (NSGA-II). Experimental results have demonstrated that MOEA/D with simple decomposition methods outperforms or performs similarly to MOGLS and NSGA-II on multiobjective 0-1 knapsack problems and continuous multiobjective optimization problems. It has been shown that MOEA/D using objective normalization can deal with disparately-scaled objectives, and MOEA/D with an advanced decomposition method can generate a set of very evenly distributed solutions for 3-objective test instances. The ability of MOEA/D with small population, the scalability and sensitivity of MOEA/D have also been experimentally investigated in this paper.},
author = {Zhang, Q. and Li, Hui},
doi = {10.1109/TEVC.2007.892759},
file = {:Users/naubergois/Downloads/moead.pdf:pdf},
isbn = {1089-778X VO - 11},
issn = {1089-778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Computational complexity,Pareto optimality,decomposition,evolutionary algorithm,multiobjective optimization},
number = {6},
pages = {712--731},
title = {{MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition}},
volume = {11},
year = {2007}
}


@article{Zhang2007,
abstract = {Decomposition is a basic strategy in traditional multiobjective optimization. However, it has not yet been widely used in multiobjective evolutionary optimization. This paper proposes a multiobjective evolutionary algorithm based on decomposition (MOEA/D). It decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously. Each subproblem is optimized by only using information from its several neighboring subproblems, which makes MOEA/D have lower computational complexity at each generation than MOGLS and nondominated sorting genetic algorithm II (NSGA-II). Experimental results have demonstrated that MOEA/D with simple decomposition methods outperforms or performs similarly to MOGLS and NSGA-II on multiobjective 0-1 knapsack problems and continuous multiobjective optimization problems. It has been shown that MOEA/D using objective normalization can deal with disparately-scaled objectives, and MOEA/D with an advanced decomposition method can generate a set of very evenly distributed solutions for 3-objective test instances. The ability of MOEA/D with small population, the scalability and sensitivity of MOEA/D have also been experimentally investigated in this paper.},
author = {Zhang, Q. and Li, Hui},
doi = {10.1109/TEVC.2007.892759},
file = {:Users/naubergois/Downloads/moead.pdf:pdf},
isbn = {1089-778X VO - 11},
issn = {1089-778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Computational complexity,Pareto optimality,decomposition,evolutionary algorithm,multiobjective optimization},
number = {6},
pages = {712--731},
title = {{MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition}},
volume = {11},
year = {2007}
}

@article{McConaghy2011,
abstract = {This paper presents MOJITO, a system that performs structural synthesis of analog circuits, returning designs that are trustworthy by construction. The search space is defined by a set of expert-specified, trusted, hierarchically-organized analog building blocks, which are organized as a parameterized context-free grammar. The search algorithm is a multiobjective evolutionary algorithm that uses an age-layered population structure to balance exploration versus exploitation. It is validated with experiments to search across {\textless}formula formulatype="inline"{\textgreater}{\textless}tex Notation="TeX"{\textgreater}{\$}{\{}{\&}{\#}x003E;{\}}{\{}100000{\}}{\$}{\textless}/tex{\textgreater}{\textless}/formula{\textgreater} different one-stage and two-stage opamp topologies, returning human-competitive results. The runtime is orders of magnitude faster than open-ended systems, and unlike the other evolutionary algorithm approaches, the resulting circuits are trustworthy by construction. The approach generalizes to other problem domains which have accumulated structural domain knowledge, such as robotic structures, car assemblies, and modeling biological systems.},
author = {McConaghy, Trent and Palmers, Pieter and Steyaert, Michiel and Gielen, Georges G E},
doi = {10.1109/TEVC.2010.2093581},
file = {:Users/naubergois/Downloads/Trustworthy{\_}Genetic{\_}Programming-Based{\_}Synthesis{\_}of.pdf:pdf},
isbn = {1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Analog,design automation,evolutionary algorithm (EA),integrated circuit (IC),multiobjective optimization},
number = {4},
pages = {557--570},
title = {{Trustworthy genetic programming-based synthesis of analog circuit topologies using hierarchical domain-specific building blocks}},
volume = {15},
year = {2011}
}

@article{Michalak2014,
abstract = {The Multiobjective Evolutionary Algorithm Based on Decomposition (MOEA/D) is a very efficient multiobjective evolutionary algorithm introduced in recent years. This algorithm works by decomposing a multiobjective optimization problem to many scalar optimization problems and by assigning each specimen in the population to a specific subproblem. The MOEA/D algorithm transfers information between specimens assigned to the subproblems using a neighborhood relation. In this paper it is shown that parameter settings commonly used in the literature cause an asymmetric neighbor assignment which in turn affects the selective pressure and consequently causes the population to converge asymmetrically. The paper contains theoretical explanation of how this bias is caused as well as an experimental verification. The described effect is undesirable, because a multiobjective optimizer should not introduce asymmetries not present in the optimization problem. The paper gives some guidelines on how to avoid such artificial asymmetries.},
author = {Michalak, Krzysztof},
doi = {10.1016/j.asoc.2014.07.029},
file = {:Users/naubergois/Downloads/michalak2014.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Evolutionary algorithms,MOEA/D algorithm,Multiobjective optimization,Selective pressure},
pages = {97--106},
publisher = {Elsevier B.V.},
title = {{The effects of asymmetric neighborhood assignment in the MOEA/D algorithm}},
url = {http://dx.doi.org/10.1016/j.asoc.2014.07.029},
volume = {25},
year = {2014}
}



@article{Michalak2014,
abstract = {The Multiobjective Evolutionary Algorithm Based on Decomposition (MOEA/D) is a very efficient multiobjective evolutionary algorithm introduced in recent years. This algorithm works by decomposing a multiobjective optimization problem to many scalar optimization problems and by assigning each specimen in the population to a specific subproblem. The MOEA/D algorithm transfers information between specimens assigned to the subproblems using a neighborhood relation. In this paper it is shown that parameter settings commonly used in the literature cause an asymmetric neighbor assignment which in turn affects the selective pressure and consequently causes the population to converge asymmetrically. The paper contains theoretical explanation of how this bias is caused as well as an experimental verification. The described effect is undesirable, because a multiobjective optimizer should not introduce asymmetries not present in the optimization problem. The paper gives some guidelines on how to avoid such artificial asymmetries.},
author = {Michalak, Krzysztof},
doi = {10.1016/j.asoc.2014.07.029},
file = {:Users/naubergois/Downloads/michalak2014.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Evolutionary algorithms,MOEA/D algorithm,Multiobjective optimization,Selective pressure},
pages = {97--106},
publisher = {Elsevier B.V.},
title = {{The effects of asymmetric neighborhood assignment in the MOEA/D algorithm}},
url = {http://dx.doi.org/10.1016/j.asoc.2014.07.029},
volume = {25},
year = {2014}
}

@article{Yuen2009,
author = {Yuen, Tey Jing and Ramli, Rahizar},
file = {:Users/naubergois/Downloads/is{\_}ECMS2010{\_}0027.pdf:pdf},
isbn = {9780956494405},
keywords = {evolutionary algorithms,genetic algorithms,multi-objective,passive suspension optimization,quarter,ride comfort,vehicle model},
number = {Cd},
title = {{Comparison of Computational Efficiency of Moea $\backslash$ D and Nsga-Ii for Passive Vehicle Suspension Optimization}},
volume = {2},
year = {2009}
}

@article{Enoiu2013,
abstract = {A method for model-based test generation of safety-critical embedded applications using Programmable Logic Controllers and implemented in a programming language such as Function Block Diagram (FBD) is described. The FBD component model is based on the IEC 1131 standard and it is used primarily for embedded systems, in which timeliness is an important property to be tested. Our method involves the transformation of FBD programs with timed annotations into timed automata models which are used to automatically generate test suites. Specifically we demonstrate how to use model transformation for formalization and modelchecking of FBD programs using the UPPAAL tool. Many benefits emerge from this method, including the ability to automatically generate test suites from a formal model in order to ensure compliance to strict quality requirements including unit testing and specific coverage measurements. The approach is experimentally assessed on a train control system in terms of consumed resources.},
author = {Enoiu, Eduard Paul and Sundmark, Daniel and Pettersson, Paul},
doi = {10.1109/ICSTW.2013.27},
file = {:Users/naubergois/Downloads/enoiu2013.pdf:pdf},
isbn = {978-0-7695-4993-4},
journal = {Proceedings - IEEE 6th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2013},
keywords = {function block diagram,model based testing,plc,structural coverage,test case generation,timed automata},
mendeley-groups = {Model Based Test/Other Aproaches},
pages = {158--167},
title = {{Model-based test suite generation for function block diagrams using the UPPAAL model checker}},
year = {2013}
}
@article{Shirole2013,
abstract = {In software engineering, system modeling is the process of for-mulating a representation of a real system in an abstract way to understand its behavior. Software testing encourages reusing these models for testing purpose. This expedites the process of test case generation. UML structural and behavioral specification diagrams have been used by testing researchers for generation of test scenarios and test data. The aim of this survey is to improve the understanding of UML based testing techniques. We have focused on test case genera-tion from the behavioral specification diagrams, namely sequence, state chart and activity diagrams. We classify the various research approaches that are based on formal specifications, graph theo-retic, heuristic testing, and direct UML specification processing. We discuss the issues of test coverage associated with these ap-proaches.},
author = {Shirole, Mahesh and Kumar, Rajeev},
doi = {10.1145/2492248.2492274},
file = {:Users/naubergois/Downloads/shirole2013.pdf:pdf},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {activity diagram,formal specifications based testing,graph theoretic testing,heuristic testing,sequence diagram,state machine diagram,test case generation},
mendeley-groups = {Model Based Test/UML},
number = {4},
pages = {1},
title = {{UML behavioral model based test case generation}},
url = {http://dl.acm.org/citation.cfm?doid=2492248.2492274},
volume = {38},
year = {2013}
}
@article{Arcaini2015,
abstract = {One of the well-known techniques for model-based test generation exploits the capability of model checkers to return counterexamples upon property violations. However, this approach is not always optimal in practice due to the required time and memory, or even not feasible due to the state explosion problem of model checking. A way to mitigate these limitations consists in decomposing a system model into suitable subsystem models separately analyzable. In this paper, we show a technique to decompose a system model into subsystems by exploiting the model variables dependency, and then we propose a test generation approach which builds tests for the single subsystems and combines them later in order to obtain tests for the system as a whole. Such approach mitigates the exponential increase of the test generation time and memory consumption, and, compared with the same model-based test generation technique applied to the whole system, shows to be more efficient. We prove that, although not complete, the approach is sound. {\&}copy; 2015 ACM.},
author = {Arcaini, Paolo and Gargantini, Angelo and Riccobene, Elvinia},
doi = {10.1145/2786805.2786837},
file = {:Users/naubergois/Downloads/arcaini2015.pdf:pdf},
isbn = {978-1-4503-3675-8},
journal = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
keywords = {Test case generation,abstraction,model-based testing,state explosion problem},
mendeley-groups = {Model Based Test/Other Aproaches},
pages = {119--130},
title = {{Improving Model-based Test Generation by Model Decomposition}},
url = {http://doi.acm.org/10.1145/2786805.2786837},
year = {2015}
}
@article{Mamrot2016,
abstract = {Test and validation of autonomous mechatronic systems is a major challenge. Due to more complex tasks as well as dynamic environments, existing test and validation methods are reaching their limits. The complexity and diversity of their elements and interrelations of these as well as interrelations with environmental elements have to be handled because established methods do not consider the characteristics of autonomous mechatronic systems. Therefore Systems Engineering seems to be a proper solution. Based on system thinking an approach for analyzing autonomous mechatronic systems will be developed. For this purpose a procedure for model development will be aligned with the robot's system model. This system model combines hardware and software elements, analyzes their interrelations and prepares a later test and validation. With the help of this new system model, which decomposes to the hardware and software level, new test and validation methods can be developed. {\&}copy; 2015 IEEE.},
author = {Mamrot, Michel and Marchlewitz, Stefan and Nicklas, Jan Peter and Winzer, Petra and Tetzlaff, Thomas and Kemper, Philipp and Witkowski, Ulf},
doi = {10.1109/SMC.2015.132},
file = {:Users/naubergois/Downloads/mamrot2015.pdf:pdf},
isbn = {9781479986965},
issn = {1062-922X},
journal = {Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015},
keywords = {autonomous mechatronic systems,product development,system modeling,systems engineering,test and validation},
mendeley-groups = {Model Based Test/Other Aproaches},
pages = {701--706},
title = {{Model-Based Test and Validation Support for Autonomous Mechatronic Systems}},
year = {2016}
}
@article{Jidong2016,
author = {Jidong, Lv and Kaicheng, Li},
file = {:Users/naubergois/Downloads/10.1109@icirt.2016.7588752.pdf:pdf},
isbn = {9781509015559},
keywords = {hcsp,model-based,test case,timed automata},
mendeley-groups = {Model Based Test},
title = {{A Model-based Test Case Generation Method for Function Testing of Train Control Systems}},
volume = {3},
year = {2016}
}
@article{Araiza-Illan2016,
abstract = {Robotic code needs to be verified to ensure its safety and functional correctness, especially when the robot is interacting with people. Testing real code in simulation is a viable option. However, generating tests that cover rare scenarios, as well as exercising most of the code, is a challenge amplified by the complexity of the interactions between the environment and the software. Model-based test generation methods can automate otherwise manual processes and facilitate reaching rare scenarios during testing. In this paper, we compare using Belief-Desire-Intention (BDI) agents as models for test generation with more conventional automata-based techniques that exploit model checking, in terms of practicality, performance, transferability to different scenarios, and exploration (`coverage'), through two case studies: a cooperative manufacturing task, and a home care scenario. The results highlight the advantages of using BDI agents for test generation. BDI agents naturally emulate the agency present in Human-Robot Interactions (HRIs), and are thus more expressive than automata. The performance of the BDI-based test generation is at least as high, and the achieved coverage is higher or equivalent, compared to test generation based on model checking automata.},
archivePrefix = {arXiv},
arxivId = {1609.08439},
author = {Araiza-Illan, Dejanira and Pipe, Anthony G. and Eder, Kerstin},
eprint = {1609.08439},
file = {:Users/naubergois/Downloads/1609.08439.pdf:pdf},
mendeley-groups = {Model Based Test/BeliefDesire-Intention},
pages = {1--16},
title = {{Model-based Test Generation for Robotic Software: Automata versus Belief-Desire-Intention Agents}},
url = {http://arxiv.org/abs/1609.08439},
year = {2016}
}
@article{Gay2016,
abstract = {The oracle—an arbiter of correctness of the system under test (SUT)—is a major component of the testing process. Specifying oracles is particularly challenging for real-time embedded systems, where small changes in time or sensor inputs may cause large differences in behavior. Behavioral models of such systems, often built for analysis and simulation purposes, are naturally appealing for reuse as oracles. However, these models typically provide an idealized view of the system. Even when given the same inputs, the model's behavior can frequently be at variance with some acceptable behavior of the SUT executing on a real platform. We therefore propose steering the model when used as an oracle, to admit an expanded set of behaviors when judging the SUT's adherence to its requirements. On detecting a behavioral difference, the model is backtracked and then searched for a new state that satisfies certain constraints and minimizes a dissimilarity metric. The goal is to allow non-deterministic, but bounded, behavior differences while preventing future mismatches, by guiding the oracle—within limits—to match the execution of the SUT. Early experimental results show that steering significantly increases SUT-oracle conformance with minimal masking of real faults and, thus, has significant potential for reducing development costs.},
author = {Gay, Gregory and Rayadurgam, Sanjai and Heimdahl, Mats P.E.},
doi = {10.1109/TSE.2016.2615311},
file = {:Users/naubergois/Downloads/gay2016.pdf:pdf},
isbn = {9781450327688},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Model-Based Development,Model-Based Testing,Software Testing,Test Oracles,Verification},
mendeley-groups = {Model Based Test/State Machine Model},
number = {99},
title = {{Automated Steering of Model-Based Test Oracles to Admit Real Program Behaviors}},
volume = {PP},
year = {2016}
}
@article{Rauf2009,
author = {Rauf, Irum and Iqbal, Muhammad Zohaib Z and Malik, Zafar I},
file = {:Users/naubergois/Downloads/ECMDA2009-MOTIP.pdf:pdf},
journal = {2nd Workshop on Model-based Testing in Practice, MOTIP 2009},
mendeley-groups = {Model Based Test,Model Based Test/UML},
title = {{Model Based Testing of Web Service Composition Using UML Profile}},
url = {http://www.fokus.fraunhofer.de/go/motip09},
year = {2009}
}
@article{Wieczorek2010,
abstract = {This paper presents a case study for the modeling and model-based testing (MBT) of enterprise service choreographies. Our proposed MBT approach uses proprietary models called Message Choreography Models (MCM) as test models. The case study illustrates how MCM-based service integration testing allows to formalize design decisions and enables full integration into an existing industrial test infrastructure by using the concepts of domain specific languages and model transformations. Further, the MBT tools integrated into the testing framework have been compared based on one concrete use case.},
author = {Wieczorek, S and Stefanescu, A and Roth, A},
doi = {10.1109/QUATIC.2010.49},
file = {:Users/naubergois/Downloads/quatic10{\_}camera{\_}ready{\_}version.pdf:pdf},
isbn = {978-1-4244-8539-0},
journal = {Quality of Information and Communications Technology (QUATIC), 2010 Seventh International Conference on the},
keywords = {domain specific languages,enterprise service choreographies,formal specification,industrial test infrastructure,message choreography models,model transformations,model-based testing,model-driven service integration testing,program testing,testing framework},
mendeley-groups = {Model Based Test/Non Critical,Model Based Test/MCM Model,Model Based Test/Test Case Generation},
pages = {292--297},
title = {{Model-Driven Service Integration Testing - A Case Study}},
year = {2010}
}
@phdthesis{Eslamimehr2008,
author = {Eslamimehr, Mohammad Mahdi},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Eslamimehr - 2008 - The survey of model based testing and industrial tools(2).pdf:pdf},
mendeley-groups = {Model Based Test,Model Based Test/Survey},
number = {April},
pages = {1--65},
title = {{The survey of model based testing and industrial tools}},
year = {2008}
}
@article{Gambi2013,
abstract = {Elastic computing systems can dynamically scale to continuously and cost-effectively provide their required Quality of Service in face of time-varying workloads, and they are usually implemented in the cloud. Despite their wide-spread adoption by industry, a formal definition of elasticity and suitable procedures for its assessment and verification are still missing. Both academia and industry are trying to adapt established testing procedures for functional and non-functional properties, with limited effectiveness with respect to elasticity. In this paper we propose a new methodology to automatically generate test-suites for testing the elastic properties of systems. Elasticity, plasticity, and oscillations are first formalized through a convenient behavioral abstraction of the elastic system and then used to drive an iterative test suite refinement process. The outcomes of our approach are a test suite tailored to the violation of elasticity properties and a human-readable abstraction of the system behavior to further support diagnosis and fix.},
author = {Gambi, Alessio and Filieri, Antonio and Dustdar, Schahram},
doi = {10.1145/2491411.2494579},
file = {:Users/naubergois/Downloads/gambi2013.pdf:pdf},
isbn = {978-1-4503-2237-9},
journal = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
keywords = {Cloud,behavioral modeling,model-based testing},
mendeley-groups = {Model Based Test/Non Critical,Model Based Test/Test Case Generation,Model Based Test/Cloud Test},
pages = {635--638},
title = {{Iterative Test Suites Refinement for Elastic Computing Systems}},
url = {http://doi.acm.org/10.1145/2491411.2494579},
year = {2013}
}
@article{Buchs2009,
author = {Buchs, Didier and Lucio, Levi and Chen, Ang},
file = {:Users/naubergois/Downloads/buchs2009.pdf:pdf},
journal = {Reliable Software Technologies--Ada-Europe 2009},
keywords = {algebraic,decisions diagrams,higher-level nets,petri nets,state space generation,system design and verification},
mendeley-groups = {Model Based Test,Model Based Test/Non Critical,Model Based Test/Test Case Generation,Model Based Test/Algebraic Petri Nets Algebraic},
pages = {59--74},
title = {{Model checking techniques for test generation from business process models}},
year = {2009}
}
@article{Schaefer2013,
abstract = {Testing game applications relies heavily on beta testing methods. The effectiveness of beta testing depends on how well beta testers represent the common game-application users and if users are willing to participate in the beta test. An automated testing tool framework could reduce the dependence upon beta testing by most companies to analyze their game applications. This paper presents the Crushinator as one such framework. This framework provides a game-independent testing tool that implements multiple testing methods that can assist and possibly replace the use of beta testing.},
author = {Schaefer, Christopher and Do, Hyunsook and Slator, Brian M.},
doi = {10.1109/ASE.2013.6693143},
file = {:Users/naubergois/Downloads/schaefer2013.pdf:pdf},
isbn = {9781479902156},
journal = {2013 28th IEEE/ACM International Conference on Automated Software Engineering, ASE 2013 - Proceedings},
keywords = {Crushinator,event-driven applications,exploratory testing,model-based testing},
mendeley-groups = {Model Based Test/UML},
pages = {726--729},
title = {{Crushinator: A framework towards game-independent testing}},
year = {2013}
}


@article{Paper2014,
author = {{Matthias Beyer, Winfried Dulz}, Kai-Steffen Hielscher},
doi = {10.13140/2.1.3658.3363},
file = {:Users/naubergois/Downloads/Performance Issues in Statistical Testing.pdf:pdf},
mendeley-groups = {Model Based Test/UML,Model Based Test/Test Case Generation},
number = {April 2006},
title = {{Performance Issues in Statistical Testing}},
year = {2014}
}

@article{moscher2017facing,
  title={Facing Synthetic Workload Generation as part of Performance Testing--a tools approach},
  author={Moscher, Marco and F{\"o}gen, Konrad},
  journal={Full-scale Software Engineering/The Art of Software Testing},
  pages={38},
  year={2017}
}


@article{Anisetti2013,
abstract = {The Service-Oriented Architecture (SOA) paradigm is giving rise to a new generation of applications built by dynamically composing loosely coupled autonomous services. Clients (i.e., software agents acting on behalf of human users or service providers) implementing such complex applications typically search and integrate services on the basis of their functional requirements and of their trust in the service suppliers. A major issue in this scenario relates to the definition of an assurance technique allowing clients to select services on the basis of their nonfunctional requirements and increasing their confidence that the selected services will satisfy such requirements. In this article, we first present an assurance solution that focuses on security and supports a test-based security certification scheme for Web services. The certification scheme is driven by the security properties to be certified and relies upon a formal definition of the service model. The evidence supporting a certified property is computed using a model-based testing approach that, starting from the service model, automatically generates the test cases to be used in the service certification. We also define a set of indexes and metrics that evaluate the assurance level and the quality of the certification process. Finally, we present our evaluation toolkit and experimental results obtained applying our certification solution to a financial service implementing the Interactive Financial eXchange (IFX) standard.},
author = {Anisetti, Marco and Ardagna, Claudio A. and Damiani, Ernesto and Saonara, Francesco},
doi = {10.1145/2460383.2460384},
file = {:Users/naubergois/Downloads/anisetti2013.pdf:pdf},
isbn = {1559-1131},
issn = {15591131},
journal = {ACM Transactions on the Web},
keywords = {Model-based testing,security certification,service-oriented architecture,symbolic transition systems,web services},
mendeley-groups = {Model Based Test,Model Based Test/Symbolic Transition System,Model Based Test/Test Case Generation},
number = {2},
pages = {1--41},
title = {{A test-based security certification scheme for web services}},
url = {http://dl.acm.org/citation.cfm?id=2460383.2460384},
volume = {7},
year = {2013}
}
@article{Kim2005,
abstract = {Testing the performance of a server that handles massive connections requires to generate massive virtual client connections and to model realistic traffic. In this paper, we propose a novel approach to generate massive virtual clients and realistic traffic. Our approach exploits the Windows I/O completion port (IOCP), which is the Windows NT operating system support for developing a scalable, high throughput server, and model-based testing scenarios. We describe implementation details of the proposed approach. Through analysis and experiments, we prove that the proposed method can predict and evaluate performance data more accurately in cost-effective way.},
author = {Kim, Gyu Baek},
doi = {10.1109/QSIC.2005.4},
file = {:Users/naubergois/Downloads/10.1109@qsic.2005.4.pdf:pdf},
isbn = {0769524729},
issn = {15506002},
journal = {Proceedings - International Conference on Quality Software},
mendeley-groups = {Model Based Test/Critical Systems,Model Based Test,Model Based Test/UML,Model Based Test/Test Case Generation,Model Based Test/Load Test,Load Test Tools},
pages = {250--254},
title = {{A method of generating massive virtual clients and model-based performance test}},
volume = {2005},
year = {2005}
}
@article{Rodrigues2014,
abstract = {[Context] A variety of testing tools have been developed to support and automate software performance testing activities. These tools may use different techniques, such as Model-Based Testing (MBT) or Capture and Replay (CR). [Goal] For software companies, it is important to evaluate such tools w.r.t. the effort required for creating test artifacts using them; despite its importance, there are few empirical studies comparing performance testing tools, specially tools developed with different approaches. [Method] We are conducting experimental studies to provide evidence about the required effort to use CR-based tools and MBT tools. In this paper, we present our first results, evaluating the effort (time spent) when using LoadRunner and Visual Studio CR-based tools, and the PLeTsPerf MBT tool to create performance test scripts and scenarios to test Web applications, in the context of a collaboration project between Software Engineering Research Center at PUCRS and a technological laboratory of a global IT company. [Results] Our results indicate that, for simple testing tasks, the effort of using a CR-based tool was lower than using an MBT tool, but as the testing complexity increases tasks, the advantage of using MBT grows significantly. [Conclusions] To conclude, we discuss the lessons we learned from the design, operation, and analysis of our empirical experiment. },
author = {Rodrigues, Elder M and Saad, Rodrigo S and Oliveira, Flavio M and Costa, Leandro T and Bernardino, Maicon and Zorzo, Avelino F},
doi = {10.1145/2652524.2652587},
file = {:Users/naubergois/Downloads/rodrigues2014.pdf:pdf},
isbn = {978-1-4503-2774-9},
issn = {19493789},
journal = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
keywords = {experiment,performance testing,testing tools},
mendeley-groups = {Load Test Tools,Load Test Tools/PleTsPerf,Load Test Tools/LoadRunner,Load Test Tools/Visual Studio,Model Based Test/UML},
pages = {9:1----9:8},
title = {{Evaluating Capture and Replay and Model-based Performance Testing Tools: An Empirical Comparison}},
url = {http://doi.acm.org/10.1145/2652524.2652587},
year = {2014}
}
@book{Hessel2007,
abstract = {Testing is the dominant verification technique used in the software$\backslash$nindustry today. The use of automatic test case$\backslash$nexecution increases, but the creation of test cases$\backslash$nremains manual and thus error prone and$\backslash$nexpensive. To automate generation and selection of$\backslash$ntest cases, model-based testing techniques have been$\backslash$nsuggested. In this thesis two central problems in$\backslash$nmodel-based testing are addressed: the problem of$\backslash$nhow to formally specify coverage criteria, and the$\backslash$nproblem of how to generate a test suite from a$\backslash$nformal timed system model, such that the test suite$\backslash$nsatisfies a given coverage criterion. We use model$\backslash$nchecking techniques to explore the state-space of a$\backslash$nmodel until a set of traces is found that together$\backslash$nsatisfy the coverage criterion. A key observation is$\backslash$nthat a coverage criterion can be viewed as$\backslash$nconsisting of a set of items, which we call coverage$\backslash$nitems. Each coverage item can be treated as a$\backslash$nseparate reachability problem. Based on our view$\backslash$nof coverage items we define a language, in the form$\backslash$nof parameterized observer automata, to formally$\backslash$ndescribe coverage criteria. We show that the$\backslash$nlanguage is expressive enough to describe a variety$\backslash$nof common coverage criteria described in the$\backslash$nliterature. Two algorithms for test case generation$\backslash$nwith observer automata are presented. The first$\backslash$nalgorithm returns a trace that satisfies all$\backslash$ncoverage items with a minimum cost. We use this$\backslash$nalgorithm to generate a test suite with minimal$\backslash$nexecution time. The second algorithm explores only$\backslash$nstates that may increase the already found set of$\backslash$ncoverage items. This algorithm works well together$\backslash$nwith observer automata. The developed techniques$\backslash$nhave been implemented in the tool CoVer. The tool$\backslash$nhas been used in a case study together with Ericsson$\backslash$nwhere a WAP gateway has been tested. The case study$\backslash$nshows that the techniques have industrial strength.},
author = {Hessel, Anders},
file = {:Users/naubergois/Downloads/FULLTEXT01.pdf:pdf},
isbn = {9789155468835},
mendeley-groups = {Model Based Test/Critical Systems,Model Based Test/State Machine Model,Model Based Test},
title = {{Model-Based Test Case Generation for Real-Time Systems}},
year = {2007}
}
@misc{Kosindrdecha2010,
abstract = {This study aims to improve an automated test case generation method to minimize a number of test cases while maximizing an ability to identify critical domain specific requirements. It has been proven that the software testing phase is one of the most critical and important phases in the software development life cycle. In general, the software testing phase takes around 40-70{\%} of the effort, time and cost. This area has been well researched over a long period of time. Unfortunately, while many researchers have found methods of reducing time and cost during the testing process, there are still a number of important related issues that need to be researed. This study introduces a new test case generation process with a requeirement priorization method to resolve the following research problems: (1) inefficent test case generation techniqeus with limited resources (2) lack of an ability to identify critical domain requirements in the test case generation process (3) inefficient automated test case generation techniques and (4) ignoring a number of generated test cases. In brief, the contrubutions are to: (1) study a comprehensive set of test case generation techniques since 1990, (2) compare existing test case generation methods and address the limitations of each technique, (3) introduce a new classification of test case generation techniques, (4) define a new process to generate test cases by prposing a requirement prioritization method and (5) propose a new effective test generation method},
author = {Kosindrdecha, Nicha and Daengdej, Jirapun},
booktitle = {Journal of Software Engineering 4(4): 265-287, 2010},
doi = {1819-4311},
file = {:Users/naubergois/Downloads/265-287.pdf:pdf},
keywords = {Test case generation,requirement prioritization,test generation,test generation method,test generation process,testing research issues},
mendeley-groups = {Model Based Test/Test Case Generation,Model Based Test/Test Case Generation Process},
title = {{A Test Case Generation Process and Technique}},
year = {2010}
}
@article{Maalej2013,
abstract = {Web service compositions must provide services to hundreds even thousands of users concurrently. These applications must be load tested to ensure that they can function properly under high load. We propose in this paper a solution for load testing of WS-BPEL compositions. It is based on Timed Automata as model for specifying requirements to test under various load conditions, a distributed testing architecture, an algorithm for online load test generation and execution, and finally an automated log analysis technique. We also illustrate our approach by means of a case study. {\textcopyright} 2013 IEEE.},
author = {Maalej, Afef Jmal and Hamza, Manel and Krichen, Moez and Jmaiel, Mohamed},
doi = {10.1109/ICSTW.2013.25},
file = {:Users/naubergois/Downloads/maalej2013.pdf:pdf},
isbn = {978-0-7695-4993-4},
journal = {Proceedings - IEEE 6th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2013},
keywords = {Timed Automata,WS-BPEL compositions,load testing,log analysis,online model-based testing},
mendeley-groups = {Model Based Test/Timed Automata},
pages = {144--153},
title = {{Automated significant load testing for WS-BPEL compositions}},
year = {2013}
}
@article{Avritzer1995b,
abstract = {Three automatic test case generation algorithms intended to test the resource allocation mechanisms of telecommunications software systems are introduced. Although these techniques were specifically designed for testing telecommunications software, they can be used to generate test cases for any software system that is modelable by a Markov chain provided operational profile data can either be collected or estimated. These algorithms have been used successfully to perform load testing for several real industrial software systems. Experience generating test suites for five such systems is presented. Early experience with the algorithms indicate that they are highly effective at detecting subtle faults that would have been likely to be missed if load testing had been done in the more traditional way, using hand-crafted test cases. A domain-based reliability measure is applied to systems after the load testing algorithms have been used to generate test data. Data are presented for the same five industrial telecommunications systems in order to track the reliability as a function of the degree of system degradation experienced},
annote = {From Duplicate 4 ( 


The automatic generation of load test suites and the assessment of the resulting software


- Avritzer, A.; Weyuker, E.J. )




From Duplicate 1 ( 


The automatic generation of load test suites and the assessment of the resulting software


- Avritzer, A.; Weyuker, E.J. )

},
author = {Avritzer, A. and Weyuker, E.J.},
doi = {10.1109/32.464549},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Avritzer, Weyuker - 1995 - The automatic generation of load test suites and the assessment of the resulting software.html:html;:Users/naubergois/Downloads/avritzer1995.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
mendeley-groups = {Model Based Test/Markov Chains},
mendeley-tags = {Automatic testing,Communication industry,Computer industry,Markov chain,Markov processes,Performance evaluation,Resource management,Software algorithms,Software systems,System testing,automatic test case generation algorithms,automatic test software,domain-based reliability measure,fault detection,industrial software systems,load test suites,load testing,program testing,reliability,resource allocation,resource allocation mechanisms,software reliability,software testing,system degradation,telecommunication computing,telecommunications software},
number = {9},
pages = {705--716},
title = {{The automatic generation of load test suites and the assessment of the resulting software}},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=464549{\&}url=http{\%}3A{\%}2F{\%}2Fieeexplore.ieee.org{\%}2Fxpls{\%}2Fabs{\_}all.jsp{\%}3Farnumber{\%}3D464549 http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=464549{\&}url=http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumbe},
volume = {21},
year = {1995}
}
@article{El-far2001,
abstract = {There is an abundance of testing styles in the discipline of software engineering today. Over the last few decades, many of these have come to be used and adopted by the industry as solutions to address the increasing demand for assuring software quality. Since 1990 or so, perhaps as an outcome of the popularization of object orientation and models in software engineering, there has been a growth in black-box testing techniques that are collectively dubbed model-based testing. Model-based testing (MBT) is a general term that signifies an approach that bases common testing tasks such as test case generation and test result evaluation [see Jorgensen (1995) for some of these basic terms and concepts] on a model of the application under test.This generic definition is probably the least general statement that can be made about MBT. One of the striking issues about MBT is the nonstandard lingo that reflects a diversity of philosophies and models. Another issue that one will eventually realize in studying this set of techniques is that the models and techniques have yet to travel the long course to maturity. Disregarding these concerns, model-based techniques have gained the attention of practitioners and theoreticians alike. The wealth of published work portraying case studies in both academic and industrial settings is a sign of the newfound interest in this youthful branch of testing.Model-based techniques have substantial appeal. The first sign of potential are studies showing that testing a variety of applications has been met with success when MBT was employed. This article discussed what a model is and gives some models that have been useful for testing. Information given or choosing a module, building it, and testing it, The present and future status of model-based software testing is detailed.},
author = {El-far, Ibrahim K and Whittaker, James a},
doi = {10.1002/0471028959.sof207},
file = {:Users/naubergois/Downloads/Model-based Software Testing.pdf:pdf},
isbn = {9780471028956},
journal = {Encyclopedia of Software Engineering},
keywords = {finite state machines,grammars,markov chains,software behavior models,statecharts,test automation,test case generation,unified modeling language},
mendeley-groups = {Model Based Test},
pages = {1--22},
title = {{Model‐Based Software Testing}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/0471028959.sof207/full},
year = {2001}
}
@book{Havelund2006,
author = {Havelund, Klaus and N{\'{u}}{\~{n}}ez, Manuel and Roşu, Grigore and Wolff, Burkhart},
booktitle = {Serious Games Development and Applications},
file = {:Users/naubergois/Downloads/Deterministic{\_}dynamic{\_}monitors{\_}for{\_}linea.pdf:pdf},
isbn = {9783642238338},
mendeley-groups = {Reinforcement Learning,Model Based Test},
pages = {155},
title = {{Formal Approaches to Software Testing and Runtime Verification}},
url = {http://www.ulb.tu-darmstadt.de/tocs/79304567.pdf},
year = {2006}
}
@article{Hierons2009,
abstract = {Formal methods and testing are two important approaches that assist in the development of high-quality software.While traditionally these approaches have been seen as rivals, in recent years a new consensus has developed in which they are seen as complementary. This article reviews the state of the art regarding ways in which the presence of a formal specification can be used to assist testing.},
author = {Hierons, Robert M and Bogdanov, Kirill and Bowen, Jonathan P and Cleaveland, Rance and Derrick, John and Dick, Jeremy and Gheorghe, Marian and Harman, Mark and Kapoor, Kalpesh and Krause, Paul and L{\"{u}}ttgen, Gerald and Simons, Anthony J H and Vilkomir, Sergiy and Woodward, Martin R and Zedan, Hussein},
doi = {http://doi.acm.org/10.1145/1459352.1459354},
file = {:Users/naubergois/Downloads/hierons2009.pdf:pdf},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
mendeley-groups = {Model Based Test/State Machine Model},
number = {2},
pages = {1--76},
title = {{Using formal specifications to support testing}},
volume = {41},
year = {2009}
}
@article{MarkUtting2012,
abstract = {Penetration testing is widely used to help ensure the security of web applications. Using penetration testing, testers discover vulnerabilities by simulating attacks on a target web application. To do this efﬁciently, testers rely on automated techniques that gather input vector information about the target web application and analyze the application's responses to determine whether an attack was successful. Techniques for performing these steps are often incomplete, which can leave parts of the web application untested and vulnerabilities undiscovered. This paper proposes a new approach to penetration testing that addresses the limitations of current techniques. The approach incorporates two recently developed analysis techniques to improve input vector identiﬁcation and detect when attacks have been successful against a web application. This paper compares the proposed approach against two popular penetration testing tools for a suite of web applications with known and unknown vulnerabilities. The evaluation results show that the proposed approach performs a more thorough penetration testing and leads to the discovery of more vulnerabilities than both the tools.},
author = {{Mark Utting}, Alexander Pretschner and Bruno Legeard},
doi = {10.1002/stvr},
file = {:Users/naubergois/Downloads/master{\_}pdflatex.pdf:pdf},
isbn = {1099-1689},
issn = {10991689},
journal = {Software Testing Verification and Reliability},
keywords = {model-based testing approaches,survey,taxonomy},
mendeley-groups = {Model Based Test/Taxonomy},
number = {8},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {24},
year = {2012}
}
@article{Wang2013,
author = {Wang, Xingen and Zhou, Bo and Li, Wei},
doi = {10.1080/02533839.2012.726028},
file = {:Users/naubergois/Downloads/wang2013.pdf:pdf},
issn = {0253-3839},
journal = {Journal of the Chinese Institute of Engineers},
keywords = {Model Based Test,Stress testing,load testing,markov chains,usage model},
mendeley-groups = {Model Based Test/CONCEPT},
number = {1},
pages = {74--86},
title = {{Model-based load testing of web applications}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02533839.2012.726028},
volume = {36},
year = {2013}
}
@article{Ag2006,
author = {Ag, Daimler Chrysler and Berlin, D- and Wappler, Stefan},
file = {:Users/naubergois/Downloads/tlili2006.pdf:pdf},
isbn = {1595931864},
journal = {Proceedings of the 8th annual conference on Genetic and evolutionary computation},
keywords = {Execution Time Testing,Software Tools,Software engineering,Stress testing},
mendeley-groups = {Model Based Test/Critical Systems},
pages = {1917--1924},
title = {{Improving Evolutionary Real-Time Testing Categories and Subject Descriptors}},
year = {2006}
}
@article{Bertolino2008,
abstract = {A Web Service is commonly not an independent software entity, but plays a role in some business process. Hence, it depends on the services provided by external Web Services, to provide its own service. While developing and testing a Web Service, such external services are not always available, or their usage comes along with unwanted side effects like, e.g., utilization fees or database modifications. We present a model-based approach to generate stubs for Web Services which respect both an extra-functional contract expressed via a Service Level Agree- ment (SLA), and a functional contract modeled via a state machine. These stubs allow a developer to set up a testbed over the target plat- form, in which the extra-functional and functional behavior of a Web Service under development can be tested before its publication.},
author = {Bertolino, Antonia and Angelis, Guglielmo De},
doi = {10.1007/978-3-540-68524-1_19},
file = {:Users/naubergois/Downloads/BAFP08.pdf:pdf},
isbn = {978-3-540-68514-2, 978-3-540-68524-1},
issn = {978-3-540-68514-2},
journal = {Testing of Software and {\ldots}},
mendeley-groups = {Model Based Test/Non Critical,Model Based Test/Test Bed},
pages = {266--282},
title = {{Model-based generation of testbeds for web services}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-68524-1{\_}19},
year = {2008}
}
@article{Afzal2008,
abstract = {Automated software test generation has been applied across the spectrum of test case design methods; this includes white-box (structural), black-box (functional), grey-box (combination of structural and functional) and non-functional testing. In this paper, we undertake a systematic mapping study to present a broad review of primary studies on the application of search-based optimization techniques to non-functional testing. The motivation is to identify the evidence available on the topic and to identify gaps in the application of search-based optimization techniques to different types of non-functional testing. The study is based on a comprehensive set of 35 papers obtained after using a multi-stage selection criteria and are published in workshops, conferences and journals in the time span 1996-2007. We conclude that the search-based software testing community needs to do more and broader studies on non-functional search-based software testing (NFSBST) and the results from our systematic map can help direct such efforts.},
author = {Afzal, Wasif and Torkar, Richard and Feldt, Robert},
isbn = {1891706225},
journal = {Proceedings of the Twentieth International Conference on Software Engineering {\&} Knowledge Engineering (SEKE'2008)},
keywords = {Search-Based Test,Stress testing,Systematic Review},
mendeley-groups = {Model Based Test/Survey},
mendeley-tags = {Search-Based Test,Stress testing,Systematic Review},
number = {October 2015},
pages = {488--493},
title = {{A systematic mapping study on non-functional search-based software testing}},
url = {http://richard.torkar.googlepages.com/a{\_}systematic{\_}mapping{\_}study{\_}on{\_}non-fu.pdf},
year = {2008}
}
@article{Zhou2014,
author = {Zhou, Junzan and Zhou, Bo and Li, Shanping},
doi = {10.1109/COMPSACW.2014.108},
file = {:Users/naubergois/Downloads/zhou2014.pdf:pdf},
isbn = {978-1-4799-3578-9},
journal = {2014 IEEE 38th International Computer Software and Applications Conference Workshops},
keywords = {Cloud,Model Based Test,Stress Testing},
mendeley-groups = {Model Based Test,Model Based Test/Non Critical,Model Based Test/Test Case Generation,Model Based Test/Cloud Test,Model Based Test/Load Test,Search-Based Tests/Multi objective tests/Multo-objective tests},
pages = {644--649},
title = {{Automated Model-Based Performance Testing for PaaS Cloud Services}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6903204},
year = {2014}
}
@article{Anand2013a,
abstract = {Test case generation is among the most labour-intensive tasks in software testing. It also has a strong impact on the effectiveness and efficiency of software testing. For these reasons, it has been one of the most active research topics in software testing for several decades, resulting in many different approaches and tools. This paper presents an orchestrated survey of the most prominent techniques for automatic generation of software test cases, reviewed in self-standing sections. The techniques presented include: (a) structural testing using symbolic execution, (b) model-based testing, (c) combinatorial testing, (d) random testing and its variant of adaptive random testing, and (e) search-based testing. Each section is contributed by world-renowned active researchers on the technique, and briefly covers the basic ideas underlying the method, the current state of the art, a discussion of the open research problems, and a perspective of the future development of the approach. As a whole, the paper aims at giving an introductory, up-to-date and (relatively) short overview of research in automatic test case generation, while ensuring a comprehensive and authoritative treatment. ?? 2013 Elsevier Inc. All rights reserved.},
author = {Anand, Saswat and Burke, Edmund K. and Chen, Tsong Yueh and Clark, John and Cohen, Myra B. and Grieskamp, Wolfgang and Harman, Mark and Harrold, Mary Jean and McMinn, Phil},
doi = {10.1016/j.jss.2013.02.061},
isbn = {0164-1212},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {Adaptive random testing,Combinatorial testing,Model-based testing,Orchestrated survey,Search-based software testing,Software testing,Symbolic execution,Test automation,Test case generation},
mendeley-groups = {Model Based Test/Test Case Generation},
number = {8},
pages = {1978--2001},
title = {{An orchestrated survey of methodologies for automated software test case generation}},
volume = {86},
year = {2013}
}
@article{Ali2010,
author = {Ali, S and Briand, Lc},
doi = {10.1109/TSE.2009.52},
issn = {0098-5589},
journal = {Software {\ldots}},
mendeley-groups = {Model Based Test/Test Case Generation},
number = {5},
pages = {1--22},
title = {{A systematic review of the application and empirical investigation of search-based test case generation}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5210118},
year = {2010}
}
@article{Cai2007,
abstract = {Accurate web application performance testing relies on the use of loading tests based on a realistic client behaviour load model. Unfortunately developing such load models and associated test plans and scripts is tedious and error-prone with most existing web performance testing tools providing limited client load modelling capabilities. We describe a new approach and toolset that we have developed, MaramaMTE+, which improves the ability to model realistic web client load behaviour, automatically generates complex web application testing plans and scripts, and integrates load behaviour modelling with a generic performance engineering tool. MaramaMTE+ uses a stochastic form chart as its client loading model. A 3rd party web crawler application extracts structural information from a target web site, aggregating the collected data into a crawler database that is then used for form chart model generation. The performance engineer then augments this synthesized form probabilities. Realistic web loading tests for a 3rd party web load testing tool are then automatically generated from this resultant stochastic form chart client load model. We chart with client loading describe the development of our MaramaMTE+ environment, example usage of the tool, and compare and contrast the results obtained from our generated performance load tests against hand-built 3rd party tool load tests.},
author = {Cai, Yuhong and Grundy, John and Hosking, John},
doi = {10.1145/1321631.1321684},
file = {:Users/naubergois/Downloads/cai2007.pdf:pdf},
isbn = {9781595938824},
journal = {Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering - ASE '07},
mendeley-groups = {Model Based Test/Stochastic model},
pages = {353},
title = {{Synthesizing client load models for performance engineering via web crawling}},
url = {http://portal.acm.org/citation.cfm?doid=1321631.1321684},
year = {2007}
}
@article{Barber1999,
author = {Barber, Scott},
mendeley-groups = {Model Based Test/UCML},
pages = {1--9},
title = {{User Community Modeling Language ( UCML ™ ) v1 . 1 for Performance Test Workloads UCML ™ Overview}},
year = {1999}
}
@article{Neto2007,
abstract = {This paper describes a systematic review performed on modelbased testing (MBT) approaches. A selection criterion was used to narrow the initially identified four hundred and six papers to focus on seventy-eight papers. Detailed analysis of these papers shows where MBT approaches have been applied, the characteristics, and the limitations. The comparison criteria includes representation models, support tools, test coverage criteria, the level of automation, intermediate models, and the complexity. This paper defines and explains the review methodology and presents some results.},
author = {Neto, Arilo C Dias and Subramanyan, Rajesh and Vieira, Marlon and Travassos, Guilherme H.},
doi = {10.1145/1353673.1353681},
file = {:Users/naubergois/Downloads/10.1145@1353673.1353681 (1).pdf:pdf},
isbn = {9781595938800},
issn = {09505849},
journal = {22nd IEEE/ACM International Conference on Automated Software Engineering (AES)},
keywords = {2,model-based testing,survey,systematic review,test case generation,testing approaches},
mendeley-groups = {Model Based Test,Model Based Test/Survey},
pages = {31--36},
title = {{A Survey on Model-based Testing Approaches : A Systematic Review}},
year = {2007}
}
@article{Ferrer2015,
author = {Ferrer, Javier and Kruse, Peter M. and Chicano, Francisco and Alba, Enrique},
doi = {10.1016/j.infsof.2014.07.014},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Ferrer et al. - 2015 - Search based algorithms for test sequence generation in functional testing(2).pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
mendeley-groups = {Model Based Test/Test Case Generation},
pages = {419--432},
publisher = {Elsevier B.V.},
title = {{Search based algorithms for test sequence generation in functional testing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584914001827},
volume = {58},
year = {2015}
}
@inproceedings{Barros2007,
abstract = {New versions of existing large-scale web services such as Passport.comcopy have to go through rigorous performance evaluations in order to ensure a high degree of availability. Performance testing (such as benchmarking, scalability, and capacity tests) of large-scale stateful systems in managed test environments has many different challenges, mainly related to the reproducibility of production conditions in live data centers. One of these challenges is creating a dataset in a test environment that mimics the actual dataset in production. Other challenges involve the characterization of load patterns in production based on log analysis and proper load simulation via reutilization of data from the existing dataset. The intent of this paper is to describe practical approaches to address some of the aforementioned challenges through the use of various novel techniques. For example, this paper discusses data sanitization, which is the alteration of large datasets in a controlled manner to obfuscate sensitive information, preserving data integrity, relationships, and data equivalence classes. This paper also provides techniques for load pattern characterization via the application of Markov chains to custom and generic logs, as well as general guidelines for the development of cache-based load simulation tools tailored for the performance evaluation of stateful systems.},
author = {{De Barros}, Marcelo and Shiau, Jing and Shang, Chen and Gidewall, Kenton and Shi, Hui and Forsmann, Joe},
booktitle = {Proceedings of the International Conference on Dependable Systems and Networks},
doi = {10.1109/DSN.2007.102},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Barros, Shiau - 2007 - Web services wind tunnel On performance testing large-scale stateful web services.pdf:pdf},
isbn = {0769528554},
mendeley-groups = {Model Based Test/Markov Chains},
pages = {612--617},
title = {{Web services wind tunnel: On performance testing large-scale stateful web services}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4273012},
year = {2007}
}
@article{Silveira2011,
author = {da Silveira, MB and Rodrigues, EM and Zorzo, AF},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Silveira, Rodrigues, Zorzo - 2011 - Generation of Scripts for Performance Testing Based on UML Models.pdf:pdf},
journal = {SEKE},
keywords = {- model-based testing,performance testing,software product line},
mendeley-groups = {Model Based Test/Non Critical,Model Based Test,Model Based Test/Load Test,Model Based Test/UML},
title = {{Generation of Scripts for Performance Testing Based on UML Models.}},
url = {http://www.ksi.edu/seke/Proceedings/seke11/154{\_}Elder{\_}de{\_}Macedo{\_}Rodrigues.pdf},
year = {2011}
}
@article{Avritzer1994,
address = {New York, New York, USA},
author = {Avritzer, Alberto and Weyuker, EJ},
doi = {10.1145/186258.186507},
file = {:Users/naubergois/Downloads/Generating test suites for software load testing.pdf:pdf},
isbn = {0897916832},
journal = {{\ldots} international symposium on Software testing {\ldots}},
mendeley-groups = {Model Based Test/Markov Chains},
pages = {44--57},
publisher = {ACM Press},
title = {{Generating test suites for software load testing}},
url = {http://portal.acm.org/citation.cfm?doid=186258.186507 http://dl.acm.org/citation.cfm?id=186507},
year = {1994}
}
@article{Anand2013,
abstract = {Test case generation is among the most labour-intensive tasks in software testing. It also has a strong impact on the effectiveness and efficiency of software testing. For these reasons, it has been one of the most active research topics in software testing for several decades, resulting in many different approaches and tools. This paper presents an orchestrated survey of the most prominent techniques for automatic generation of software test cases, reviewed in self-standing sections. The techniques presented include: (a) structural testing using symbolic execution, (b) model-based testing, (c) combinatorial testing, (d) random testing and its variant of adaptive random testing, and (e) search-based testing. Each section is contributed by world-renowned active researchers on the technique, and briefly covers the basic ideas underlying the method, the current state of the art, a discussion of the open research problems, and a perspective of the future development of the approach. As a whole, the paper aims at giving an introductory, up-to-date and (relatively) short overview of research in automatic test case generation, while ensuring a comprehensive and authoritative treatment. ?? 2013 Elsevier Inc. All rights reserved.},
author = {Anand, Saswat and Burke, Edmund K. and Chen, Tsong Yueh and Clark, John and Cohen, Myra B. and Grieskamp, Wolfgang and Harman, Mark and Harrold, Mary Jean and McMinn, Phil},
doi = {10.1016/j.jss.2013.02.061},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Anand et al. - 2013 - An orchestrated survey of methodologies for automated software test case generation.pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {Adaptive random testing,Combinatorial testing,Model-based testing,Orchestrated survey,Search-based software testing,Software testing,Symbolic execution,Test automation,Test case generation},
mendeley-groups = {Model Based Test,Model Based Test/Survey,Model Based Test/Test Data Generation},
pages = {1978--2001},
title = {{An orchestrated survey of methodologies for automated software test case generation}},
volume = {86},
year = {2013}
}
@inproceedings{Draheim2006b,
abstract = {We present a new approach for performing load testing of Web applications by simulating realistic user behaviour with stochastic form-oriented analysis models. Realism in the simulation of user behaviour is necessary in order to achieve valid testing results. In contrast to many other user models, Web site navigation and time delay are modelled stochastically. The models can be constructed from sample data and can take into account effects of session history on user behaviour and the existence of different categories of users. The approach is implemented in an existing architecture modelling and performance evaluation tool and is integrated with existing methods for forward and reverse engineering},
author = {Draheim, D. and Grundy, J. and Hosking, J. and Lutteroth, C. and Weber, G.},
booktitle = {Conference on Software Maintenance and Reengineering (CSMR'06)},
doi = {10.1109/CSMR.2006.43},
file = {:Users/naubergois/Downloads/Realistic{\_}Load{\_}Testing{\_}ofWeb{\_}Application.pdf:pdf},
isbn = {0-7695-2536-9},
issn = {1052-8725},
mendeley-groups = {Search-Based Tests/Critical Systems,Model Based Test/Stochastic model},
title = {{Realistic load testing of Web applications}},
url = {http://ieeexplore.ieee.org/xpl/login.jsp?tp={\&}arnumber=1602358{\&}url=http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1602358},
year = {2006}
}
@article{Lenz2007,
author = {Lenz, Chris and Chimiak-Opoka, J and Breu, Ruth},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Lenz, Chimiak-Opoka, Breu - 2007 - Model-Driven Testing of SOA-based Software(2).pdf:pdf},
journal = {{\ldots} of the SEMSOA Workshop on Software {\ldots}},
mendeley-groups = {Model Based Test/UML},
title = {{Model-Driven Testing of SOA-based Software}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.128.7626{\&}rep=rep1{\&}type=pdf},
year = {2007}
}
@inproceedings{Avritzer1993,
abstract = {In this paper we introduce a new load testing technique called Deterministic Markov State Testing and report on its application. Our approach is called “deterministic” because the sequence of test case execution is set at planning time, and “state testing” because each test case certifies a unique software state. There are four main advantages of Deterministic Markov State Testing for system testers: provision of precise software state information for root cause analysis in load test, accommodation for limitations of the system test lab configuration, higher acceleration ratios in system test, and simple management of distributed execution of test cases. System testers using the proposed method have great flexibility in dealing with common system test problems: limited access to the system test environment, unstable software, or changing operational conditions. Because each test case verifies correct execution on a path from the idle state to the software state under test, our method does not require the continuous execution of all test cases. Deterministic Markov State Testing is operational-profile-based, and allows for measurement of software reliability robustness when the operational profile changes.},
address = {New York, NY, USA},
author = {Avritzer, Alberto and Larson, Brian},
doi = {10.1145/154183.154244},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Avritzer, Larson - 1993 - Load Testing Software Using Deterministic State Testing.pdf:pdf},
isbn = {0-89791-608-5},
mendeley-groups = {Model Based Test/Markov Chains},
pages = {82--88},
publisher = {ACM},
series = {ISSTA '93},
title = {{Load Testing Software Using Deterministic State Testing}},
url = {http://doi.acm.org/10.1145/154183.154244},
year = {1993}
}
@inproceedings{Avritzer1993d,
abstract = {In this paper we introduce a new load testing technique called Deterministic Markov State Testing and report on its application. Our approach is called “deterministic” because the sequence of test case execution is set at planning time, and “state testing” because each test case certifies a unique software state. There are four main advantages of Deterministic Markov State Testing for system testers: provision of precise software state information for root cause analysis in load test, accommodation for limitations of the system test lab configuration, higher acceleration ratios in system test, and simple management of distributed execution of test cases. System testers using the proposed method have great flexibility in dealing with common system test problems: limited access to the system test environment, unstable software, or changing operational conditions. Because each test case verifies correct execution on a path from the idle state to the software state under test, our method does not require the continuous execution of all test cases. Deterministic Markov State Testing is operational-profile-based, and allows for measurement of software reliability robustness when the operational profile changes.},
address = {New York, NY, USA},
annote = {From Duplicate 1 ( 

Load Testing Software Using Deterministic State Testing

- Avritzer, Alberto; Larson, Brian )




From Duplicate 3 ( 

Load Testing Software Using Deterministic State Testing

- Avritzer, Alberto; Larson, Brian )




From Duplicate 2 ( 

Load Testing Software Using Deterministic State Testing

- Avritzer, Alberto; Larson, Brian )
















From Duplicate 2 ( 

Load Testing Software Using Deterministic State Testing

- Avritzer, Alberto; Larson, Brian )




From Duplicate 1 ( 

Load testing software using deterministic state testing

- Avritzer, Alberto; Larson, Brian )








From Duplicate 2 ( 

Load Testing Software Using Deterministic State Testing

- Avritzer, Alberto; Larson, Brian )




From Duplicate 2 ( 

Load Testing Software Using Deterministic State Testing

- Avritzer, Alberto; Larson, Brian )

},
author = {Avritzer, Alberto and Larson, Brian},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/154183.154244},
file = {:Users/naubergois/Library/Application Support/Mendeley Desktop/Downloaded/Avritzer, Larson - 1993 - Load Testing Software Using Deterministic State Testing.pdf:pdf},
isbn = {0-89791-608-5},
mendeley-groups = {Model Based Test/Markov Chains},
pages = {82--88},
publisher = {ACM},
series = {ISSTA '93},
title = {{Load Testing Software Using Deterministic State Testing}},
url = {http://doi.acm.org/10.1145/154183.154244 http://dl.acm.org/citation.cfm?id=154244},
year = {1993}
}



